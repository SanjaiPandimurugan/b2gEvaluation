<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/water.css@2/out/water.css"><link rel="stylesheet" href="../custom.css"><div class="middle-column">
 <section id="overview">
  <h1 class="hckui__typography__h1" itemprop="name">
   Build2gether2.0 – MOBILITY IMPAIRMENTS Track1: Entry Project
  </h1>
  <p class="hckui__typography__bodyL hckui__layout__marginBottom15" itemprop="description">
   Sensing the walls.
  </p>
  <div class="hckui__layout__marginTop30">
   <div class="hckui__layout__hiddenMedUp">
   </div>
   <div class="project-cover-image" itemprop="image" itemscope="" itemtype="https://schema.org/ImageObject">
    <meta content="https://hackster.imgix.net/uploads/attachments/1739162/_imZizemiz5.blob?auto=compress&amp;w=900&amp;h=675&amp;fit=min&amp;fm=jpg" itemprop="url"/>
    <meta content="900" itemprop="width"/>
    <meta content="675" itemprop="height"/>
    <img alt="Build2gether2.0 – MOBILITY IMPAIRMENTS Track1: Entry Project" src="1.jpg"/>
   </div>
  </div>
 </section>
 <div class="project-section-break">
 </div>
 <div id="project_page_simple_ad_portal">
 </div>
 <div id="description" itemprop="articleBody">
  <section id="things">
   <div class="project-section-title">
    <h2 class="hckui__typography__h2 title-with-anchor">
     <span>
      Things used in this project
     </span>
    </h2>
   </div>
   <div class="project-parts">
    <div class="view-expanded" style="display:block">
     <table class="project-parts-table">
      <colgroup>
       <col style="width: 100px; height: 50px;"/>
       <col style="width: auto;"/>
      </colgroup>
      <tbody>
       <tr class="head">
        <td colspan="2">
         <h3 class="hckui__typography__h3">
          Hardware components
         </h3>
        </td>
        <tr>
         <td class="part-img">
          <img alt="UNIHIKER - IoT Python Programming Single Board Computer with Touchscreen" src="2.jpg" srcset="https://hackster.imgix.net/uploads/attachments/1623050/9924dc25f8a8d36cae2ea2becac95b77_Bn8OXLjRQw.png?auto=compress%2Cformat&amp;w=96&amp;h=96&amp;fit=fill&amp;bg=ffffff 2x, https://hackster.imgix.net/uploads/attachments/1623050/9924dc25f8a8d36cae2ea2becac95b77_Bn8OXLjRQw.png?auto=compress%2Cformat&amp;w=48&amp;h=48&amp;fit=fill&amp;bg=ffffff"/>
         </td>
         <td class="hckui__typography__bodyL">
          <a class="hckui__typography__linkBlue" data-ha='{"eventName":"Clicked link","customProps":{"value":"DFRobot UNIHIKER - IoT Python Programming Single Board Computer with Touchscreen","href":"/dfrobot/products/unihiker-iot-python-programming-single-board-computer-with-touchscreen1?ref=project-9cc2b1","type":"part","location":"things"},"clickOpts":{"delayRedirect":true}}' href="https://www.hackster.io/dfrobot/products/unihiker-iot-python-programming-single-board-computer-with-touchscreen1?ref=project-9cc2b1">
           DFRobot UNIHIKER - IoT Python Programming Single Board Computer with Touchscreen
          </a>
         </td>
        </tr>
        <tr>
         <td class="part-img">
          <img alt="Blues Notecarrier A" src="3.jpg" srcset="https://hackster.imgix.net/uploads/attachments/1431807/CARR_AL_2.0_front_1800x1800.jpg?auto=compress%2Cformat&amp;w=96&amp;h=96&amp;fit=fill&amp;bg=ffffff 2x, https://hackster.imgix.net/uploads/attachments/1431807/CARR_AL_2.0_front_1800x1800.jpg?auto=compress%2Cformat&amp;w=48&amp;h=48&amp;fit=fill&amp;bg=ffffff"/>
         </td>
         <td class="hckui__typography__bodyL">
          <a class="hckui__typography__linkBlue" data-ha='{"eventName":"Clicked link","customProps":{"value":"Blues Notecarrier A","href":"/blues-wireless/products/blues-notecarrier-a?ref=project-9cc2b1","type":"part","location":"things"},"clickOpts":{"delayRedirect":true}}' href="https://www.hackster.io/blues-wireless/products/blues-notecarrier-a?ref=project-9cc2b1">
           Blues Notecarrier A
          </a>
         </td>
        </tr>
        <tr>
         <td class="part-img">
          <img alt="Blues Notecard (Cellular)" src="4.jpg" srcset="https://hackster.imgix.net/uploads/attachments/1708752/wbnan-front_tdId2xJ1V4.png?auto=compress%2Cformat&amp;w=96&amp;h=96&amp;fit=fill&amp;bg=ffffff 2x, https://hackster.imgix.net/uploads/attachments/1708752/wbnan-front_tdId2xJ1V4.png?auto=compress%2Cformat&amp;w=48&amp;h=48&amp;fit=fill&amp;bg=ffffff"/>
         </td>
         <td class="hckui__typography__bodyL">
          <a class="hckui__typography__linkBlue" data-ha='{"eventName":"Clicked link","customProps":{"value":"Blues Notecard (Cellular)","href":"/blues-wireless/products/blues-notecard-cellular?ref=project-9cc2b1","type":"part","location":"things"},"clickOpts":{"delayRedirect":true}}' href="https://www.hackster.io/blues-wireless/products/blues-notecard-cellular?ref=project-9cc2b1">
           Blues Notecard (Cellular)
          </a>
         </td>
        </tr>
        <tr>
         <td class="part-img">
          <img alt="Blues Notecard (Wi-Fi)" src="5.jpg" srcset="https://hackster.imgix.net/uploads/attachments/1636404/esp-front_ntOcWJneD1.png?auto=compress%2Cformat&amp;w=96&amp;h=96&amp;fit=fill&amp;bg=ffffff 2x, https://hackster.imgix.net/uploads/attachments/1636404/esp-front_ntOcWJneD1.png?auto=compress%2Cformat&amp;w=48&amp;h=48&amp;fit=fill&amp;bg=ffffff"/>
         </td>
         <td class="hckui__typography__bodyL">
          <a class="hckui__typography__linkBlue" data-ha='{"eventName":"Clicked link","customProps":{"value":"Blues Notecard (Wi-Fi)","href":"/blues-wireless/products/blues-notecard-wi-fi?ref=project-9cc2b1","type":"part","location":"things"},"clickOpts":{"delayRedirect":true}}' href="https://www.hackster.io/blues-wireless/products/blues-notecard-wi-fi?ref=project-9cc2b1">
           Blues Notecard (Wi-Fi)
          </a>
         </td>
        </tr>
        <tr>
         <td class="part-img">
          <img alt="MAX32620FTHR" src="6.jpg" srcset="https://hackster.imgix.net/uploads/attachments/560756/max32620fthr__2__9QnGHOwXt8.png?auto=compress%2Cformat&amp;w=96&amp;h=96&amp;fit=fill&amp;bg=ffffff 2x, https://hackster.imgix.net/uploads/attachments/560756/max32620fthr__2__9QnGHOwXt8.png?auto=compress%2Cformat&amp;w=48&amp;h=48&amp;fit=fill&amp;bg=ffffff"/>
         </td>
         <td class="hckui__typography__bodyL">
          <a class="hckui__typography__linkBlue" data-ha='{"eventName":"Clicked link","customProps":{"value":"Maxim Integrated MAX32620FTHR","href":"/maxim-integrated/products/max32620fthr?ref=project-9cc2b1","type":"part","location":"things"},"clickOpts":{"delayRedirect":true}}' href="https://www.hackster.io/maxim-integrated/products/max32620fthr?ref=project-9cc2b1">
           Maxim Integrated MAX32620FTHR
          </a>
         </td>
        </tr>
        <tr>
         <td class="part-img">
          <img alt="Grove Vision AI Module V2" src="7.jpg" srcset="https://hackster.imgix.net/uploads/attachments/1671503/1-101021112-grove-vision-ai-module-v2-45font_LxXbpFHMhY.jpg?auto=compress%2Cformat&amp;w=96&amp;h=96&amp;fit=fill&amp;bg=ffffff 2x, https://hackster.imgix.net/uploads/attachments/1671503/1-101021112-grove-vision-ai-module-v2-45font_LxXbpFHMhY.jpg?auto=compress%2Cformat&amp;w=48&amp;h=48&amp;fit=fill&amp;bg=ffffff"/>
         </td>
         <td class="hckui__typography__bodyL">
          <a class="hckui__typography__linkBlue" data-ha='{"eventName":"Clicked link","customProps":{"value":"Seeed Studio Grove Vision AI Module V2","href":"/seeed/products/grove-vision-ai-module-v2?ref=project-9cc2b1","type":"part","location":"things"},"clickOpts":{"delayRedirect":true}}' href="https://www.hackster.io/seeed/products/grove-vision-ai-module-v2?ref=project-9cc2b1">
           Seeed Studio Grove Vision AI Module V2
          </a>
         </td>
        </tr>
        <tr>
         <td class="part-img">
          <img alt="Raspberry Pi Camera Module" src="8.jpg" srcset="https://hackster.imgix.net/uploads/attachments/1466496/pi_camero_2A0Tl73V99.png?auto=compress%2Cformat&amp;w=96&amp;h=96&amp;fit=fill&amp;bg=ffffff 2x, https://hackster.imgix.net/uploads/attachments/1466496/pi_camero_2A0Tl73V99.png?auto=compress%2Cformat&amp;w=48&amp;h=48&amp;fit=fill&amp;bg=ffffff"/>
         </td>
         <td class="hckui__typography__bodyL">
          <a class="hckui__typography__linkBlue" data-ha='{"eventName":"Clicked link","customProps":{"value":"Seeed Studio Raspberry Pi Camera Module","href":"/seeed/products/raspberry-pi-camera-module?ref=project-9cc2b1","type":"part","location":"things"},"clickOpts":{"delayRedirect":true}}' href="https://www.hackster.io/seeed/products/raspberry-pi-camera-module?ref=project-9cc2b1">
           Seeed Studio Raspberry Pi Camera Module
          </a>
         </td>
        </tr>
       </tr>
      </tbody>
     </table>
    </div>
   </div>
  </section>
  <div class="project-section-break">
  </div>
  <section id="story">
   <div class="project-section-title">
    <h2 class="hckui__typography__h2 title-with-anchor">
     <span>
      Story
     </span>
    </h2>
   </div>
   <div class="project-story collapsible-section collapsed hljs-active hljs-monokai" itemprop="text">
    <h3 class="hckui__typography__h3 title-with-anchor" id="toc-introduction-0">
     <p>
      <p class="hckui__typography__bodyL">
      </p>
     </p>
     <span>
      Introduction
     </span>
    </h3>
    <p class="hckui__typography__bodyL">
     <span>
      This document details a project proposal for the Build2gether 2.0 challenge focused on assisting individuals with mobility impairments. The project aims to create a device that guides wheelchair users in unfamiliar accommodations  to their desired location, avoiding obstacles and tight spaces. A hotel
     </span>
     <strong>
      Smart Wheelchair Navigation system
     </strong>
     <span>
      that uses sensors and GPS to map out a safe and efficient route for wheelchair users and an
     </span>
     <strong>
      Obstacle detection system
     </strong>
     <span>
      with Sensors installed in hotel rooms to detect obstacles and alert users, helping them navigate safely.
     </span>
    </p>
    <p class="hckui__typography__bodyL">
     <span>
      The device has two modes of operation: Learn Mode, where it maps the environment, and Run Mode, where it provides audio feedback to guide the user based on the learned map. The project builds upon a previous project
     </span>
     <a class="hckui__typography__linkBlue" data-ha='{"eventName":"Clicked link","customProps":{"value":"B2G 1.0 -- TRAVELING for people with mobility impairments","href":"https://www.hackster.io/skruglewicz/b2g-2-travelling-for-people-with-mobility-impairments-a8baf1#overview","type":"story","location":"story"},"clickOpts":{"delayRedirect":true}}' href="https://www.hackster.io/skruglewicz/b2g-2-travelling-for-people-with-mobility-impairments-a8baf1#overview" rel="nofollow">
      B2G 1.0 -- TRAVELING for people with mobility impairments
     </a>
     <span>
      and outlines potential use of hardware from the SUPERBOX.I will refer to this project as B2G1.0 from the remainder of this document..
     </span>
    </p>
    <h3 class="hckui__typography__h3 title-with-anchor" id="toc-the-superbox-contents-1">
     <p>
      <p class="hckui__typography__bodyL">
      </p>
     </p>
     <span>
      The SUPERBOX Contents
     </span>
    </h3>
    <p class="hckui__typography__bodyL">
     The superbox contains plenty of hardware to aid in the implementation of my idea.
    </p>
    <p class="hckui__typography__bodyL">
     The superbox contains:
    </p>
    <div class="carousel-images">
     <img class="carousel-image" src="0.jpg"/>
    </div>
    <p class="hckui__typography__bodyL">
     However, I need to figure out what hardware to choose. I only need certain hardware components.
    </p>
    <h3 class="hckui__typography__h3 title-with-anchor" id="toc-private-feedback-from-contest-masters-2">
     <p>
      <p class="hckui__typography__bodyL">
      </p>
     </p>
     <span>
      PRIVATE FEEDBACK FROM CONTEST MASTERS
     </span>
    </h3>
    <p class="hckui__typography__bodyL">
     For this contest challenge the organizers used Contest Masters to provide tailored feedback to my idea proposal survey that I filled out at the beginning of the contest..I received the feedback via an email.FEEDBACK SUMMARY report from the Contest Masters.
    </p>
    <p class="hckui__typography__bodyL">
     My initial proposal for this project was a continuation of my B2G 1.0 project, which involved developing a device to detect walls and obstacles for individuals with mobility impairments.
    </p>
    <p class="hckui__typography__bodyL">
     The feedback received from the Contest Masters placed emphasis on the necessity to prioritize wheelchair maneuverability, such as the incorporation of devices capable of facilitating wheelchair pivoting or sliding over obstacles, particularly in confined spaces. However, in light of my personal limited mechanical expertise, the focus will shift toward guiding wheelchair users to their intended destination while avoiding obstacles and constricted areas. Accordingly, the primary objectives have been revised to reflect this adjustment, and only the two operational modes, namely Learn Mode and Run Mode, will be retained. This prompted me to undertake a reassessment of my original concept and engage in introspective contemplation. Through this process of inquiry, a novel pathway emerged, imbued with fresh and fundamental objectives.
    </p>
    <p class="hckui__typography__bodyL">
     The main objectives of the project now are:
    </p>
    <ul class="hckui__typography__bodyL">
     <li>
      Guiding wheelchair users to their desired location: The device will help users navigate unfamiliar spaces by providing audio feedback and directions.
     </li>
     <li>
      Avoiding obstacles and tight spaces:  The device will map the environment and identify potential obstacles, allowing users to plan a safe and efficient route.
     </li>
     <li>
      Improving wheelchair maneuverability: While not directly manipulating the wheelchair, the device will focus on guiding users to avoid obstacles and tight spaces, indirectly improving maneuverability.
     </li>
    </ul>
    <h3 class="hckui__typography__h3 title-with-anchor" id="toc-specification-3">
     <p>
      <p class="hckui__typography__bodyL">
      </p>
     </p>
     <span>
      Specification
     </span>
    </h3>
    <p class="hckui__typography__bodyL">
     These functional and technical specifications serve as a blueprint for the development and evaluation of the proposed solution, ensuring that it meets the desired criteria for practicality, effectiveness, and user benefit. The specification includes some points from the B2G1.0 project.
    </p>
    <h3 class="hckui__typography__h3 title-with-anchor" id="toc-research-mobility-in-unfamiliar-accommodations-4">
     <p>
      <p class="hckui__typography__bodyL">
      </p>
     </p>
     <span>
      Research Mobility in Unfamiliar Accommodations
     </span>
    </h3>
    <p class="hckui__typography__bodyL">
     I wanted to dig deeper into the problem by addressing some questions on implementing a mobility device for wheelchairs.
    </p>
    <p class="hckui__typography__bodyL">
     <strong>
      What are some potential challenges in implementing obstacle detection systems in hotel rooms and how can these challenges be addressed?
     </strong>
    </p>
    <ul class="hckui__typography__bodyL">
     <li>
      Implementing obstacle detection systems in hotel rooms presents several potential challenges:
     </li>
     <li>
      Cost: The installation and maintenance of sensors and software can be expensive, potentially increasing the cost of hotel stays.
     </li>
     <li>
      Privacy: Guests may be uncomfortable with the idea of sensors monitoring their movements in a private space.
     </li>
     <li>
      Reliability: The system needs to be highly reliable to avoid false alarms or missed obstacles, which could lead to accidents.
     </li>
     <li>
      Complexity: Integrating the system with existing hotel infrastructure and ensuring compatibility with different room layouts and furniture arrangements can be complex.
     </li>
     <li>
      Aesthetics:  The sensors and other components need to be discreet and not detract from the overall aesthetic of the room.
     </li>
    </ul>
    <p class="hckui__typography__bodyL">
     These challenges can be addressed through careful design and planning:
    </p>
    <ul class="hckui__typography__bodyL">
     <li>
      Cost-effective solutions: Explore the use of affordable sensor technologies and open-source software to minimize costs.
     </li>
     <li>
      Privacy-preserving design: Implement data anonymization and allow guests to opt out of the system if they prefer.
     </li>
     <li>
      Rigorous testing: Conduct thorough testing in various room configurations to ensure the system's reliability.
     </li>
     <li>
      Modular design: Develop a modular system that can be easily adapted to different room layouts and furniture arrangements.
     </li>
     <li>
      Aesthetic integration: Design sensors and components that blend seamlessly with the room's décor.
     </li>
    </ul>
    <p class="hckui__typography__bodyL">
     <strong>
      Modular design addresses the challenge of varying room layouts and furniture arrangements by allowing for flexibility and customization. Here's how:
     </strong>
    </p>
    <ul class="hckui__typography__bodyL">
     <li>
      Reconfiguration: Modular systems are composed of individual components or modules that can be easily rearranged, added, or removed. This means the system can be adapted to fit different room sizes, shapes, and furniture placements without major overhauls.
     </li>
     <li>
      Scalability:  If a hotel room has a unique layout or requires additional coverage, more modules can simply be added to the system. This scalability ensures that the obstacle detection system can effectively cover the entire space, regardless of its configuration.
     </li>
     <li>
      Customization: Modular systems often offer a variety of sensor types and configurations. This allows hotels to choose the most appropriate sensors for their specific needs and room layouts. For example, some areas might require more sensitive or specialized sensors than others.
     </li>
     <li>
      Ease of Installation:  Modular components are typically designed for easy installation, often with plug-and-play functionality. This simplifies the setup process and reduces the need for complex wiring or calibration.
     </li>
    </ul>
    <p class="hckui__typography__bodyL">
     By offering this flexibility, a modular design ensures that obstacle detection systems can be effectively deployed in a wide range of hotel rooms, regardless of their individual characteristics.
    </p>
    <p class="hckui__typography__bodyL">
     <strong>
      Here are some specific examples of modular components that can be used to create a flexible obstacle detection system in hotel rooms:
     </strong>
    </p>
    <p class="hckui__typography__bodyL">
     <em>
      Sensor Modules:
     </em>
    </p>
    <ul class="hckui__typography__bodyL">
     <li>
      Ultrasonic distance sensors: These sensors emit sound waves and measure the time it takes for the waves to bounce back after hitting an object. They are good for detecting large obstacles but may have limited sensitivity for smaller objects.
     </li>
     <li>
      Infrared sensors: These sensors emit infrared light and detect the reflected light from objects. They are effective for detecting obstacles within a shorter range and can be more sensitive to smaller objects.
     </li>
     <li>
      LiDAR sensors: These sensors use laser light to create a 3D map of the environment. They offer high accuracy and can detect obstacles with varying shapes and sizes.
     </li>
     <li>
      Camera modules: Cameras can be used to visually detect obstacles and identify their type. However, they may require more processing power and raise privacy concerns.
     </li>
    </ul>
    <p class="hckui__typography__bodyL">
     <em>
      Processing Modules:
     </em>
    </p>
    <ul class="hckui__typography__bodyL">
     <li>
      Microcontrollers: These small computers can process sensor data and make decisions about obstacle detection. They can be programmed with different algorithms to suit the specific needs of the system.
     </li>
     <li>
      Single-board computers: More powerful than microcontrollers, single-board computers like Raspberry Pi can handle more complex processing tasks, such as image recognition or machine learning.
     </li>
    </ul>
    <p class="hckui__typography__bodyL">
     <em>
      Communication Modules:
     </em>
    </p>
    <ul class="hckui__typography__bodyL">
     <li>
      Wireless modules: These modules allow the system to communicate with other devices, such as a smartphone or a central control unit. They can use technologies like Wi-Fi, Bluetooth, or Zigbee.
     </li>
     <li>
      Wired modules: For more reliable and secure communication, wired modules can be used to connect the system to a power source or a central control unit.
     </li>
    </ul>
    <p class="hckui__typography__bodyL">
     <em>
      User Interface Modules:
     </em>
    </p>
    <ul class="hckui__typography__bodyL">
     <li>
      Audio output modules: These modules can produce sound alerts to warn users about obstacles.
     </li>
     <li>
      Haptic feedback modules: These modules provide tactile feedback, such as vibrations, to alert users about obstacles.
     </li>
     <li>
      Visual display modules: These modules can display information about detected obstacles, such as their distance and location.
     </li>
    </ul>
    <p class="hckui__typography__bodyL">
     By combining these modular components in different configurations, a flexible and adaptable obstacle detection system can be created to suit the specific needs of different hotel rooms and users.
    </p>
    <p class="hckui__typography__bodyL">
     <strong>
      A modular obstacle detection system for hotel rooms could incorporate several additional features and functionalities to enhance its usability and effectiveness:
     </strong>
    </p>
    <ul class="hckui__typography__bodyL">
     <li>
      Object Identification: The system could not only detect obstacles but also identify their type (e.g., furniture, luggage, or pets). This information could be used to provide more specific alerts or guidance to the user. For instance, if the system detects a pet, it could send a message to the user's smartphone with a reminder to keep the pet on a leash.
     </li>
     <li>
      Height Detection: In addition to horizontal obstacles, the system could also detect obstacles at different heights, such as low-hanging objects or raised thresholds. This would help prevent head injuries and improve overall safety. For example, the system could alert users to a low-hanging light fixture or a raised threshold in the bathroom.
     </li>
     <li>
      User Preferences: The system could be customizable to accommodate individual user preferences. For example, users could adjust the sensitivity of the sensors, the types of alerts, or the areas of the room to be monitored. This would allow users to tailor the system to their specific needs and preferences.
     </li>
     <li>
      Integration with Smart Devices: The system could be integrated with other smart devices in the room, such as voice assistants or smartphones. This would allow users to receive alerts through their preferred channels and control the system using voice commands or a mobile app. For instance, users could ask their voice assistant to turn on the obstacle detection system or check for obstacles in a specific area of the room.
     </li>
     <li>
      Data Logging and Analysis: The system could collect data on obstacle encounters and user behavior. This data could be analyzed to identify patterns and areas for improvement, helping to refine the system's performance and user experience. For example, the data could be used to identify areas of the room where obstacles are frequently encountered, allowing hotel staff to address these issues.
     </li>
     <li>
      Remote Monitoring and Support: Hotel staff could remotely monitor the system's performance and provide technical support if needed. This would ensure that the system remains operational and that any issues are addressed promptly. Remote monitoring would also allow hotel staff to proactively identify and resolve potential problems before they impact guests.
     </li>
    </ul>
    <p class="hckui__typography__bodyL">
     <strong>
      How could the system leverage artificial intelligence (AI) to improve its obstacle detection capabilities and provide personalized recommendations to users?
     </strong>
    </p>
    <p class="hckui__typography__bodyL">
     AI could be used to significantly enhance the capabilities of the obstacle detection system in several ways:
    </p>
    <ul class="hckui__typography__bodyL">
     <li>
      Improved accuracy and adaptability: AI algorithms, particularly machine learning models, can be trained to recognize and classify obstacles with high accuracy. The system could learn to distinguish between different types of obstacles, such as furniture, luggage, or even people, and adapt to changes in the environment over time.
     </li>
     <li>
      Predictive obstacle avoidance: By analyzing sensor data in real-time, AI could anticipate the user's trajectory and predict potential collisions before they occur. This would allow the system to provide early warnings or suggest alternative routes to avoid obstacles.
     </li>
     <li>
      Personalized user experience: AI could learn from the user's behavior and preferences, tailoring its alerts and recommendations accordingly. For example, it could prioritize alerts for obstacles that are most relevant to the user's specific needs or mobility level.
     </li>
     <li>
      Continuous learning and improvement: The system could collect data on obstacle encounters and user interactions, using AI to analyze this data and identify areas for improvement. This would enable the system to continuously refine its algorithms and become more effective over time.
     </li>
    </ul>
    <p class="hckui__typography__bodyL">
     Here are some specific examples of how AI could be implemented:
    </p>
    <ul class="hckui__typography__bodyL">
     <li>
      Object recognition: A convolutional neural network (CNN) could be trained to identify different types of obstacles from camera or LiDAR data.
     </li>
     <li>
      Trajectory prediction: A recurrent neural network (RNN) could be used to model the user's movement patterns and predict their future trajectory.
     </li>
     <li>
      Personalized recommendations: A reinforcement learning algorithm could be used to learn the user's preferences and provide personalized recommendations for obstacle avoidance.
     </li>
    </ul>
    <p class="hckui__typography__bodyL">
     By leveraging AI, the obstacle detection system could become more intelligent, adaptable, and user-friendly, significantly improving the safety and independence of people with mobility impairments
    </p>
    <p class="hckui__typography__bodyL">
     <strong>
      How could AI be used to integrate the obstacle detection system with other assistive technologies, such as smart wheelchairs or walking aids?
     </strong>
    </p>
    <p class="hckui__typography__bodyL">
     AI could play a crucial role in integrating the obstacle detection system with other assistive technologies, creating a more comprehensive and seamless experience for users with mobility impairments. Here's how:
    </p>
    <ul class="hckui__typography__bodyL">
     <li>
      Data Fusion and Sensor Integration: AI algorithms could combine data from the obstacle detection system with data from other sensors on the wheelchair or walking aid, such as gyroscopes, accelerometers, and wheel encoders. This would create a more complete picture of the user's environment and movements, allowing for more accurate and timely obstacle avoidance maneuvers.
     </li>
     <li>
      Adaptive Control Strategies: AI could analyze the combined sensor data to develop adaptive control strategies for the wheelchair or walking aid. For example, it could adjust the speed, direction, or braking of the device to avoid obstacles while maintaining stability and comfort for the user.
     </li>
     <li>
      Personalized Assistance: AI could learn the user's individual needs and preferences, tailoring the assistive technology's behavior accordingly. For instance, it could prioritize obstacle avoidance in certain areas of the room or adjust the level of assistance based on the user's fatigue or confidence level.
     </li>
     <li>
      Proactive Guidance: By predicting the user's intended path and potential obstacles, AI could provide proactive guidance and suggestions. This could include suggesting alternative routes, highlighting potential hazards, or offering step-by-step navigation instructions.
     </li>
     <li>
      Seamless Communication: AI could facilitate communication between the user and the assistive technology through natural language processing or other intuitive interfaces. This would allow users to easily control the device, provide feedback, and receive personalized assistance.
     </li>
    </ul>
    <p class="hckui__typography__bodyL">
     By integrating AI into the obstacle detection system and other assistive technologies, a more intelligent and responsive ecosystem of support could be created for people with mobility impairments, enhancing their safety, independence, and overall quality of life.
    </p>
    <h3 class="hckui__typography__h3 title-with-anchor" id="toc-research-conclusions-5">
     <p>
      <p class="hckui__typography__bodyL">
      </p>
     </p>
     <span>
      RESEARCH CONCLUSIONS
     </span>
    </h3>
    <p class="hckui__typography__bodyL">
     This project objective is to develop a device that facilitates the navigation of wheelchair users within unfamiliar environments, enabling them to reach their desired destinations while circumventing obstacles and constricted spaces. During the research phase, mentioned in the previous section, I have reached the following conclusions:
    </p>
    <p class="hckui__typography__bodyL">
     <em>
      The device will have two modes of operation:
     </em>
    </p>
    <ul class="hckui__typography__bodyL">
     <li>
      Learn Mode: In this mode, the wheelchair will map the environment and create a detailed map.
     </li>
     <li>
      Run Mode: In this mode, the wheelchair will use the map it created in Learn mode to provide audio feedback to the user, guiding them through the environment.
     </li>
    </ul>
    <p class="hckui__typography__bodyL">
     <em>
      Additional Features:
     </em>
    </p>
    <ul class="hckui__typography__bodyL">
     <li>
      Route Planning: In RUN mode, the wheelchair can use its map to plan the best route from point A to point B.
     </li>
     <li>
      Obstacle Detection: If the wheelchair detects an obstacle in its path, it will re-route and send a message to the user informing them of the obstacle.
     </li>
     <li>
      Size of Wheelchair: The wheelchair can take into account its own size when planning routes, ensuring that it can safely navigate through tight spaces.
     </li>
    </ul>
    <p class="hckui__typography__bodyL">
     <em>
      Use Camera and AI mapping:
     </em>
    </p>
    <ul class="hckui__typography__bodyL">
     <li>
      In LEARN mode, the wheelchair would use its camera to capture images of its surroundings. These images would then be processed by an AI algorithm to create a map of the environment. This map would include information about the location of objects, obstacles, and other relevant features.
     </li>
     <li>
      In RUN mode, the wheelchair would use the map created in LEARN mode to navigate its environment. The wheelchair would use the camera to track its position relative to the map and would use this information to avoid obstacles and reach its destination.
     </li>
    </ul>
    <p class="hckui__typography__bodyL">
     <em>
      Use other sensors on the wheelchair (Accelerometers and Gyroscopes or LDAR)) to aid in Object detection:
     </em>
    </p>
    <ul class="hckui__typography__bodyL">
     <li>
      Accelerometers and gyroscopes can be used to measure the wheelchair's movement and orientation. This information can be used to detect objects that are moving or that are in the wheelchair's path.
     </li>
     <li>
      LDAR (Light Detection and Ranging) is a sensor that can be used to measure the distance between the wheelchair and objects in its environment. This information can be used to create a more detailed map of the environment and to detect objects that are not visible to the camera.
     </li>
     <li>
      By combining the information from the camera, accelerometers, gyroscopes, and LDAR, the wheelchair can create a more comprehensive understanding of its environment and navigate more safely and efficiently.
     </li>
    </ul>
    <p class="hckui__typography__bodyL">
     <em>
      Use the DFRobot UniHiker from the SUPERBOX:
     </em>
    </p>
    <ul class="hckui__typography__bodyL">
     <li>
      Use it as the center of the system:
     </li>
     <li>
      The UniHiker can serve as the central hub of your system, connecting all of the different components and devices.
     </li>
     <li>
      It provides a stable and reliable platform for running your applications and software.
     </li>
     <li>
      The UniHiker's powerful processor and ample memory ensure that it can handle even the most demanding tasks.
     </li>
     <li>
      Use the screen to display the interface to the system:
     </li>
     <li>
      The UniHiker's built-in screen can be used to display the user interface for your system.
     </li>
     <li>
      This allows users to interact with the system and control its various functions.
     </li>
     <li>
      The screen can also be used to display information and data from the system's sensors and devices.
     </li>
     <li>
      Attach the camera module and audio devices to it:
     </li>
     <li>
      The UniHiker can be equipped with a variety of camera modules and audio devices.
     </li>
     <li>
      These devices can be used to capture images and videos, as well as record and playback audio.
     </li>
     <li>
      The UniHiker's built-in microphone and speaker can also be used for audio input and output.
     </li>
    </ul>
    <p class="hckui__typography__bodyL">
     Additional tips for using the UniHiker:
    </p>
    <ul class="hckui__typography__bodyL">
     <li>
      Use the UniHiker's built-in Wi-Fi and Bluetooth connectivity to connect to other devices and networks.
     </li>
     <li>
      Use the UniHiker's GPIO pins to connect to external sensors and devices.
     </li>
     <li>
      Use the UniHiker's onboard sensors, such as the accelerometer and gyroscope, to detect motion and orientation.
     </li>
     <li>
      Use the UniHiker's built-in battery to power the system for extended periods of time.
     </li>
    </ul>
    <p class="hckui__typography__bodyL">
     <strong>
      The project will incorporate AI to improve obstacle detection and provide personalized recommendations and will explore integration with other assistive technologies. Specific examples include:
     </strong>
    </p>
    <ul class="hckui__typography__bodyL">
     <li>
      Object recognition using convolutional neural networks (CNNs) to identify obstacles from camera or LiDAR data.
     </li>
     <li>
      Trajectory prediction using recurrent neural networks (RNNs) to model user movement patterns and predict future trajectories.
     </li>
     <li>
      Personalized recommendations using reinforcement learning algorithms to learn user preferences and provide customized obstacle avoidance suggestions.
     </li>
    </ul>
    <p class="hckui__typography__bodyL">
     <strong>
      AI can also be utilized to enhance the obstacle detection system and other assistive technologies by:
     </strong>
    </p>
    <ul class="hckui__typography__bodyL">
     <li>
      Integrating data from various sensors, developing adaptive control strategies, offering personalized assistance, providing proactive guidance, and enabling seamless communication. This integration allows for a more comprehensive and tailored assistive ecosystem, improving the safety, independence, and quality of life for individuals with mobility impairments.
     </li>
    </ul>
    <p class="hckui__typography__bodyL">
     <strong>
      Use a Modular design approach
     </strong>
    </p>
    <ul class="hckui__typography__bodyL">
     <li>
      Modular design is a design strategy that splits a system into smaller parts called modules, which can be independently developed, modified, replaced, or exchanged.
     </li>
     <li>
      A modular obstacle detection system for hotel rooms can be enhanced with various features and functionalities to improve its usability and effectiveness. These features include object identification, height detection, user preferences, integration with smart devices, data logging and analysis, and remote monitoring and support. By incorporating these features, the system can provide more specific alerts, prevent injuries, accommodate individual user needs, and allow for remote monitoring and support, ultimately enhancing the guest experience and improving hotel operations.
     </li>
    </ul>
    <p class="hckui__typography__bodyL">
     <strong>
      Be aware of Potential Challenges
     </strong>
    </p>
    <ul class="hckui__typography__bodyL">
     <li>
      Potential challenges in implementing such a system include cost, privacy concerns, reliability, complexity, and aesthetics.
     </li>
    </ul>
    <p class="hckui__typography__bodyL">
     <strong>
      Functional and technical specifications are critical components in the software development process, serving distinct but complementary purposes.
     </strong>
    </p>
    <p class="hckui__typography__bodyL">
     The functional and technical specifications serve as a blueprint for the development and evaluation of the proposed solution, ensuring that it meets the desired criteria for practicality, effectiveness, and user benefit.
    </p>
    <ul class="hckui__typography__bodyL">
     <li>
      A functional specification outlines sensor requirements, operating modes, audio feedback, user interface, and power management strategies.
     </li>
     <li>
      A technical specification details hardware components, software design, communication protocols, performance metrics, and testing and validation procedures.
     </li>
    </ul>
    <h3 class="hckui__typography__h3 title-with-anchor" id="toc-specification-6">
     <p>
      <p class="hckui__typography__bodyL">
      </p>
     </p>
     <span>
      Specification
     </span>
    </h3>
    <p class="hckui__typography__bodyL">
     These functional and technical specifications serve as a blueprint for the development and evaluation of the proposed solution, ensuring that it meets the desired criteria for practicality, effectiveness, and user benefit. The specification includes some points from the B2G1.0 project.
    </p>
    <h3 class="hckui__typography__h3 title-with-anchor" id="toc-functional-specification-7">
     <p>
      <p class="hckui__typography__bodyL">
      </p>
     </p>
     <span>
      Functional Specification
     </span>
    </h3>
    <p class="hckui__typography__bodyL">
     Here's a functional specification based on the hardware available in the Superbox:
    </p>
    <p class="hckui__typography__bodyL">
     <strong>
      Core Components:
     </strong>
    </p>
    <p class="hckui__typography__bodyL">
     <em>
      <span>
       Microcontroller:
      </span>
     </em>
     <strong>
      Swan v3
     </strong>
     <span>
      (STM32L4+): Offers a good balance of power, memory, and peripherals.
     </span>
    </p>
    <p class="hckui__typography__bodyL">
     <em>
      <span>
       Wireless Communication
      </span>
     </em>
     <span>
      :
     </span>
     <strong>
      Blues Notecard WiFi
     </strong>
     <span>
      : Provides necessary connectivity for data logging and potential future features.
     </span>
    </p>
    <p class="hckui__typography__bodyL">
     <em>
      <span>
       Single  Board Computer:
      </span>
     </em>
     <span>
     </span>
     <strong>
      DFRobot UNIHIKER:
     </strong>
     <span>
      Is utilized as a Single Board Computer, and is the heart of the system
     </span>
    </p>
    <p class="hckui__typography__bodyL">
     <em>
      <span>
       Camera Module:
      </span>
     </em>
     <strong>
      Seeed Studio Grove - Vision AI Module
     </strong>
     <span>
      : Compact and offers pre-trained models for object detection, potentially simplifying development.
     </span>
     <em>
      <span>
      </span>
     </em>
     <span>
      The OV7670 Camera will be used to capture images of the environment.
     </span>
    </p>
    <p class="hckui__typography__bodyL">
     <em>
      <span>
       MAX32666FTHR Board
      </span>
     </em>
     <strong>
      Accelerometer and Gyroscope:
     </strong>
     <span>
      This sensor on the board, will be used to measure the wheelchair's acceleration and angular velocity, aiding in movement detection and orientation.
     </span>
    </p>
    <p class="hckui__typography__bodyL">
     <em>
      <span>
       Power Supply:
      </span>
     </em>
     <strong>
     </strong>
     <em>
      <span>
      </span>
     </em>
     <strong>
      Battery
     </strong>
     <em>
      <span>
       :
      </span>
     </em>
     <span>
      Utilize the Notecarrier-A's battery holder for a rechargeable LiPo battery. This provides a compact and integrated power solution.
     </span>
    </p>
    <p class="hckui__typography__bodyL">
     <strong>
      <span>
       User Interface
      </span>
     </strong>
     <strong>
      :
     </strong>
     <span>
      use the
     </span>
     <strong>
      DFRobot UNIHIKER
     </strong>
     <span>
      buttons and displa for mode selection, configuration, and user feedback.
     </span>
    </p>
    <p class="hckui__typography__bodyL">
     <strong>
      Assembly:
     </strong>
    </p>
    <p class="hckui__typography__bodyL">
     <em>
      <span>
       Mount components:
      </span>
     </em>
     <span>
      Securely attach the Swan v3, Notecarrier-A, MAX32666FTHR within an enclosure using appropriate mounting hardware or adhesive.
     </span>
    </p>
    <p class="hckui__typography__bodyL">
     <em>
      <span>
       Connect camera:
      </span>
     </em>
     <span>
      Connect the Vision AI Module to the Swan v3 using the Grove connector.
     </span>
    </p>
    <p class="hckui__typography__bodyL">
     <em>
      <span>
       Wiring:
      </span>
     </em>
     <span>
      Carefully connect the Swan v3's and the  MAX32666FTHR to the Unihiker GPIO pins, ensuring correct polarity.
     </span>
    </p>
    <p class="hckui__typography__bodyL">
     <em>
      <span>
       Battery:
      </span>
     </em>
     <span>
      Insert the rechargeable LiPo battery into the Notecarrier-A's battery holder.
     </span>
    </p>
    <p class="hckui__typography__bodyL">
     Enclosure: Seal the enclosure, ensuring all openings are properly closed and waterproof.
    </p>
    <p class="hckui__typography__bodyL">
     <strong>
      Operating Modes:
     </strong>
    </p>
    <p class="hckui__typography__bodyL">
     <em>
      <span>
       Learn Mode:
      </span>
     </em>
     <span>
      In this mode, the wheelchair will move through the environment, capturing images and sensor data. The system will process this data to create a map of the environment.
     </span>
    </p>
    <p class="hckui__typography__bodyL">
     <em>
      <span>
       Run Mode:
      </span>
     </em>
     <span>
      In this mode, the wheelchair will use the map created in Learn Mode to navigate to a desired location, avoiding obstacles and tight spaces.
     </span>
    </p>
    <p class="hckui__typography__bodyL">
     <strong>
      Audio Feedback:
     </strong>
    </p>
    <p class="hckui__typography__bodyL">
     <strong>
      <em>
       <span>
        Audio Module:
       </span>
      </em>
     </strong>
     <em>
      <span>
      </span>
     </em>
     <span>
      The system will use the onboard speaker on the DFRobot Unihiker to provide audio feedback to the user. This will include:
     </span>
    </p>
    <p class="hckui__typography__bodyL">
     <span>
      Directional cues:
     </span>
     <em>
     </em>
     <span>
      Indicating turns (e.g., "turn left," "turn right").
     </span>
    </p>
    <p class="hckui__typography__bodyL">
     Obstacle warnings: Alerting the user to obstacles in their path (e.g., "obstacle ahead").
    </p>
    <p class="hckui__typography__bodyL">
     Confirmation sounds: Confirming user inputs or successful actions (e.g., "destination set").
    </p>
    <p class="hckui__typography__bodyL">
     <strong>
      User Interface:
     </strong>
    </p>
    <p class="hckui__typography__bodyL">
     <em>
      <span>
       LCD Screen:
      </span>
     </em>
     <span>
      The system will utilize the Unihiker's LCD screen to display a basic user interface. This interface will allow the user to:
     </span>
    </p>
    <p class="hckui__typography__bodyL">
     Select mode: Switch between Learn Mode and Run Mode.
    </p>
    <p class="hckui__typography__bodyL">
     Set destination: Input the desired destination within the mapped environment.
    </p>
    <p class="hckui__typography__bodyL">
     View map: Display a simplified representation of the mapped environment.
    </p>
    <p class="hckui__typography__bodyL">
     Adjust settings: Modify system parameters like sensitivity or volume.
    </p>
    <p class="hckui__typography__bodyL">
     <strong>
      Power Management:
     </strong>
    </p>
    <p class="hckui__typography__bodyL">
     <em>
      <span>
       Lithium Battery:
      </span>
     </em>
     <span>
      The system will be powered by a 3.7V Lithium battery.
     </span>
    </p>
    <p class="hckui__typography__bodyL">
     Power-saving features: Implement power-saving strategies like:
    </p>
    <p class="hckui__typography__bodyL">
     Screen dimming: Automatically dim the screen after a period of inactivity.
    </p>
    <p class="hckui__typography__bodyL">
     Sleep mode: Enter a low-power sleep mode when not in use.
    </p>
    <p class="hckui__typography__bodyL">
     Optimized algorithms: Design algorithms to minimize power consumption during sensor data processing.
    </p>
    <h3 class="hckui__typography__h3 title-with-anchor" id="toc-technical-specification-8">
     <p>
      <p class="hckui__typography__bodyL">
      </p>
     </p>
     <span>
      Technical Specification
     </span>
    </h3>
    <p class="hckui__typography__bodyL">
     Here's a technical specification based on the hardware mentioned in the Core Components sectionabove:
    </p>
    <p class="hckui__typography__bodyL">
     <strong>
      Microcontroller:
     </strong>
    </p>
    <p class="hckui__typography__bodyL">
     <span>
      Model:
     </span>
     <span>
      Swan v3 (STM32L4+)
     </span>
    </p>
    <p class="hckui__typography__bodyL">
     <em>
      <span>
       Specifications:
      </span>
     </em>
    </p>
    <p class="hckui__typography__bodyL">
     ARM Cortex-M4 core with 120 MHz clock speed
    </p>
    <p class="hckui__typography__bodyL">
     1 MB Flash memory, 320 KB RAM
    </p>
    <p class="hckui__typography__bodyL">
     Multiple communication interfaces (I2C, SPI, UART, USB)
    </p>
    <p class="hckui__typography__bodyL">
     Low-power consumption modes
    </p>
    <p class="hckui__typography__bodyL">
     <strong>
      Wireless Communication:
     </strong>
    </p>
    <p class="hckui__typography__bodyL">
     <em>
      <span>
       Model
      </span>
     </em>
     <strong>
      :
     </strong>
     <span>
      Blues Notecard WiFi
     </span>
    </p>
    <p class="hckui__typography__bodyL">
     <em>
      <span>
       Specifications:
      </span>
     </em>
    </p>
    <p class="hckui__typography__bodyL">
     Wi-Fi connectivity (802.11 b/g/n)
    </p>
    <p class="hckui__typography__bodyL">
     Secure data transmission
    </p>
    <p class="hckui__typography__bodyL">
     Cloud integration for data logging and remote management
    </p>
    <p class="hckui__typography__bodyL">
     <strong>
      Single Board Computer:
     </strong>
    </p>
    <p class="hckui__typography__bodyL">
     <em>
      <span>
       Model:
      </span>
     </em>
     <span>
      DFRobot UNIHIKER
     </span>
    </p>
    <p class="hckui__typography__bodyL">
     <em>
      <span>
       Specifications:
      </span>
     </em>
    </p>
    <p class="hckui__typography__bodyL">
     ESP32-based microcontroller with dual-core processor
    </p>
    <p class="hckui__typography__bodyL">
     4 MB Flash memory, 520 KB RAM
    </p>
    <p class="hckui__typography__bodyL">
     Built-in 2.8" LCD touch screen
    </p>
    <p class="hckui__typography__bodyL">
     Multiple communication interfaces (I2C, SPI, UART, USB, Wi-Fi, Bluetooth)
    </p>
    <p class="hckui__typography__bodyL">
     <strong>
      Camera Module:
     </strong>
    </p>
    <p class="hckui__typography__bodyL">
     <em>
      <span>
       Model:
      </span>
     </em>
     <span>
      Seeed Studio Grove - Vision AI Module
     </span>
    </p>
    <p class="hckui__typography__bodyL">
     <em>
      <span>
       Specifications:
      </span>
     </em>
    </p>
    <p class="hckui__typography__bodyL">
     13 MP image sensor
    </p>
    <p class="hckui__typography__bodyL">
     Pre-trained models for object detection and recognition
    </p>
    <p class="hckui__typography__bodyL">
     Grove connector for easy integration
    </p>
    <p class="hckui__typography__bodyL">
     <strong>
      Accelerometer and Gyroscope:
     </strong>
    </p>
    <p class="hckui__typography__bodyL">
     <em>
      <span>
       Model:
      </span>
     </em>
     <span>
      MAX32666FTHR Board
     </span>
    </p>
    <p class="hckui__typography__bodyL">
     <em>
      <span>
       Specifications:
      </span>
     </em>
    </p>
    <p class="hckui__typography__bodyL">
     3-axis accelerometer and 3-axis gyroscope
    </p>
    <p class="hckui__typography__bodyL">
     High precision and low noise
    </p>
    <p class="hckui__typography__bodyL">
     I2C communication interface
    </p>
    <p class="hckui__typography__bodyL">
     <strong>
      Power Supply:
     </strong>
    </p>
    <p class="hckui__typography__bodyL">
     <em>
      <span>
       Battery:
      </span>
     </em>
     <span>
      Rechargeable LiPo battery
     </span>
    </p>
    <p class="hckui__typography__bodyL">
     <em>
      <span>
       Battery Holder:
      </span>
     </em>
     <span>
      Notecarrier-A's battery holder for compact integration
     </span>
    </p>
    <h3 class="hckui__typography__h3 title-with-anchor" id="toc-build-9">
     <p>
      <p class="hckui__typography__bodyL">
      </p>
     </p>
     <span>
      BUILD
     </span>
    </h3>
    <p class="hckui__typography__bodyL">
     Here's a well-described build process based on the functional and technical specifications:
    </p>
    <p class="hckui__typography__bodyL">
     <strong>
      1. Component Assembly:
     </strong>
    </p>
    <p class="hckui__typography__bodyL">
     <strong>
      Microcontroller and Wireless Communication:
     </strong>
    </p>
    <p class="hckui__typography__bodyL">
     Securely mount the Swan v3 microcontroller and Blues Notecard WiFi module onto the Notecarrier-A board using standoffs and screws, ensuring firm connections.
    </p>
    <p class="hckui__typography__bodyL">
     <strong>
      Single Board Computer:
     </strong>
    </p>
    <p class="hckui__typography__bodyL">
     Attach the DFRobot UNIHIKER board to a suitable enclosure or mounting plate using appropriate hardware, ensuring accessibility to ports and buttons.
    </p>
    <p class="hckui__typography__bodyL">
     <strong>
      Camera Module:
     </strong>
    </p>
    <p class="hckui__typography__bodyL">
     Connect the Seeed Studio Grove - Vision AI Module to the Swan v3 microcontroller using the Grove connector, ensuring proper alignment.
    </p>
    <p class="hckui__typography__bodyL">
     <strong>
      Accelerometer and Gyroscope:
     </strong>
    </p>
    <p class="hckui__typography__bodyL">
     Carefully connect the MAX32666FTHR Board to the Swan v3 microcontroller's I2C pins, ensuring correct polarity and secure connections.
    </p>
    <p class="hckui__typography__bodyL">
     <strong>
      Power Supply:
     </strong>
    </p>
    <p class="hckui__typography__bodyL">
     Insert the rechargeable LiPo battery into the Notecarrier-A's battery holder, ensuring a snug fit.
    </p>
    <p class="hckui__typography__bodyL">
     <strong>
      2. Wiring and Connections:
     </strong>
    </p>
    <p class="hckui__typography__bodyL">
     <strong>
      Power Connections:
     </strong>
    </p>
    <p class="hckui__typography__bodyL">
     Connect the LiPo battery's power leads to the appropriate power input pins on the Swan v3 microcontroller, observing correct polarity.
    </p>
    <p class="hckui__typography__bodyL">
     <strong>
      Communication Connections:
     </strong>
    </p>
    <p class="hckui__typography__bodyL">
     Connect the Swan v3 microcontroller's UART pins to the Blues Notecard WiFi module's UART pins, enabling serial communication.
    </p>
    <p class="hckui__typography__bodyL">
     Connect the Swan v3 microcontroller's I2C pins to the DFRobot UNIHIKER's I2C pins, allowing for data exchange and control.
    </p>
    <p class="hckui__typography__bodyL">
     <strong>
      Camera Connection:
     </strong>
    </p>
    <p class="hckui__typography__bodyL">
     Ensure the camera module is securely connected to the Swan v3 microcontroller's Grove connector.
    </p>
    <p class="hckui__typography__bodyL">
     <strong>
      Accelerometer and Gyroscope Connection:
     </strong>
    </p>
    <p class="hckui__typography__bodyL">
     Verify the I2C connection between the MAX32666FTHR Board and the Swan v3 microcontroller.
    </p>
    <p class="hckui__typography__bodyL">
     <strong>
      3. Enclosure and Protection:
     </strong>
    </p>
    <p class="hckui__typography__bodyL">
     <strong>
      Enclosure Selection:
     </strong>
    </p>
    <p class="hckui__typography__bodyL">
     Choose an appropriate enclosure that accommodates all components, provides necessary protection, and allows for easy access to ports and buttons.
    </p>
    <p class="hckui__typography__bodyL">
     <strong>
      Component Placement:
     </strong>
    </p>
    <p class="hckui__typography__bodyL">
     Carefully position all components within the enclosure, ensuring they are securely mounted and do not interfere with each other.
    </p>
    <p class="hckui__typography__bodyL">
     <strong>
      Cable Management:
     </strong>
    </p>
    <p class="hckui__typography__bodyL">
     Neatly arrange and secure all cables and wires within the enclosure to prevent accidental disconnections or damage.
    </p>
    <p class="hckui__typography__bodyL">
     <strong>
      Environmental Protection:
     </strong>
    </p>
    <p class="hckui__typography__bodyL">
     Consider adding weatherproofing or dustproofing measures if the device will be used in outdoor or harsh environments.
    </p>
    <p class="hckui__typography__bodyL">
     <strong>
      4. Software Integration:
     </strong>
    </p>
    <p class="hckui__typography__bodyL">
     <strong>
      Microcontroller Programming:
     </strong>
    </p>
    <p class="hckui__typography__bodyL">
     Develop and upload firmware to the Swan v3 microcontroller to handle sensor data acquisition, processing, and communication with other components.
    </p>
    <p class="hckui__typography__bodyL">
     <strong>
      Wireless Communication Setup:
     </strong>
    </p>
    <p class="hckui__typography__bodyL">
     Configure the Blues Notecard WiFi module for network connectivity and data transmission.
    </p>
    <p class="hckui__typography__bodyL">
     <strong>
      Single Board Computer Programming:
     </strong>
    </p>
    <p class="hckui__typography__bodyL">
     Program the DFRobot UNIHIKER to provide the user interface, display sensor data, and control the wheelchair's navigation system.
    </p>
    <p class="hckui__typography__bodyL">
     <strong>
      Sensor Calibration:
     </strong>
    </p>
    <p class="hckui__typography__bodyL">
     Calibrate the camera module, accelerometer, and gyroscope to ensure accurate data readings.
    </p>
    <p class="hckui__typography__bodyL">
     <strong>
      5. Testing and Validation:
     </strong>
    </p>
    <p class="hckui__typography__bodyL">
     <strong>
      Functional Testing:
     </strong>
    </p>
    <p class="hckui__typography__bodyL">
     Test each component and connection individually to verify proper operation.
    </p>
    <p class="hckui__typography__bodyL">
     Test the integrated system in both Learn Mode and Run Mode to ensure it meets the functional requirements.
    </p>
    <p class="hckui__typography__bodyL">
     <strong>
      Performance Testing:
     </strong>
    </p>
    <p class="hckui__typography__bodyL">
     Evaluate the system's performance in terms of accuracy, responsiveness, and power consumption.
    </p>
    <p class="hckui__typography__bodyL">
     <strong>
      User Acceptance Testing:
     </strong>
    </p>
    <p class="hckui__typography__bodyL">
     Conduct user testing to gather feedback and identify areas for improvement.
    </p>
    <h3 class="hckui__typography__h3 title-with-anchor" id="toc-implementation-10">
     <p>
      <p class="hckui__typography__bodyL">
      </p>
     </p>
     <span>
      IMPLEMENTATION
     </span>
    </h3>
    <p class="hckui__typography__bodyL">
     This section contains implementation details.
    </p>
    <p class="hckui__typography__bodyL">
     Here's a breakdown of the implementation details, focusing on the key hardware and software components:
    </p>
    <p class="hckui__typography__bodyL">
     <strong>
      Hardware:
     </strong>
    </p>
    <p class="hckui__typography__bodyL">
     <strong>
      Microcontroller (Swan v3):
     </strong>
    </p>
    <p class="hckui__typography__bodyL">
     <strong>
      Sensor Integration:
     </strong>
     <span>
      The microcontroller will be programmed to interface with the camera module, accelerometer, and gyroscope. It will handle tasks like capturing images, reading sensor data, and processing this information to make real-time decisions.
     </span>
    </p>
    <p class="hckui__typography__bodyL">
     <strong>
      Communication:
     </strong>
     <span>
      The microcontroller will communicate with the Blues Notecard WiFi module to send sensor data and receive commands. It will also communicate with the DFRobot Unihiker to display information and receive user input.
     </span>
    </p>
    <p class="hckui__typography__bodyL">
     <strong>
      Wireless Communication (Blues Notecard WiFi):
     </strong>
    </p>
    <p class="hckui__typography__bodyL">
     <strong>
      Data Transmission:
     </strong>
     <span>
      This module will be responsible for transmitting sensor data and other information to a cloud-based platform or a local server. This data can be used for further analysis, remote monitoring, or integration with other systems.
     </span>
    </p>
    <p class="hckui__typography__bodyL">
     <strong>
      Connectivity:
     </strong>
     <span>
      The module will handle the WiFi connection, ensuring that the wheelchair remains connected to the network for continuous data transmission and remote management.
     </span>
    </p>
    <p class="hckui__typography__bodyL">
     <strong>
      Single Board Computer (DFRobot Unihiker):
     </strong>
    </p>
    <p class="hckui__typography__bodyL">
     <strong>
      User Interface:
     </strong>
     <span>
      The Unihiker's LCD screen and buttons will be used to provide a user-friendly interface. This interface will allow the user to switch between modes, set destinations, view the map, and adjust settings.
     </span>
    </p>
    <p class="hckui__typography__bodyL">
     <strong>
      Audio Feedback:
     </strong>
     <span>
      The Unihiker's onboard speaker will be used to provide audio cues and warnings to the user, guiding them through the environment and alerting them to obstacles.
     </span>
    </p>
    <p class="hckui__typography__bodyL">
     <strong>
      Camera Module (Seeed Studio Grove - Vision AI Module):
     </strong>
    </p>
    <p class="hckui__typography__bodyL">
     <strong>
      Image Capture:
     </strong>
     <span>
      The camera module will capture images of the environment, which will be used for mapping and object detection.
     </span>
    </p>
    <p class="hckui__typography__bodyL">
     <strong>
      Object Detection:
     </strong>
     <span>
      The module's pre-trained models will be used to detect and identify obstacles in the captured images. This information will be used to guide the wheelchair's navigation.
     </span>
    </p>
    <p class="hckui__typography__bodyL">
     <strong>
      Accelerometer and Gyroscope (MAX32666FTHR Board):
     </strong>
    </p>
    <p class="hckui__typography__bodyL">
     <strong>
      Movement Detection:
     </strong>
     <span>
      These sensors will measure the wheelchair's acceleration and angular velocity. This data will be used to detect movement, determine the wheelchair's orientation, and assist in navigation.
     </span>
    </p>
    <p class="hckui__typography__bodyL">
     <strong>
      Software:
     </strong>
    </p>
    <p class="hckui__typography__bodyL">
     <strong>
      Microcontroller Firmware:
     </strong>
    </p>
    <p class="hckui__typography__bodyL">
     <strong>
      Sensor Data Acquisition:
     </strong>
     <span>
      The firmware will be responsible for collecting data from the camera, accelerometer, and gyroscope.
     </span>
    </p>
    <p class="hckui__typography__bodyL">
     <strong>
      Data Processing:
     </strong>
     <span>
      The firmware will process the sensor data to create a map of the environment, detect obstacles, and make navigation decisions.
     </span>
    </p>
    <p class="hckui__typography__bodyL">
     <strong>
      Communication:
     </strong>
     <span>
      The firmware will handle communication with the Blues Notecard WiFi module and the DFRobot Unihiker.
     </span>
    </p>
    <p class="hckui__typography__bodyL">
     <strong>
      DFRobot Unihiker Software:
     </strong>
    </p>
    <p class="hckui__typography__bodyL">
     <strong>
      User Interface:
     </strong>
     <span>
      The software will provide a user-friendly interface for interacting with the system.
     </span>
    </p>
    <p class="hckui__typography__bodyL">
     <strong>
      Audio Feedback:
     </strong>
     <span>
      The software will generate audio cues and warnings based on the sensor data and navigation decisions.
     </span>
    </p>
    <p class="hckui__typography__bodyL">
     <strong>
      Cloud-Based Platform (or Local Server):
     </strong>
    </p>
    <p class="hckui__typography__bodyL">
     <strong>
      Data Storage:
     </strong>
     <span>
      The platform will store the sensor data and other information transmitted from the wheelchair.
     </span>
    </p>
    <p class="hckui__typography__bodyL">
     <strong>
      Data Analysis:
     </strong>
     <span>
      The platform can be used to analyze the collected data to gain insights into user behavior, system performance, and potential areas for improvement.
     </span>
    </p>
    <p class="hckui__typography__bodyL">
     <strong>
      Remote Management:
     </strong>
     <span>
      The platform can be used to remotely monitor and manage the wheelchair's navigation system.
     </span>
    </p>
    <p class="hckui__typography__bodyL">
     <strong>
      Implementation Challenges and Considerations:
     </strong>
    </p>
    <p class="hckui__typography__bodyL">
     <strong>
      Sensor Fusion:
     </strong>
     <span>
      Combining data from multiple sensors (camera, accelerometer, gyroscope) can be challenging. Careful calibration and sensor fusion algorithms will be needed to ensure accurate and reliable obstacle detection and navigation.
     </span>
    </p>
    <p class="hckui__typography__bodyL">
     <strong>
      Power Consumption:
     </strong>
     <span>
      The system needs to be designed for low power consumption to maximize battery life. This will involve optimizing algorithms, implementing power-saving modes, and carefully selecting hardware components.
     </span>
    </p>
    <p class="hckui__typography__bodyL">
     <strong>
      Real-time Performance:
     </strong>
     <span>
      The system needs to operate in real-time to provide timely feedback and guidance to the user. This will require efficient algorithms and hardware that can handle the computational demands of sensor data processing and navigation.
     </span>
    </p>
    <p class="hckui__typography__bodyL">
     <strong>
      User Experience:
     </strong>
     <span>
      The user interface needs to be intuitive and easy to use, even for users with limited technical expertise. The audio feedback should be clear and informative, providing the user with the necessary information to navigate safely.
     </span>
    </p>
    <h3 class="hckui__typography__h3 title-with-anchor" id="toc-running-the-system-11">
     <p>
      <p class="hckui__typography__bodyL">
      </p>
     </p>
     <span>
      RUNNING THE SYSTEM
     </span>
    </h3>
    <p class="hckui__typography__bodyL">
     Here's a detailed description of how to run the Smart Wheelchair Navigation System:
    </p>
    <p class="hckui__typography__bodyL">
     <strong>
      Startup:
     </strong>
    </p>
    <p class="hckui__typography__bodyL">
     <strong>
      Power On:
     </strong>
     <span>
      Turn on the DFRobot Unihiker board. The system will perform a self-check and initialize all sensors and components.
     </span>
    </p>
    <p class="hckui__typography__bodyL">
     <strong>
      Mode Selection:
     </strong>
     <span>
      The Unihiker's LCD will display the main menu, allowing the user to select between "Learn Mode" and "Run Mode."
     </span>
    </p>
    <p class="hckui__typography__bodyL">
     <strong>
      Learn Mode:
     </strong>
    </p>
    <p class="hckui__typography__bodyL">
     <strong>
      Initiate Mapping:
     </strong>
     <span>
      Select "Learn Mode" on the Unihiker's display. The system will prompt the user to start moving the wheelchair around the environment.
     </span>
    </p>
    <p class="hckui__typography__bodyL">
     <strong>
      Data Collection:
     </strong>
     <span>
      As the wheelchair moves, the camera module will capture images, and the accelerometer and gyroscope will record movement data. The microcontroller will process this data to create a map of the environment.
     </span>
    </p>
    <p class="hckui__typography__bodyL">
     <strong>
      Mapping Progress:
     </strong>
     <span>
      The Unihiker's display will show a progress bar or other visual indication of the mapping process. The user can continue moving the wheelchair until the desired area is mapped.
     </span>
    </p>
    <p class="hckui__typography__bodyL">
     <strong>
      Save Map:
     </strong>
     <span>
      Once the mapping is complete, the user can save the map to the system's memory or a cloud-based platform.
     </span>
    </p>
    <p class="hckui__typography__bodyL">
     <strong>
      Run Mode:
     </strong>
    </p>
    <p class="hckui__typography__bodyL">
     <strong>
      Load Map:
     </strong>
     <span>
      Select "Run Mode" on the Unihiker's display. The system will prompt the user to load a previously saved map.
     </span>
    </p>
    <p class="hckui__typography__bodyL">
     <strong>
      Set Destination:
     </strong>
     <span>
      Once the map is loaded, the user can set their desired destination on the Unihiker's display. This can be done by selecting a point on the map or by entering coordinates.
     </span>
    </p>
    <p class="hckui__typography__bodyL">
     <strong>
      Navigation:
     </strong>
     <span>
      The system will calculate the optimal route to the destination, taking into account obstacles and tight spaces. The wheelchair will then start moving towards the destination.
     </span>
    </p>
    <p class="hckui__typography__bodyL">
     <strong>
      Audio Guidance:
     </strong>
     <span>
      As the wheelchair moves, the system will provide audio feedback to the user, indicating turns, obstacles, and other relevant information.
     </span>
    </p>
    <p class="hckui__typography__bodyL">
     <strong>
      Obstacle Avoidance:
     </strong>
     <span>
      If the wheelchair encounters an obstacle, the system will detect it using the camera module and sensor data. It will then re-route the wheelchair to avoid the obstacle and continue towards the destination.
     </span>
    </p>
    <p class="hckui__typography__bodyL">
     <strong>
      Arrival:
     </strong>
     <span>
      When the wheelchair reaches the destination, the system will provide an audio notification to the user.
     </span>
    </p>
    <p class="hckui__typography__bodyL">
     <strong>
      Additional Features:
     </strong>
    </p>
    <p class="hckui__typography__bodyL">
     <strong>
      User Profiles:
     </strong>
     <span>
      Users can create profiles to store their preferences for route planning, obstacle avoidance, and terrain preferences.
     </span>
    </p>
    <p class="hckui__typography__bodyL">
     <strong>
      Real-time Feedback:
     </strong>
     <span>
      The system can gather feedback from the user during navigation to improve its understanding of their preferences.
     </span>
    </p>
    <p class="hckui__typography__bodyL">
     <strong>
      Machine Learning:
     </strong>
     <span>
      The system can use machine learning algorithms to analyze user behavior and provide more personalized recommendations.
     </span>
    </p>
    <h3 class="hckui__typography__h3 title-with-anchor" id="toc-conclusions-12">
     <p>
      <p class="hckui__typography__bodyL">
      </p>
     </p>
     <span>
      CONCLUSIONS
     </span>
    </h3>
    <p class="hckui__typography__bodyL">
     The Smart Wheelchair Navigation System is a device designed to assist individuals with mobility impairments in navigating unfamiliar environments. The device operates in two modes: Learn Mode, where it maps the environment using sensors and AI, and Run Mode, where it provides audio feedback to guide the user based on the learned map.
    </p>
    <p class="hckui__typography__bodyL">
     The project aims to address challenges faced by wheelchair users in navigating obstacles and tight spaces, particularly in hotel rooms. It utilizes a modular design approach, incorporating various sensors and AI algorithms to enhance its functionality and adaptability.
    </p>
    <p class="hckui__typography__bodyL">
     The system's core components include a microcontroller, wireless communication module, single-board computer, camera module, accelerometer, gyroscope, and power supply. These components work together to collect and process sensor data, create a map of the environment, detect obstacles, and provide audio feedback to the user.
    </p>
    <p class="hckui__typography__bodyL">
     The implementation details outline the hardware and software components, highlighting their specific roles in the system's operation. The document also discusses potential challenges and considerations, such as sensor fusion, power consumption, real-time performance, and user experience.
    </p>
    <p class="hckui__typography__bodyL">
     The Smart Wheelchair Navigation System offers features like route planning, obstacle detection, and personalized recommendations based on user preferences and behavior patterns. The system utilizes machine learning algorithms to continuously learn and adapt to individual user needs, enhancing its accuracy and effectiveness over time.
    </p>
    <p class="hckui__typography__bodyL">
     So, the Design Phase took longer than I thought, and the contest deadline is September 4, 2014, which is creeping up fast. I'm not quite finished with the project yet, but I'm working hard to wrap it up. I'm really excited about my project and I'm confident that it will be a valuable resource for others. I plan to document every step of the way, so people can see how I did it and maybe even replicate it themselves. Once I'm finished, I'll be showcasing a fully functional prototype, along with Code, Schematics and Instructions on how to operate it.  This will give people a chance to see what the project can do and how it works. I'm also going to be seeking feedback from users and experts to help me refine and improve the prototype. I want to make sure it's the best it can be and meets the highest standards of quality and functionality. I'm really excited to share this project with the world and I hope it will make a positive contribution to the field.
    </p>
    <h3 class="hckui__typography__h3 title-with-anchor" id="toc-enhancements-13">
     <p>
      <p class="hckui__typography__bodyL">
      </p>
     </p>
     <span>
      ENHANCEMENTS
     </span>
    </h3>
    <p class="hckui__typography__bodyL">
     <strong>
      Here are some additional features that could enhance the functionality of the wheelchair navigation system:
     </strong>
    </p>
    <p class="hckui__typography__bodyL">
     <strong>
      Route Planning:
     </strong>
     <span>
      In RUN mode, the wheelchair could use its map to plan the best route from point A to point B, taking into account factors like distance, obstacles, and user preferences.
     </span>
    </p>
    <p class="hckui__typography__bodyL">
     <strong>
      Obstacle Detection:
     </strong>
     <span>
      If the wheelchair detects an obstacle in its path, it could re-route and send a message to the user informing them of the obstacle.
     </span>
    </p>
    <p class="hckui__typography__bodyL">
     <strong>
      Size of Wheelchair:
     </strong>
     <span>
      The wheelchair could take into account its own size when planning routes, ensuring that it can safely navigate through tight spaces.
     </span>
    </p>
    <p class="hckui__typography__bodyL">
     <strong>
      The wheelchair's route planning could be enhanced to take into account the user's preferences in several ways:
     </strong>
    </p>
    <p class="hckui__typography__bodyL">
     <strong>
      User Profiles:
     </strong>
     <span>
      The system could allow users to create profiles where they specify their preferences, such as:
     </span>
    </p>
    <p class="hckui__typography__bodyL">
     <strong>
      Preferred routes:
     </strong>
     <span>
      Users could indicate if they prefer shorter routes, even if they are more complex, or if they prefer simpler routes, even if they are slightly longer.
     </span>
    </p>
    <p class="hckui__typography__bodyL">
     <strong>
      Obstacle avoidance:
     </strong>
     <span>
      Users could specify their comfort level with navigating near obstacles. For example, a user who is more cautious might prefer a route that keeps a wider berth from obstacles.
     </span>
    </p>
    <p class="hckui__typography__bodyL">
     <strong>
      Terrain preferences:
     </strong>
     <span>
      Users could indicate if they prefer to avoid certain types of terrain, such as inclines or uneven surfaces.
     </span>
    </p>
    <p class="hckui__typography__bodyL">
     <strong>
      Real-time Feedback:
     </strong>
     <span>
      The system could gather feedback from the user during navigation to further refine its understanding of their preferences. For example, if the user frequently deviates from the suggested route, the system could learn that they prefer a different type of route.
     </span>
    </p>
    <p class="hckui__typography__bodyL">
     <strong>
      Machine Learning:
     </strong>
     <span>
      The system could use machine learning algorithms to analyze the user's past behavior and preferences to make more accurate predictions about their future preferences. This would allow the system to proactively suggest routes that are most likely to be preferred by the user.
     </span>
    </p>
    <p class="hckui__typography__bodyL">
     <strong>
      To enhance the wheelchair's route planning for more personalized recommendations, consider these strategies:
     </strong>
    </p>
    <p class="hckui__typography__bodyL">
     <strong>
      User Profiles:
     </strong>
     <span>
      Allow users to input preferences like preferred routes (shortest, simplest, etc.), obstacle avoidance comfort levels, and terrain preferences.
     </span>
    </p>
    <p class="hckui__typography__bodyL">
     <strong>
      Real-time Feedback:
     </strong>
     <span>
      Gather user input during navigation to understand their preferences better. If they often deviate from suggested routes, learn from those choices.
     </span>
    </p>
    <p class="hckui__typography__bodyL">
     <strong>
      Machine Learning:
     </strong>
     <span>
      Analyze past user behavior and preferences using machine learning algorithms to predict future needs and proactively suggest routes.
     </span>
    </p>
    <p class="hckui__typography__bodyL">
     <strong>
      Here's how the system could use machine learning algorithms to analyze user preferences and provide more accurate recommendations:
     </strong>
    </p>
    <p class="hckui__typography__bodyL">
     <strong>
      Data Collection:
     </strong>
     <span>
      The system would continuously gather data on user interactions, including:
     </span>
    </p>
    <p class="hckui__typography__bodyL">
     Chosen routes: The actual paths taken by the user, including any deviations from suggested routes.
    </p>
    <p class="hckui__typography__bodyL">
     Obstacle responses: How the user reacts to obstacles, such as whether they follow the suggested rerouting or find alternative paths.
    </p>
    <p class="hckui__typography__bodyL">
     User feedback: Explicit feedback from the user, such as ratings of suggested routes or obstacle avoidance maneuvers.
    </p>
    <p class="hckui__typography__bodyL">
     <strong>
      Feature Extraction:
     </strong>
     <span>
      Relevant features would be extracted from the collected data, such as:
     </span>
    </p>
    <p class="hckui__typography__bodyL">
     Route characteristics: Length, complexity, number of turns, elevation changes.
    </p>
    <p class="hckui__typography__bodyL">
     Obstacle types: Size, shape, location.
    </p>
    <p class="hckui__typography__bodyL">
     User behavior patterns: Tendency to choose shorter/simpler routes, obstacle avoidance preferences.
    </p>
    <p class="hckui__typography__bodyL">
     <strong>
      Model Training:
     </strong>
     <span>
      Machine learning algorithms, such as decision trees, support vector machines, or neural networks, would be trained on the extracted features and associated user preferences. The goal is to learn a model that can accurately predict user preferences based on new data.
     </span>
    </p>
    <p class="hckui__typography__bodyL">
     <strong>
      Preference Prediction:
     </strong>
     <span>
      The trained model would be used to predict the user's preferences for new routes or obstacle avoidance scenarios. For example, the model could predict the user's likelihood of choosing a particular route based on its characteristics and the user's past behavior.
     </span>
    </p>
    <p class="hckui__typography__bodyL">
     <strong>
      Personalized Recommendations:
     </strong>
     <span>
      The system would use the predicted preferences to provide personalized recommendations to the user. For example, it could suggest routes that are most likely to be preferred by the user, or it could adjust obstacle avoidance strategies based on the user's comfort level.
     </span>
    </p>
    <p class="hckui__typography__bodyL">
     <strong>
      Continuous Learning:
     </strong>
     <span>
      The system would continuously update its models as new data becomes available, allowing it to adapt to changes in the user's preferences over time. This would ensure that the recommendations remain accurate and relevant
     </span>
    </p>
    <h3 class="hckui__typography__h3 title-with-anchor" id="toc-thank-you-14">
     <p>
      <p class="hckui__typography__bodyL">
      </p>
     </p>
     <span>
      Thank you
     </span>
    </h3>
    <p class="hckui__typography__bodyL">
     to the Hackster community for taking the time to read through my project. I hope that you found the information enlightening and that it sparked some ideas for future assistive technology developments. Your feedback and support are invaluable as we work together to create a more inclusive world for individuals with mobility impairments.
    </p>
   </div>
  </section>
  <div class="project-section-break">
  </div>
  <div class="project-section-break">
  </div>
 </div>
</div>
