<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/water.css@2/out/water.css"><link rel="stylesheet" href="../custom.css"><div class="middle-column">
 <section id="overview">
  <h1 class="hckui__typography__h1" itemprop="name">
   Face Recognition Controlled Entry Lock
  </h1>
  <p class="hckui__typography__bodyL hckui__layout__marginBottom15" itemprop="description">
   Face recognition controlled smart lock to assist mobility impaired individuals to access a locked entry door.
  </p>
  <div class="hckui__layout__marginTop30">
   <div class="hckui__layout__hiddenMedUp">
   </div>
   <div class="project-cover-image" itemprop="image" itemscope="" itemtype="https://schema.org/ImageObject">
    <meta content="https://hackster.imgix.net/uploads/attachments/1751241/_2DoF4U014k.blob?auto=compress&amp;w=900&amp;h=675&amp;fit=min&amp;fm=jpg" itemprop="url"/>
    <meta content="900" itemprop="width"/>
    <meta content="675" itemprop="height"/>
    <img alt="Face Recognition Controlled Entry Lock" src="13.jpg"/>
   </div>
  </div>
 </section>
 <div class="project-section-break">
 </div>
 <div id="project_page_simple_ad_portal">
 </div>
 <div id="description" itemprop="articleBody">
  <section id="things">
   <div class="project-section-title">
    <h2 class="hckui__typography__h2 title-with-anchor">
     <span>
      Things used in this project
     </span>
    </h2>
   </div>
   <div class="project-parts">
    <div class="view-expanded" style="display:block">
     <table class="project-parts-table">
      <colgroup>
       <col style="width: 100px; height: 50px;"/>
       <col style="width: auto;"/>
      </colgroup>
      <tbody>
       <tr class="head">
        <td colspan="2">
         <h3 class="hckui__typography__h3">
          Hardware components
         </h3>
        </td>
        <tr>
         <td class="part-img">
         </td>
         <td class="hckui__typography__bodyL">
          SwitchBot Lock Pro + Keypad Touch
         </td>
        </tr>
        <tr>
         <td class="part-img">
          <img alt="UNIHIKER - IoT Python Programming Single Board Computer with Touchscreen" src="14.jpg" srcset="https://hackster.imgix.net/uploads/attachments/1623050/9924dc25f8a8d36cae2ea2becac95b77_Bn8OXLjRQw.png?auto=compress%2Cformat&amp;w=96&amp;h=96&amp;fit=fill&amp;bg=ffffff 2x, https://hackster.imgix.net/uploads/attachments/1623050/9924dc25f8a8d36cae2ea2becac95b77_Bn8OXLjRQw.png?auto=compress%2Cformat&amp;w=48&amp;h=48&amp;fit=fill&amp;bg=ffffff"/>
         </td>
         <td class="hckui__typography__bodyL">
          <a class="hckui__typography__linkBlue" data-ha='{"eventName":"Clicked link","customProps":{"value":"DFRobot UNIHIKER - IoT Python Programming Single Board Computer with Touchscreen","href":"/dfrobot/products/unihiker-iot-python-programming-single-board-computer-with-touchscreen1?ref=project-2c95aa","type":"part","location":"things"},"clickOpts":{"delayRedirect":true}}' href="https://www.hackster.io/dfrobot/products/unihiker-iot-python-programming-single-board-computer-with-touchscreen1?ref=project-2c95aa">
           DFRobot UNIHIKER - IoT Python Programming Single Board Computer with Touchscreen
          </a>
         </td>
        </tr>
        <tr>
         <td class="part-img">
         </td>
         <td class="hckui__typography__bodyL">
          M5Stack CoreS3 - ESP32S3 - IoT Development Kit
         </td>
        </tr>
        <tr>
         <td class="part-img">
          <img alt="Blues Notecard (Cellular)" src="15.jpg" srcset="https://hackster.imgix.net/uploads/attachments/1708752/wbnan-front_tdId2xJ1V4.png?auto=compress%2Cformat&amp;w=96&amp;h=96&amp;fit=fill&amp;bg=ffffff 2x, https://hackster.imgix.net/uploads/attachments/1708752/wbnan-front_tdId2xJ1V4.png?auto=compress%2Cformat&amp;w=48&amp;h=48&amp;fit=fill&amp;bg=ffffff"/>
         </td>
         <td class="hckui__typography__bodyL">
          <a class="hckui__typography__linkBlue" data-ha='{"eventName":"Clicked link","customProps":{"value":"Blues Notecard (Cellular)","href":"/blues-wireless/products/blues-notecard-cellular?ref=project-2c95aa","type":"part","location":"things"},"clickOpts":{"delayRedirect":true}}' href="https://www.hackster.io/blues-wireless/products/blues-notecard-cellular?ref=project-2c95aa">
           Blues Notecard (Cellular)
          </a>
         </td>
        </tr>
        <tr>
         <td class="part-img">
          <img alt="Blues Notecarrier A" src="16.jpg" srcset="https://hackster.imgix.net/uploads/attachments/1431807/CARR_AL_2.0_front_1800x1800.jpg?auto=compress%2Cformat&amp;w=96&amp;h=96&amp;fit=fill&amp;bg=ffffff 2x, https://hackster.imgix.net/uploads/attachments/1431807/CARR_AL_2.0_front_1800x1800.jpg?auto=compress%2Cformat&amp;w=48&amp;h=48&amp;fit=fill&amp;bg=ffffff"/>
         </td>
         <td class="hckui__typography__bodyL">
          <a class="hckui__typography__linkBlue" data-ha='{"eventName":"Clicked link","customProps":{"value":"Blues Notecarrier A","href":"/blues-wireless/products/blues-notecarrier-a?ref=project-2c95aa","type":"part","location":"things"},"clickOpts":{"delayRedirect":true}}' href="https://www.hackster.io/blues-wireless/products/blues-notecarrier-a?ref=project-2c95aa">
           Blues Notecarrier A
          </a>
         </td>
        </tr>
        <tr>
         <td class="part-img">
          <img alt="Seeed Studio XIAO ESP32S3 Sense" src="17.jpg" srcset="https://hackster.imgix.net/uploads/attachments/1650360/screenshot_2023-11-20_at_17_16_09_QdLoLAbseq.png?auto=compress%2Cformat&amp;w=96&amp;h=96&amp;fit=fill&amp;bg=ffffff 2x, https://hackster.imgix.net/uploads/attachments/1650360/screenshot_2023-11-20_at_17_16_09_QdLoLAbseq.png?auto=compress%2Cformat&amp;w=48&amp;h=48&amp;fit=fill&amp;bg=ffffff"/>
         </td>
         <td class="hckui__typography__bodyL">
          <a class="hckui__typography__linkBlue" data-ha='{"eventName":"Clicked link","customProps":{"value":"Seeed Studio XIAO ESP32S3 Sense","href":"/seeed/products/seeed-studio-xiao-esp32s3-sense?ref=project-2c95aa","type":"part","location":"things"},"clickOpts":{"delayRedirect":true}}' href="https://www.hackster.io/seeed/products/seeed-studio-xiao-esp32s3-sense?ref=project-2c95aa">
           Seeed Studio XIAO ESP32S3 Sense
          </a>
         </td>
        </tr>
        <tr>
         <td class="part-img">
          <img alt="Mini RFID Unit RC522 Module Sensor" src="18.jpg" srcset="https://hackster.imgix.net/uploads/attachments/916413/rfid_kDI7D49Cx7.jpg?auto=compress%2Cformat&amp;w=96&amp;h=96&amp;fit=fill&amp;bg=ffffff 2x, https://hackster.imgix.net/uploads/attachments/916413/rfid_kDI7D49Cx7.jpg?auto=compress%2Cformat&amp;w=48&amp;h=48&amp;fit=fill&amp;bg=ffffff"/>
         </td>
         <td class="hckui__typography__bodyL">
          <a class="hckui__typography__linkBlue" data-ha='{"eventName":"Clicked link","customProps":{"value":"M5Stack Mini RFID Unit RC522 Module Sensor","href":"/m5stack/products/mini-rfid-unit-rc522-module-sensor?ref=project-2c95aa","type":"part","location":"things"},"clickOpts":{"delayRedirect":true}}' href="https://www.hackster.io/m5stack/products/mini-rfid-unit-rc522-module-sensor?ref=project-2c95aa">
           M5Stack Mini RFID Unit RC522 Module Sensor
          </a>
         </td>
        </tr>
        <tr>
         <td class="part-img">
          <img alt="Finger Print Unit FPC1020A" src="19.jpg" srcset="https://hackster.imgix.net/uploads/attachments/916341/finger_0gqwH4Jatm.jpg?auto=compress%2Cformat&amp;w=96&amp;h=96&amp;fit=fill&amp;bg=ffffff 2x, https://hackster.imgix.net/uploads/attachments/916341/finger_0gqwH4Jatm.jpg?auto=compress%2Cformat&amp;w=48&amp;h=48&amp;fit=fill&amp;bg=ffffff"/>
         </td>
         <td class="hckui__typography__bodyL">
          <a class="hckui__typography__linkBlue" data-ha='{"eventName":"Clicked link","customProps":{"value":"M5Stack Finger Print Unit FPC1020A","href":"/m5stack/products/finger-print-unit-fpc1020a?ref=project-2c95aa","type":"part","location":"things"},"clickOpts":{"delayRedirect":true}}' href="https://www.hackster.io/m5stack/products/finger-print-unit-fpc1020a?ref=project-2c95aa">
           M5Stack Finger Print Unit FPC1020A
          </a>
         </td>
        </tr>
        <tr>
         <td class="part-img">
         </td>
         <td class="hckui__typography__bodyL">
          Adafruit Ultra Tiny USB Camera with GC0307 Sensor
         </td>
        </tr>
        <tr>
         <td class="part-img">
         </td>
         <td class="hckui__typography__bodyL">
          SparkFun Qwiic micro:bit Breakout (with Headers)
         </td>
        </tr>
        <tr>
         <td class="part-img">
          <img alt="Grove Shield for Seeeduino XIAO - with embedded battery management chip" src="20.jpg" srcset="https://hackster.imgix.net/uploads/attachments/1443566/xiao_-preview-25_YOYZK9MZYo.png?auto=compress%2Cformat&amp;w=96&amp;h=96&amp;fit=fill&amp;bg=ffffff 2x, https://hackster.imgix.net/uploads/attachments/1443566/xiao_-preview-25_YOYZK9MZYo.png?auto=compress%2Cformat&amp;w=48&amp;h=48&amp;fit=fill&amp;bg=ffffff"/>
         </td>
         <td class="hckui__typography__bodyL">
          <a class="hckui__typography__linkBlue" data-ha='{"eventName":"Clicked link","customProps":{"value":"Seeed Studio Grove Shield for Seeeduino XIAO - with embedded battery management chip","href":"/seeed/products/grove-shield-for-seeeduino-xiao-with-embedded-battery-management-chip?ref=project-2c95aa","type":"part","location":"things"},"clickOpts":{"delayRedirect":true}}' href="https://www.hackster.io/seeed/products/grove-shield-for-seeeduino-xiao-with-embedded-battery-management-chip?ref=project-2c95aa">
           Seeed Studio Grove Shield for Seeeduino XIAO - with embedded battery management chip
          </a>
         </td>
        </tr>
       </tr>
       <tr class="head">
        <td colspan="2">
         <h3 class="hckui__typography__h3">
          Software apps and online services
         </h3>
        </td>
       </tr>
       <tr>
        <td class="part-img">
         <img alt="Arduino IDE" src="21.jpg" srcset="https://hackster.imgix.net/uploads/image/file/144203/IDE_web.jpg?auto=compress%2Cformat&amp;w=96&amp;h=96&amp;fit=fill&amp;bg=ffffff 2x, https://hackster.imgix.net/uploads/image/file/144203/IDE_web.jpg?auto=compress%2Cformat&amp;w=48&amp;h=48&amp;fit=fill&amp;bg=ffffff"/>
        </td>
        <td class="hckui__typography__bodyL">
         <a class="hckui__typography__linkBlue" data-ha='{"eventName":"Clicked link","customProps":{"value":"Arduino IDE","href":"/arduino/products/arduino-ide?ref=project-2c95aa","type":"part","location":"things"},"clickOpts":{"delayRedirect":true}}' href="https://www.hackster.io/arduino/products/arduino-ide?ref=project-2c95aa">
          Arduino IDE
         </a>
        </td>
       </tr>
       <tr>
        <td class="part-img">
         <img alt="VS Code" src="22.jpg" srcset="https://hackster.imgix.net/uploads/attachments/673386/512px-visual_studio_code_1_18_icon_svg_k5OBc8o3Yk.png?auto=compress%2Cformat&amp;w=96&amp;h=96&amp;fit=fill&amp;bg=ffffff 2x, https://hackster.imgix.net/uploads/attachments/673386/512px-visual_studio_code_1_18_icon_svg_k5OBc8o3Yk.png?auto=compress%2Cformat&amp;w=48&amp;h=48&amp;fit=fill&amp;bg=ffffff"/>
        </td>
        <td class="hckui__typography__bodyL">
         <a class="hckui__typography__linkBlue" data-ha='{"eventName":"Clicked link","customProps":{"value":"Microsoft VS Code","href":"/microsoft/products/vs-code?ref=project-2c95aa","type":"part","location":"things"},"clickOpts":{"delayRedirect":true}}' href="https://www.hackster.io/microsoft/products/vs-code?ref=project-2c95aa">
          Microsoft VS Code
         </a>
        </td>
       </tr>
       <tr class="head">
        <td colspan="2">
         <h3 class="hckui__typography__h3">
          Hand tools and fabrication machines
         </h3>
        </td>
       </tr>
       <tr>
        <td class="part-img">
        </td>
        <td class="hckui__typography__bodyL">
         Anycubic Kobra 2
        </td>
       </tr>
      </tbody>
     </table>
    </div>
   </div>
  </section>
  <div class="project-section-break">
  </div>
  <section id="story">
   <div class="project-section-title">
    <h2 class="hckui__typography__h2 title-with-anchor">
     <span>
      Story
     </span>
    </h2>
   </div>
   <div class="project-story collapsible-section collapsed hljs-active hljs-monokai" itemprop="text">
    <p class="hckui__typography__bodyL">
     This project is an entry for the Build2gether 2.0 contest for Track 1: Accessible HOME &amp; TOOLS.
    </p>
    <h3 class="hckui__typography__h3 title-with-anchor" id="toc-preface-0">
     <p>
      <p class="hckui__typography__bodyL">
      </p>
     </p>
     <span>
      Preface
     </span>
    </h3>
    <p class="hckui__typography__bodyL">
     This has been an unexpectedly difficult summer for me.  We've had weeks of extreme heat and poor air quality which created an unhealthy work environment.  I then had a subconjunctival hemorrhage (bleed) in my right eye and have been experiencing persistent vision issues since then.  I realized about 5 weeks ago that I would not be able to complete the project that I proposed for this contest.  The contest admin suggested that I could try to submit a simpler project.
    </p>
    <p class="hckui__typography__bodyL">
     I did get through the initial planning and feedback stages and received the superbox hardware and purchased additional hardware, so in the spirit of participation and gratitude to the contest sponsors I am going to submit as much of a descoped project as I can complete.
    </p>
    <p class="hckui__typography__bodyL">
     I'll cover my original proposal and the simpler project in the Introduction.
    </p>
    <h3 class="hckui__typography__h3 title-with-anchor" id="toc-introduction-1">
     <p>
      <p class="hckui__typography__bodyL">
      </p>
     </p>
     <span>
      Introduction
     </span>
    </h3>
    <p class="hckui__typography__bodyL">
     <span>
      My original project title was
     </span>
     <strong>
      Secure Voice Controlled Entry Lock
     </strong>
     <span>
      .
     </span>
    </p>
    <p class="hckui__typography__bodyL">
     Here was the problem statement and proposed solution:
    </p>
    <p class="hckui__typography__bodyL">
     PROBLEM: Mobility impaired individuals encounter difficulty accessing secured (locked) areas due to the inability to reach or manipulate the locks. This could be caused by the proximity limitations caused by larger assistive such as wheelchairs/walkers or there could be a more direct problem of not being able to manually manipulate the lock mechanism.
    </p>
    <p class="hckui__typography__bodyL">
     SOLUTION: I would build a device to either request access or directly provide access using voice control. This would only work with electronic locks. The Seeed ESP32S3 would provide the voice control and request access using the Blues Notecard for cellular/WiFi requests or direct access the lock using its own BLE/WiFi radios.
    </p>
    <p class="hckui__typography__bodyL">
     <span>
      FEEDBACKFROM CONTEST MASTERS ::
     </span>
     <br/>
     <span>
      This is a great idea, I can use this all the time. I think it would be important for multiple security features. Having a distinctive voice profile that others cannot use would be one good option. Also having a secondary BLE key or something that’s attached to the wheelchair so that you ensure both the person and the wheelchair are together so that the device can’t be removed from. Lastly being able to easily recalibrate or retrain would be helpful. It is also essential that if somebody is dependent on this device, it is robust enough notifies the user when the batteries get low, and has some amount of longevity beyond that. Having it rechargeable via USB may allow it to even be plugged into the wheelchair battery system. You just don’t want something like this to malfunction or run out of batteries and have someone stuck out in the rain or something."
     </span>
    </p>
    <p class="hckui__typography__bodyL">
     <span>
      INITIAL CONCEPT:
     </span>
     <br/>
     <span>
      After receiving the super box hardware and reviewing the feedback I decided that  I would build a compact control unit with BLE communication to the electronic lock.  The unit would mount on the arm of a wheelchair and receive power using a USB charging adapter that plugged into the wheelchair battery charging port.
     </span>
    </p>
    <p class="hckui__typography__bodyL">
     The control unit would interface with multiple sensors to provide secure user authentication to operate the lock.
    </p>
    <ul class="hckui__typography__bodyL">
     <li>
      Voice control
     </li>
     <li>
      Button control
     </li>
     <li>
      Facial recognition
     </li>
     <li>
      Fingerprint recognition
     </li>
     <li>
      RFID card verification
     </li>
     <li>
      BLE communication for primary lock control
     </li>
     <li>
      WiFi communication for local backup
     </li>
     <li>
      Cellular communication for emergency and status alerts
     </li>
    </ul>
    <p class="hckui__typography__bodyL">
     I chose to use the DFRobot Unihiker as the central controller as it integrates a quad-core Linux SBC with 240x320 capacitive touch display, microphone, imu, WiFi/BLE radios, and I2C and UART interfaces for external sensors.
    </p>
    <p class="hckui__typography__bodyL">
     My proposed configuration is shown below.
    </p>
    <ul class="hckui__typography__bodyL">
     <li>
      Unihiker
     </li>
     <li>
      640x480 USB webcam
     </li>
     <li>
      RFID reader
     </li>
     <li>
      Fingerprint scanner
     </li>
     <li>
      Blues Notecard for cellular
     </li>
    </ul>
    <div class="carousel-images">
     <img class="carousel-image" src="0.jpg"/>
    </div>
    <p class="hckui__typography__bodyL">
     <span>
      ALTERNATE CONCEPT:
     </span>
     <br/>
     <span>
      I also had an alternative configuration in mind that would use a M5Stack CoreS3 as the controller.  The CoreS3 has most of the capabilities as the Unihiker but it is based on a dual core MCU so it would be appropriate for a battery operated solution that could be used on a more light weight mobility device like a walker.  It also has an integrated 640x480 camera and an RTC.
     </span>
    </p>
    <div class="carousel-images">
     <img class="carousel-image" src="1.jpg"/>
    </div>
    <p class="hckui__typography__bodyL">
     <span>
      REDUCED SCOPE:
     </span>
     <br/>
     <span>
      Unfortunately, as I mentioned in the preface, my personal issues prevented me from being able to pursue my original plan even though I did get all the necessary hardware.  Also, I had unanticipated problems with the Unihiker I2C and UART interfaces which made using them difficult.  I had selected the Unihiker because I thought that the Debian Linux OS would be a good development environment for me since I have done a lot Python based projects on various Raspberry Pi SBCs.
     </span>
    </p>
    <p class="hckui__typography__bodyL">
     The Unihiker uses an MCU coprocessor to handle its GPIO and requires using the Pinpong library to access the pin interface.  The standard Linux serial devices are not available so the usual Python libraries for UART and I2C won't work.  DFRobot has ported a number of Arduino libraries to Pinpong but the devices (Notecard,  WS1850S, F1020SC) that I wanted to use were not included so I would have had to port the libraries myself which I did not have time for.  The I2C documentation was also lacking for Pinpong.  The GPIO pin control works well so I used a hybrid approach to interface the Blues Notecard.  I used a Xiao ESP32S3 to provide the I2C interface which allowed me to use the Arduino Notecard library.  I toggled the Unihiker GPIO pins to signal interrupts on the Xiao to send notes to the Notecard,
    </p>
    <p class="hckui__typography__bodyL">
     I attempted to add the Fingerprint scanner and RFID reader to the Xiao but had compilation issues with the Arduino libraries which I did not have time to resolve.
    </p>
    <p class="hckui__typography__bodyL">
     So, I ended up just running face recognition on the Unihiker to unlock/lock the SwitchBot lock and the Xiao/Blues interface to send status to the Blues Notehub.
    </p>
    <div class="carousel-images">
     <img class="carousel-image" src="2.jpg"/>
    </div>
    <h3 class="hckui__typography__h3 title-with-anchor" id="toc-switchbot-lock-pro-2">
     <p>
      <p class="hckui__typography__bodyL">
      </p>
     </p>
     <span>
      SwitchBot Lock Pro
     </span>
    </h3>
    <p class="hckui__typography__bodyL">
     The electronic lock that I am using is the SwitchBot Lock Pro which is a "retrofit" lock that can be added to most existing deadbolts.  It is battery operated and is controlled using BLE.
    </p>
    <p class="hckui__typography__bodyL">
     I built a mock-up of an entry door deadbolt with the SwitchBot Lock Pro attached.  This allowed me to do all my development work without interfering with use of the actual entry door and made it easier to monitor and document the lock operation.
    </p>
    <div class="carousel-images">
     <img class="carousel-image" src="3.jpg"/>
    </div>
    <div class="carousel-images">
     <img class="carousel-image" src="4.jpg"/>
    </div>
    <p class="hckui__typography__bodyL">
     SwitchBot has an IOS app to interface its various "bots" including the Lock Pro.  Here is a short demo using the app to unlock and unlock the deadbolt.
    </p>
    <div class="embed-frame">
     <figure class="youtube">
      <iframe allowfullscreen="" frameborder="0" height="500" src="//www.youtube.com/embed/MIrKuPk682I?rel=0" style="margin: 10px auto; display: block;" width="75%">
      </iframe>
     </figure>
    </div>
    <p class="hckui__typography__bodyL">
     The next step was to create a Python program to control the lock.  I am using VSCode via a remote SSH interface to the Unihiker for software development.
    </p>
    <p class="hckui__typography__bodyL">
     SwitchBot has two APIs to interface its "bots" - Web based and BLE.  The Web based interfaces through the SwitchBot cloud and requires a SwitchBot hub to connect to the lock.  The BLE is a direct connection which is obviously more responsive and more reliable.  Unfortunately, I have not been able to get the BLE API to work.
    </p>
    <p class="hckui__typography__bodyL">
     <span>
      I can see and connect to the lock using the nRF Connect app on my iPad.
     </span>
     <br/>
    </p>
    <div class="carousel-images">
     <img class="carousel-image" src="5.jpg"/>
    </div>
    <p class="hckui__typography__bodyL">
     The lock is not advertising but I can see the Service and Characteristic UUIDs that I need for control.
    </p>
    <p class="hckui__typography__bodyL">
     I can also use the BLE API to verify that I can see those services using a Python program but I'm unable to get it to lock or unlock.
    </p>
    <div class="carousel-images">
     <img class="carousel-image" src="6.jpg"/>
    </div>
    <p class="hckui__typography__bodyL">
     I then tried the Web API and was successful in operating the lock.
    </p>
    <div class="carousel-images">
     <img class="carousel-image" src="7.jpg"/>
    </div>
    <p class="hckui__typography__bodyL">
     There is an approximate 5 second lag between the command and action due to the delay through the cloud and local hub as shown below.
    </p>
    <div class="embed-frame">
     <figure class="youtube">
      <iframe allowfullscreen="" frameborder="0" height="500" src="//www.youtube.com/embed/iQy__8bYiAI?rel=0" style="margin: 10px auto; display: block;" width="75%">
      </iframe>
     </figure>
    </div>
    <p class="hckui__typography__bodyL">
     I have not seen an example of the Lock Pro being used with the BLE API so I'll need to use the Web API for now.
    </p>
    <h3 class="hckui__typography__h3 title-with-anchor" id="toc-facial-recognition-3">
     <p>
      <p class="hckui__typography__bodyL">
      </p>
     </p>
     <span>
      Facial Recognition
     </span>
    </h3>
    <p class="hckui__typography__bodyL">
     <span>
      Now that I can programmatically operate the lock, I need to use face recognition to unlock the SwitchBot lock.  Luckily DFRobot already has a tutorial to train and use a face recognition model on the Unihiker -
     </span>
     <a class="hckui__typography__linkBlue" data-ha='{"eventName":"Clicked link","customProps":{"value":"Intelligent Access Control with Facial Recognition","href":"https://edu.dfrobot.com/makelog-313333.html","type":"story","location":"story"},"clickOpts":{"delayRedirect":true}}' href="https://edu.dfrobot.com/makelog-313333.html" rel="nofollow">
      Intelligent Access Control with Facial Recognition
     </a>
     <span>
      .
     </span>
    </p>
    <p class="hckui__typography__bodyL">
     There are 3 Python programs required.
    </p>
    <p class="hckui__typography__bodyL">
     <span>
      1)
     </span>
     <a class="hckui__typography__linkBlue" data-ha='{"eventName":"Clicked link","customProps":{"value":"faceRegistration.py","href":"http://faceRegistration.py","type":"story","location":"story"},"clickOpts":{"delayRedirect":true}}' href="http://faceRegistration.py" rel="nofollow">
      faceRegistration.py
     </a>
     <span>
      - use the webcam to capture and label 50 face images associated with a particular face id
     </span>
    </p>
    <p class="hckui__typography__bodyL">
     <span>
      2)
     </span>
     <a class="hckui__typography__linkBlue" data-ha='{"eventName":"Clicked link","customProps":{"value":"faceModelTraining.py","href":"http://faceModelTraining.py","type":"story","location":"story"},"clickOpts":{"delayRedirect":true}}' href="http://faceModelTraining.py" rel="nofollow">
      faceModelTraining.py
     </a>
     <span>
      - trains model using a Haar-Cascade Frontal Face Classifier and LBPH (Local Binary Pattern Histogram) algorithm to associate ids with labeled images
     </span>
    </p>
    <p class="hckui__typography__bodyL">
     <span>
      3)
     </span>
     <a class="hckui__typography__linkBlue" data-ha='{"eventName":"Clicked link","customProps":{"value":"faceRecogniton.py","href":"http://faceRecogniton.py","type":"story","location":"story"},"clickOpts":{"delayRedirect":true}}' href="http://faceRecogniton.py" rel="nofollow">
      faceRecogniton.py
     </a>
     <span>
      - uses model to perform real-time face detection and recognition
     </span>
    </p>
    <p class="hckui__typography__bodyL">
     I trained the model looking into the camera, so it does not recognize me if I look down or away.
    </p>
    <div class="carousel-images">
     <img class="carousel-image" src="8.jpg"/>
    </div>
    <div class="carousel-images">
     <img class="carousel-image" src="9.jpg"/>
    </div>
    <p class="hckui__typography__bodyL">
     A quick demo using face recognition to unlock the deadbolt.  The delay in lock response after the face is recognized is quite annoying.  I really need to figure out why the BLE API isn't working.
    </p>
    <div class="embed-frame">
     <figure class="youtube">
      <iframe allowfullscreen="" frameborder="0" height="500" src="//www.youtube.com/embed/jk1fToJGQng?rel=0" style="margin: 10px auto; display: block;" width="75%">
      </iframe>
     </figure>
    </div>
    <h3 class="hckui__typography__h3 title-with-anchor" id="toc-cellular-communication-4">
     <p>
      <p class="hckui__typography__bodyL">
      </p>
     </p>
     <span>
      Cellular Communication
     </span>
    </h3>
    <p class="hckui__typography__bodyL">
     I am using a Blues NBGL Notecard with a Notecarrier A to provide the cellular interface.  The Notecard is a device-to-cloud data pump that transmits secure cellular data to the Blues Notehub.  I've used Notecards on quite a few projects and have found then to be very reliable and easy to deploy.  I won't go through the detail of setting up projects on the Notehub as Blues has very comprehensive documentation.
    </p>
    <p class="hckui__typography__bodyL">
     <span>
      I created a project called Build2gether 2.0 on the Notehub.  Here is a quick view of the device on the dashboard:
     </span>
     <br/>
    </p>
    <div class="carousel-images">
     <img class="carousel-image" src="10.jpg"/>
    </div>
    <p class="hckui__typography__bodyL">
     Blues has excellent Notecard libraries for Python and Arduino IDE.  The great feature of the message (note) interface is that all the transactions are done using JSON objects.
    </p>
    <p class="hckui__typography__bodyL">
     Here is the interrupt service routine from the Arduino program that constructs and sends the face recognition note to the Notecard from the Xiao when a Unihiker interrupt is received..
    </p>
    <pre><code><span>void IRAM_ATTR handleInterrupt() {</span><br/><span>  // Enqueue the measurement to the Notecard for transmission to the Notehub,</span><br/><span>  // adding the "sync" flag for demonstration purposes to upload the data</span><br/><span>  // instantaneously. If you are looking at this on notehub.io you will see</span><br/><span>  // the data appearing 'live'.</span><br/><span>  J *req = notecard.newRequest("note.add");</span><br/><span>  if (req != NULL)</span><br/><span>  {</span><br/><span>      JAddBoolToObject(req, "sync", true);</span><br/><span>      J *body = JAddObjectToObject(req, "body");</span><br/><span>      if (body != NULL)</span><br/><span>      {</span><br/><span>          JAddNumberToObject(body, "lockStatus", "Unlocked");</span><br/><span>          JAddNumberToObject(body, "faceID", "Ralph");</span><br/><span>      }</span><br/><span>      notecard.sendRequest(req);</span><br/><span>  }</span><br/><span>  Serial.println("Interrupt detected!");</span><br/><span>}</span></code></pre>
    <p class="hckui__typography__bodyL">
     And the event data that is received from the Notecard in the Notehub project dashboard.
    </p>
    <div class="carousel-images">
     <img class="carousel-image" src="11.jpg"/>
    </div>
    <p class="hckui__typography__bodyL">
     <span>
      A more zoomed in view:
     </span>
     <br/>
    </p>
    <div class="carousel-images">
     <img class="carousel-image" src="12.jpg"/>
    </div>
    <p class="hckui__typography__bodyL">
     The Notehub has a great feature called routes that allows device data to be forwarded to an external APIs like MQTT, Webhooks, or Twilio.  I have not implemented this feature yet but I've used it on other projects to send SMS and email alerts and do data/status logging via MQTT.
    </p>
    <h3 class="hckui__typography__h3 title-with-anchor" id="toc-summary-5">
     <p>
      <p class="hckui__typography__bodyL">
      </p>
     </p>
     <span>
      Summary
     </span>
    </h3>
    <p class="hckui__typography__bodyL">
     I would like to thank the sponsors, admins, and Contest Masters for the opportunity to participate in the Build2Gether 2.0 contest.  I regret that my personal circumstances prevented me from being able complete the project that I had intended.  I do appreciate the feedback that I received on my original proposal.  And I apologize for the lack of comprehensive documentation.
    </p>
    <p class="hckui__typography__bodyL">
     I hope that when/if my issues resolve that I might be able to publish a more complete project later or at the very least do some smaller projects with some of the unused hardware that I received.
    </p>
   </div>
  </section>
  <div class="project-section-break">
  </div>
  <section id="schematics">
   <div class="project-section-title">
    <h2 class="hckui__typography__h2 title-with-anchor">
     <span>
      Schematics
     </span>
    </h2>
   </div>
   <div class="project-attachment">
    <div class="header">
     <div class="text">
      <h3 class="hckui__typography__h3">
       Board Interconnect
      </h3>
      <div class="hckui__typography__bodyS hckui__typography__pebble">
       Wiring between Unihiker , Xiao, and Notecard
      </div>
     </div>
    </div>
    <div class="embed original boxed hckui__typography__textCenter">
     <img src="23.jpg"/>
    </div>
   </div>
  </section>
  <div class="project-section-break">
  </div>
  <section id="code">
   <div class="project-section-title">
    <h2 class="hckui__typography__h2 title-with-anchor">
     <span>
      Code
     </span>
    </h2>
   </div>
   <div class="project-attachment project-code-widget">
    <div class="tabs hckui__typography__bodyS">
     <ul>
      <li class="active">
       <a data-target="#code-widget-656837" href="javascript:void(0)">
        faceRegistration.py
       </a>
      </li>
      <li>
       <a data-target="#code-widget-656838" href="javascript:void(0)">
        faceModelTraining.py
       </a>
      </li>
      <li>
       <a data-target="#code-widget-656919" href="javascript:void(0)">
        faceRecognition.py
       </a>
      </li>
      <li>
       <a data-target="#code-widget-656920" href="javascript:void(0)">
        faceRecognitionUnlock.py
       </a>
      </li>
      <li>
       <a data-target="#code-widget-656921" href="javascript:void(0)">
        Xiao_ESP32S3_NotecardInterrupt.ino
       </a>
      </li>
     </ul>
    </div>
    <div class="preview-container">
     <div class="preview-pane active" id="code-widget-656837">
      <div class="header">
       <div class="text">
        <div class="title">
         <h3 class="hckui__typography__h3">
          faceRegistration.py
         </h3>
         <span class="hckui__typography__bodyS hckui__typography__pebble">
          Python
         </span>
        </div>
        <div class="comment">
         <div class="hckui__typography__bodyS hckui__typography__pebble">
          Collects and labels 50 face images per ID
         </div>
        </div>
       </div>
      </div>
      <div class="preview-body pygments-syntax all">
       <div class="highlight">
        <pre><span></span><span id="line-1"><span class="sd">'''</span>
</span><span id="line-2"><span class="sd">Run the program, enter the ID in the terminal and press Enter. The screen will display the camera image. Adjust the position until a green box appears, indicating that the photo is being taken. When "done" is displayed, the process is complete.</span>
</span><span id="line-3"><span class="sd">The captured images will be saved in the "/root/image/project14/new" folder. This code captures 50 images, but you can modify the code parameters to capture more images.</span>
</span><span id="line-4"><span class="sd">'''</span>
</span><span id="line-5"> 
</span><span id="line-6"><span class="kn">import</span> <span class="nn">cv2</span>  <span class="c1"># Import the OpenCV library</span>
</span><span id="line-7"><span class="kn">import</span> <span class="nn">os</span>  <span class="c1"># Import the os library</span>
</span><span id="line-8"> 
</span><span id="line-9"><span class="n">img_src</span> <span class="o">=</span> <span class="s1">'/root/image/project14'</span>  <span class="c1"># Define the image path (Specify to a fixed location in Mind+)</span>
</span><span id="line-10"><span class="n">os</span><span class="o">.</span><span class="n">system</span><span class="p">(</span><span class="s1">'mkdir -p '</span> <span class="o">+</span> <span class="n">img_src</span> <span class="o">+</span> <span class="s1">'/new1/'</span><span class="p">)</span>  <span class="c1"># Create a folder named "new" in the specified path (The folder needs to be created first before storing the images)</span>
</span><span id="line-11"><span class="c1"># img_src = os.getcwd()  # Specify the current working directory if running directly</span>
</span><span id="line-12"> 
</span><span id="line-13"><span class="n">cap</span> <span class="o">=</span> <span class="n">cv2</span><span class="o">.</span><span class="n">VideoCapture</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>  <span class="c1"># Open and initialize the camera</span>
</span><span id="line-14"><span class="n">cap</span><span class="o">.</span><span class="n">set</span><span class="p">(</span><span class="n">cv2</span><span class="o">.</span><span class="n">CAP_PROP_BUFFERSIZE</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>  <span class="c1"># Set the buffer size to 1 frame to reduce latency</span>
</span><span id="line-15"><span class="n">cv2</span><span class="o">.</span><span class="n">namedWindow</span><span class="p">(</span><span class="s1">'frame'</span><span class="p">,</span> <span class="n">cv2</span><span class="o">.</span><span class="n">WND_PROP_FULLSCREEN</span><span class="p">)</span>  <span class="c1"># Create a window named 'frame' with the default property of being able to go fullscreen</span>
</span><span id="line-16"><span class="n">cv2</span><span class="o">.</span><span class="n">setWindowProperty</span><span class="p">(</span><span class="s1">'frame'</span><span class="p">,</span> <span class="n">cv2</span><span class="o">.</span><span class="n">WND_PROP_FULLSCREEN</span><span class="p">,</span> <span class="n">cv2</span><span class="o">.</span><span class="n">WINDOW_FULLSCREEN</span><span class="p">)</span>  <span class="c1"># Set the 'frame' window to fullscreen</span>
</span><span id="line-17"> 
</span><span id="line-18"><span class="n">font</span> <span class="o">=</span> <span class="n">cv2</span><span class="o">.</span><span class="n">FONT_HERSHEY_SIMPLEX</span>  <span class="c1"># Set the font type to a normal-sized sans-serif font</span>
</span><span id="line-19"><span class="n">detector</span> <span class="o">=</span> <span class="n">cv2</span><span class="o">.</span><span class="n">CascadeClassifier</span><span class="p">(</span><span class="n">cv2</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">haarcascades</span> <span class="o">+</span> <span class="s1">'haarcascade_frontalface_default.xml'</span><span class="p">)</span>  <span class="c1"># Load the face detection classifier</span>
</span><span id="line-20"><span class="n">sampleNum</span> <span class="o">=</span> <span class="mi">0</span>  <span class="c1"># Initialize the sample number to 0</span>
</span><span id="line-21"><span class="n">ID</span> <span class="o">=</span> <span class="nb">input</span><span class="p">(</span><span class="s1">'enter your id: '</span><span class="p">)</span>  <span class="c1"># Enter the ID number for the face image data</span>
</span><span id="line-22"> 
</span><span id="line-23"><span class="k">while</span> <span class="kc">True</span><span class="p">:</span>
</span><span id="line-24">    <span class="n">ret</span><span class="p">,</span> <span class="n">img</span> <span class="o">=</span> <span class="n">cap</span><span class="o">.</span><span class="n">read</span><span class="p">()</span>  <span class="c1"># Read the image frame by frame</span>
</span><span id="line-25">    <span class="c1"># img = cv2.flip(img, 1)  # Mirror the image (horizontally flip the img image)</span>
</span><span id="line-26">    <span class="c1">#img = cv2.flip(img, 0)  # Mirror the image (vertically flip the img image)</span>
</span><span id="line-27">    <span class="k">if</span> <span class="n">ret</span><span class="p">:</span>  <span class="c1"># If an image is successfully read</span>
</span><span id="line-28">        <span class="n">h</span><span class="p">,</span> <span class="n">w</span><span class="p">,</span> <span class="n">c</span> <span class="o">=</span> <span class="n">img</span><span class="o">.</span><span class="n">shape</span>  <span class="c1"># Record the shape of the image, which includes the height, width, and channels</span>
</span><span id="line-29">        <span class="n">w1</span> <span class="o">=</span> <span class="n">h</span> <span class="o">*</span> <span class="mi">240</span> <span class="o">//</span> <span class="mi">320</span>
</span><span id="line-30">        <span class="n">x1</span> <span class="o">=</span> <span class="p">(</span><span class="n">w</span> <span class="o">-</span> <span class="n">w1</span><span class="p">)</span> <span class="o">//</span> <span class="mi">2</span>
</span><span id="line-31">        <span class="n">img</span> <span class="o">=</span> <span class="n">img</span><span class="p">[:,</span> <span class="n">x1</span><span class="p">:</span><span class="n">x1</span> <span class="o">+</span> <span class="n">w1</span><span class="p">]</span>  <span class="c1"># Crop the image</span>
</span><span id="line-32">        <span class="n">img</span> <span class="o">=</span> <span class="n">cv2</span><span class="o">.</span><span class="n">resize</span><span class="p">(</span><span class="n">img</span><span class="p">,</span> <span class="p">(</span><span class="mi">240</span><span class="p">,</span> <span class="mi">320</span><span class="p">))</span>  <span class="c1"># Resize the image to match the dimensions of the PinPong board</span>
</span><span id="line-33">        <span class="n">gray</span> <span class="o">=</span> <span class="n">cv2</span><span class="o">.</span><span class="n">cvtColor</span><span class="p">(</span><span class="n">img</span><span class="p">,</span> <span class="n">cv2</span><span class="o">.</span><span class="n">COLOR_BGR2GRAY</span><span class="p">)</span>  <span class="c1"># Convert the image to grayscale</span>
</span><span id="line-34">        <span class="n">faces</span> <span class="o">=</span> <span class="n">detector</span><span class="o">.</span><span class="n">detectMultiScale</span><span class="p">(</span><span class="n">gray</span><span class="p">,</span> <span class="mf">1.3</span><span class="p">,</span> <span class="mi">5</span><span class="p">)</span>  <span class="c1"># Detect and obtain face recognition data</span>
</span><span id="line-35">        <span class="k">for</span> <span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">w</span><span class="p">,</span> <span class="n">h</span><span class="p">)</span> <span class="ow">in</span> <span class="n">faces</span><span class="p">:</span>  <span class="c1"># If a face is detected</span>
</span><span id="line-36">            <span class="n">cv2</span><span class="o">.</span><span class="n">rectangle</span><span class="p">(</span><span class="n">img</span><span class="p">,</span> <span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">),</span> <span class="p">(</span><span class="n">x</span> <span class="o">+</span> <span class="n">w</span><span class="p">,</span> <span class="n">y</span> <span class="o">+</span> <span class="n">h</span><span class="p">),</span> <span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">255</span><span class="p">,</span> <span class="mi">0</span><span class="p">),</span> <span class="mi">2</span><span class="p">)</span>  <span class="c1"># Draw a rectangle box around the face</span>
</span><span id="line-37">            <span class="n">sampleNum</span> <span class="o">=</span> <span class="n">sampleNum</span> <span class="o">+</span> <span class="mi">1</span>  <span class="c1"># Increment the sample number</span>
</span><span id="line-38">            <span class="k">if</span> <span class="n">sampleNum</span> <span class="o">&lt;=</span> <span class="mi">50</span><span class="p">:</span>  <span class="c1"># If the number of samples is less than or equal to 50</span>
</span><span id="line-39">                <span class="n">cv2</span><span class="o">.</span><span class="n">putText</span><span class="p">(</span><span class="n">img</span><span class="p">,</span> <span class="s1">'shooting'</span><span class="p">,</span> <span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="mi">50</span><span class="p">),</span> <span class="n">font</span><span class="p">,</span> <span class="mf">0.6</span><span class="p">,</span> <span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">255</span><span class="p">,</span> <span class="mi">0</span><span class="p">),</span> <span class="mi">2</span><span class="p">)</span>  <span class="c1"># Display the text "shooting" on the image, indicating that the face is being captured</span>
</span><span id="line-40">                <span class="c1"># Save the cropped face image with a name format of sampleNum.UserID.jpg</span>
</span><span id="line-41">                <span class="n">cv2</span><span class="o">.</span><span class="n">imwrite</span><span class="p">(</span><span class="n">img_src</span> <span class="o">+</span> <span class="s1">'/new1/'</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">sampleNum</span><span class="p">)</span> <span class="o">+</span> <span class="s1">'.'</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">ID</span><span class="p">)</span> <span class="o">+</span> <span class="s2">".jpg"</span><span class="p">,</span> <span class="n">gray</span><span class="p">[</span><span class="n">y</span><span class="p">:</span><span class="n">y</span> <span class="o">+</span> <span class="n">h</span><span class="p">,</span> <span class="n">x</span><span class="p">:</span><span class="n">x</span> <span class="o">+</span> <span class="n">w</span><span class="p">])</span>
</span><span id="line-42">            <span class="k">else</span><span class="p">:</span>  <span class="c1"># If the number of images exceeds 50</span>
</span><span id="line-43">                <span class="n">cv2</span><span class="o">.</span><span class="n">putText</span><span class="p">(</span><span class="n">img</span><span class="p">,</span> <span class="s1">'Done, Please quit'</span><span class="p">,</span> <span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="mi">50</span><span class="p">),</span> <span class="n">font</span><span class="p">,</span> <span class="mf">0.6</span><span class="p">,</span> <span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">255</span><span class="p">,</span> <span class="mi">0</span><span class="p">),</span> <span class="mi">2</span><span class="p">)</span>  <span class="c1"># Display the text "Done, Please quit" to indicate completion</span>
</span><span id="line-44">                <span class="k">break</span>
</span><span id="line-45">        <span class="n">cv2</span><span class="o">.</span><span class="n">imshow</span><span class="p">(</span><span class="s1">'frame'</span><span class="p">,</span> <span class="n">img</span><span class="p">)</span>  <span class="c1"># Display the image on the 'frame' window</span>
</span><span id="line-46"> 
</span><span id="line-47">        <span class="n">key</span> <span class="o">=</span> <span class="n">cv2</span><span class="o">.</span><span class="n">waitKey</span><span class="p">(</span><span class="mi">2</span><span class="p">)</span>  <span class="c1"># Delay each frame by 1ms, delay cannot be 0, otherwise the result will be a static frame</span>
</span><span id="line-48"><span class="c1">#        if key &amp; 0xFF == ord('b'):  # Press 'b' to exit</span>
</span><span id="line-49">        <span class="k">if</span> <span class="n">key</span> <span class="o">&amp;</span> <span class="mh">0xFF</span> <span class="o">==</span> <span class="mi">113</span><span class="p">:</span>  <span class="c1"># Press 'q' to exit</span>
</span><span id="line-50">            <span class="k">break</span>
</span><span id="line-51"> 
</span><span id="line-52"><span class="n">cap</span><span class="o">.</span><span class="n">release</span><span class="p">()</span>  <span class="c1"># Release the camera</span>
</span><span id="line-53"><span class="n">cv2</span><span class="o">.</span><span class="n">destroyAllWindows</span><span class="p">()</span>  <span class="c1"># Close all windows</span>
</span></pre>
       </div>
      </div>
     </div>
     <div class="preview-pane" id="code-widget-656838">
      <div class="header">
       <div class="text">
        <div class="title">
         <h3 class="hckui__typography__h3">
          faceModelTraining.py
         </h3>
         <span class="hckui__typography__bodyS hckui__typography__pebble">
          Python
         </span>
        </div>
        <div class="comment">
         <div class="hckui__typography__bodyS hckui__typography__pebble">
          Builds face recognition model using labeled images
         </div>
        </div>
       </div>
      </div>
      <div class="preview-body pygments-syntax all">
       <div class="highlight">
        <pre><span></span><span id="line-1"><span class="c1"># Train the Captured Face Images and Generate the model.yml (Located at the same level as the 'new' folder)</span>
</span><span id="line-2"><span class="kn">import</span> <span class="nn">cv2</span>  <span class="c1"># Import the OpenCV library</span>
</span><span id="line-3"><span class="kn">import</span> <span class="nn">os</span>  <span class="c1"># Import the os library</span>
</span><span id="line-4"><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>  <span class="c1"># Import the numpy library</span>
</span><span id="line-5"><span class="kn">from</span> <span class="nn">PIL</span> <span class="kn">import</span> <span class="n">Image</span>  <span class="c1"># Import the Image module from the PIL library</span>
</span><span id="line-6"> 
</span><span id="line-7"><span class="n">img_src</span> <span class="o">=</span> <span class="s1">'/root/image/project14'</span>  <span class="c1"># Define the save path (Specify to a fixed location in Mind+)</span>
</span><span id="line-8"> 
</span><span id="line-9"><span class="c1"># Initialize the face detector and recognizer</span>
</span><span id="line-10"><span class="n">detector</span> <span class="o">=</span> <span class="n">cv2</span><span class="o">.</span><span class="n">CascadeClassifier</span><span class="p">(</span><span class="n">cv2</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">haarcascades</span> <span class="o">+</span> <span class="s1">'haarcascade_frontalface_default.xml'</span><span class="p">)</span>  <span class="c1"># Load the face detection classifier</span>
</span><span id="line-11"><span class="n">recognizer</span> <span class="o">=</span> <span class="n">cv2</span><span class="o">.</span><span class="n">face</span><span class="o">.</span><span class="n">LBPHFaceRecognizer_create</span><span class="p">()</span>  <span class="c1"># Create an instance of the LBPH recognizer model (empty)</span>
</span><span id="line-12"> 
</span><span id="line-13"><span class="sd">'''</span>
</span><span id="line-14"><span class="sd">Traverse the image path, import images and IDs, and add them to the list</span>
</span><span id="line-15"><span class="sd">'''</span>
</span><span id="line-16"><span class="k">def</span> <span class="nf">get_images_and_labels</span><span class="p">(</span><span class="n">path</span><span class="p">):</span>
</span><span id="line-17">    <span class="c1"># Concatenate the image path to the specific image name, such as '/root/image/project14/new/50.1.jpg', and store it in the 'image_paths' list</span>
</span><span id="line-18">    <span class="n">image_paths</span> <span class="o">=</span> <span class="p">[</span><span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">path</span><span class="p">,</span> <span class="n">f</span><span class="p">)</span> <span class="k">for</span> <span class="n">f</span> <span class="ow">in</span> <span class="n">os</span><span class="o">.</span><span class="n">listdir</span><span class="p">(</span><span class="n">path</span><span class="p">)]</span>
</span><span id="line-19">    <span class="c1"># Create an empty list for face samples</span>
</span><span id="line-20">    <span class="n">face_samples</span> <span class="o">=</span> <span class="p">[]</span>
</span><span id="line-21">    <span class="c1"># Create an empty list for IDs</span>
</span><span id="line-22">    <span class="n">ids</span> <span class="o">=</span> <span class="p">[]</span>
</span><span id="line-23">    <span class="k">for</span> <span class="n">image_path</span> <span class="ow">in</span> <span class="n">image_paths</span><span class="p">:</span>  <span class="c1"># Traverse the image path</span>
</span><span id="line-24">        <span class="c1"># Print the name of each image (image name with path)</span>
</span><span id="line-25">        <span class="nb">print</span><span class="p">(</span><span class="n">image_path</span><span class="p">)</span>
</span><span id="line-26">        <span class="c1"># Convert the color image to grayscale</span>
</span><span id="line-27">        <span class="n">image</span> <span class="o">=</span> <span class="n">Image</span><span class="o">.</span><span class="n">open</span><span class="p">(</span><span class="n">image_path</span><span class="p">)</span><span class="o">.</span><span class="n">convert</span><span class="p">(</span><span class="s1">'L'</span><span class="p">)</span>
</span><span id="line-28">        <span class="c1"># Convert the grayscale image format to a Numpy array</span>
</span><span id="line-29">        <span class="n">image_np</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">image</span><span class="p">,</span> <span class="s1">'uint8'</span><span class="p">)</span>
</span><span id="line-30">        <span class="sd">'''To get the ID, we split the image path and retrieve the relevant information'''</span>
</span><span id="line-31">        <span class="c1"># Split by ".", if the last group is "jpg", then execute the following steps</span>
</span><span id="line-32">        <span class="k">if</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="n">image_path</span><span class="p">)[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s2">"."</span><span class="p">)[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span> <span class="o">!=</span> <span class="s1">'jpg'</span><span class="p">:</span>
</span><span id="line-33">            <span class="k">continue</span>
</span><span id="line-34">        <span class="c1"># Extract the ID number from the complete path name of the image, which is the ID number we set when capturing the image</span>
</span><span id="line-35">        <span class="n">image_id</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="n">image_path</span><span class="p">)[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s2">"."</span><span class="p">)[</span><span class="mi">1</span><span class="p">])</span>
</span><span id="line-36">        <span class="c1"># Detect the face in the array format and store the results in 'faces'</span>
</span><span id="line-37">        <span class="n">faces</span> <span class="o">=</span> <span class="n">detector</span><span class="o">.</span><span class="n">detectMultiScale</span><span class="p">(</span><span class="n">image_np</span><span class="p">)</span>  <span class="c1"># Detect faces</span>
</span><span id="line-38">        <span class="c1"># Crop out the face portion from the array format face image and store them in the face samples list, and store the ID number of the image in the ID samples list</span>
</span><span id="line-39">        <span class="k">for</span> <span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">w</span><span class="p">,</span> <span class="n">h</span><span class="p">)</span> <span class="ow">in</span> <span class="n">faces</span><span class="p">:</span>
</span><span id="line-40">            <span class="n">face_samples</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">image_np</span><span class="p">[</span><span class="n">y</span><span class="p">:</span><span class="n">y</span> <span class="o">+</span> <span class="n">h</span><span class="p">,</span> <span class="n">x</span><span class="p">:</span><span class="n">x</span> <span class="o">+</span> <span class="n">w</span><span class="p">])</span>
</span><span id="line-41">            <span class="n">ids</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">image_id</span><span class="p">)</span>
</span><span id="line-42">    <span class="k">return</span> <span class="n">face_samples</span><span class="p">,</span> <span class="n">ids</span>  <span class="c1"># Return the face samples list and ID samples list</span>
</span><span id="line-43"> 
</span><span id="line-44"><span class="c1"># Train the LBPH recognizer model with the face samples and ID samples, and output the corresponding face model (.yml format file)</span>
</span><span id="line-45"><span class="n">faces</span><span class="p">,</span> <span class="n">Ids</span> <span class="o">=</span> <span class="n">get_images_and_labels</span><span class="p">(</span><span class="n">img_src</span><span class="o">+</span><span class="s1">'/new1/'</span><span class="p">)</span>  <span class="c1"># Pass in the path and the folder name of the image to get the face samples list and ID samples list</span>
</span><span id="line-46"><span class="n">recognizer</span><span class="o">.</span><span class="n">train</span><span class="p">(</span><span class="n">faces</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">Ids</span><span class="p">))</span>  <span class="c1"># Pass the face samples list and ID samples list to the empty LBPH recognizer model to get a complete face model</span>
</span><span id="line-47"><span class="n">recognizer</span><span class="o">.</span><span class="n">save</span><span class="p">(</span><span class="n">img_src</span><span class="o">+</span><span class="s1">'/model.yml'</span><span class="p">)</span>  <span class="c1"># Save the generated model</span>
</span><span id="line-48"><span class="nb">print</span><span class="p">(</span><span class="s2">"generate model done"</span><span class="p">)</span>  <span class="c1"># Print "Model has been generated"</span>
</span></pre>
       </div>
      </div>
     </div>
     <div class="preview-pane" id="code-widget-656919">
      <div class="header">
       <div class="text">
        <div class="title">
         <h3 class="hckui__typography__h3">
          faceRecognition.py
         </h3>
         <span class="hckui__typography__bodyS hckui__typography__pebble">
          Python
         </span>
        </div>
        <div class="comment">
         <div class="hckui__typography__bodyS hckui__typography__pebble">
          Display ID labels on detected faces
         </div>
        </div>
       </div>
      </div>
      <div class="preview-body pygments-syntax all">
       <div class="highlight">
        <pre><span></span><span id="line-1"><span class="sd">'''</span>
</span><span id="line-2"><span class="sd">Run this program to predict faces using the trained face model. When a trained face is detected, display the ID number and rotate the servo to 170° to open the door. When an unfamiliar face is detected, display "unknown". The more images collected, the higher the recognition accuracy.</span>
</span><span id="line-3"><span class="sd">'''</span>
</span><span id="line-4"><span class="kn">import</span> <span class="nn">cv2</span>  <span class="c1"># Import the OpenCV library</span>
</span><span id="line-5"><span class="kn">from</span> <span class="nn">pinpong.board</span> <span class="kn">import</span> <span class="n">Board</span><span class="p">,</span> <span class="n">Pin</span><span class="p">,</span> <span class="n">Servo</span>  <span class="c1"># Import the Pinpong library</span>
</span><span id="line-6"><span class="kn">import</span> <span class="nn">time</span>  <span class="c1"># Import the time library</span>
</span><span id="line-7"> 
</span><span id="line-8"><span class="n">Board</span><span class="p">(</span><span class="s2">"UNIHIKER"</span><span class="p">)</span><span class="o">.</span><span class="n">begin</span><span class="p">()</span>  <span class="c1"># Initialize and select the board type, if not specified, it will be automatically recognized</span>
</span><span id="line-9"> 
</span><span id="line-10"><span class="n">s1</span> <span class="o">=</span> <span class="n">Servo</span><span class="p">(</span><span class="n">Pin</span><span class="p">(</span><span class="n">Pin</span><span class="o">.</span><span class="n">P23</span><span class="p">))</span>  <span class="c1"># Initialize the servo pin by passing it to the Servo class</span>
</span><span id="line-11"><span class="n">s1</span><span class="o">.</span><span class="n">angle</span><span class="p">(</span><span class="mi">10</span><span class="p">)</span>  <span class="c1"># Control the servo to rotate to the initial position of 10 degrees (closed door)</span>
</span><span id="line-12"><span class="n">time</span><span class="o">.</span><span class="n">sleep</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>
</span><span id="line-13"> 
</span><span id="line-14"><span class="n">img_src</span> <span class="o">=</span> <span class="s1">'/root/image/project14'</span>  <span class="c1"># Define the save path (Specify to a fixed location in Mind+)</span>
</span><span id="line-15"> 
</span><span id="line-16"><span class="n">cap</span> <span class="o">=</span> <span class="n">cv2</span><span class="o">.</span><span class="n">VideoCapture</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>  <span class="c1"># Open the camera with index 0 and initialize</span>
</span><span id="line-17"><span class="n">cap</span><span class="o">.</span><span class="n">set</span><span class="p">(</span><span class="n">cv2</span><span class="o">.</span><span class="n">CAP_PROP_BUFFERSIZE</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>  <span class="c1"># Set the buffer to 1 frame to reduce latency</span>
</span><span id="line-18"><span class="n">cv2</span><span class="o">.</span><span class="n">namedWindow</span><span class="p">(</span><span class="s1">'frame'</span><span class="p">,</span> <span class="n">cv2</span><span class="o">.</span><span class="n">WND_PROP_FULLSCREEN</span><span class="p">)</span>  <span class="c1"># Create a window with the name 'frame', and set its property to fullscreen</span>
</span><span id="line-19"><span class="n">cv2</span><span class="o">.</span><span class="n">setWindowProperty</span><span class="p">(</span><span class="s1">'frame'</span><span class="p">,</span> <span class="n">cv2</span><span class="o">.</span><span class="n">WND_PROP_FULLSCREEN</span><span class="p">,</span> <span class="n">cv2</span><span class="o">.</span><span class="n">WINDOW_FULLSCREEN</span><span class="p">)</span>  <span class="c1"># Set the 'frame' window to fullscreen</span>
</span><span id="line-20"><span class="n">font</span> <span class="o">=</span> <span class="n">cv2</span><span class="o">.</span><span class="n">FONT_HERSHEY_SIMPLEX</span>  <span class="c1"># Set the font type to normal-sized sans-serif</span>
</span><span id="line-21"> 
</span><span id="line-22"><span class="sd">'''Initialize the face detector and recognizer, and use the previously trained .yml file to recognize faces'''</span>
</span><span id="line-23"><span class="n">detector</span> <span class="o">=</span> <span class="n">cv2</span><span class="o">.</span><span class="n">CascadeClassifier</span><span class="p">(</span><span class="n">cv2</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">haarcascades</span> <span class="o">+</span> <span class="s1">'haarcascade_frontalface_default.xml'</span><span class="p">)</span>  <span class="c1"># Load the face detection classifier</span>
</span><span id="line-24"><span class="n">recognizer</span> <span class="o">=</span> <span class="n">cv2</span><span class="o">.</span><span class="n">face</span><span class="o">.</span><span class="n">LBPHFaceRecognizer_create</span><span class="p">()</span>  <span class="c1"># Create an instance of the LBPH recognizer model</span>
</span><span id="line-25"><span class="n">recognizer</span><span class="o">.</span><span class="n">read</span><span class="p">(</span><span class="n">img_src</span> <span class="o">+</span> <span class="s1">'/model.yml'</span><span class="p">)</span>  <span class="c1"># Read the trained face model from the specified path</span>
</span><span id="line-26"> 
</span><span id="line-27"><span class="n">count</span> <span class="o">=</span> <span class="mi">0</span>  <span class="c1"># Define a count flag</span>
</span><span id="line-28"> 
</span><span id="line-29"><span class="k">while</span> <span class="kc">True</span><span class="p">:</span>
</span><span id="line-30">    <span class="n">ret</span><span class="p">,</span> <span class="n">img</span> <span class="o">=</span> <span class="n">cap</span><span class="o">.</span><span class="n">read</span><span class="p">()</span>  <span class="c1"># Read the image frame by frame</span>
</span><span id="line-31">    <span class="c1"># img = cv2.flip(img, 1)  # Mirror the image (horizontally flip the img image)</span>
</span><span id="line-32">    <span class="k">if</span> <span class="n">ret</span><span class="p">:</span>  <span class="c1"># If an image is read successfully</span>
</span><span id="line-33">        <span class="n">h</span><span class="p">,</span> <span class="n">w</span><span class="p">,</span> <span class="n">c</span> <span class="o">=</span> <span class="n">img</span><span class="o">.</span><span class="n">shape</span>  <span class="c1"># Record the shape of the image, including height, width, and channels</span>
</span><span id="line-34">        <span class="n">w1</span> <span class="o">=</span> <span class="n">h</span> <span class="o">*</span> <span class="mi">240</span> <span class="o">//</span> <span class="mi">320</span>
</span><span id="line-35">        <span class="n">x1</span> <span class="o">=</span> <span class="p">(</span><span class="n">w</span> <span class="o">-</span> <span class="n">w1</span><span class="p">)</span> <span class="o">//</span> <span class="mi">2</span>
</span><span id="line-36">        <span class="n">img</span> <span class="o">=</span> <span class="n">img</span><span class="p">[:,</span> <span class="n">x1</span><span class="p">:</span><span class="n">x1</span> <span class="o">+</span> <span class="n">w1</span><span class="p">]</span>  <span class="c1"># Crop the image</span>
</span><span id="line-37">        <span class="n">img</span> <span class="o">=</span> <span class="n">cv2</span><span class="o">.</span><span class="n">resize</span><span class="p">(</span><span class="n">img</span><span class="p">,</span> <span class="p">(</span><span class="mi">240</span><span class="p">,</span> <span class="mi">320</span><span class="p">))</span>  <span class="c1"># Resize the image to match the UNIHIKER display</span>
</span><span id="line-38">        <span class="n">gray</span> <span class="o">=</span> <span class="n">cv2</span><span class="o">.</span><span class="n">cvtColor</span><span class="p">(</span><span class="n">img</span><span class="p">,</span> <span class="n">cv2</span><span class="o">.</span><span class="n">COLOR_BGR2GRAY</span><span class="p">)</span>  <span class="c1"># Convert the image to grayscale</span>
</span><span id="line-39">        <span class="n">faces</span> <span class="o">=</span> <span class="n">detector</span><span class="o">.</span><span class="n">detectMultiScale</span><span class="p">(</span><span class="n">gray</span><span class="p">,</span> <span class="mf">1.2</span><span class="p">,</span> <span class="mi">5</span><span class="p">)</span>  <span class="c1"># Detect and obtain face recognition data</span>
</span><span id="line-40">        <span class="k">for</span> <span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">w</span><span class="p">,</span> <span class="n">h</span><span class="p">)</span> <span class="ow">in</span> <span class="n">faces</span><span class="p">:</span>
</span><span id="line-41">            <span class="n">cv2</span><span class="o">.</span><span class="n">rectangle</span><span class="p">(</span><span class="n">img</span><span class="p">,</span> <span class="p">(</span><span class="n">x</span> <span class="o">-</span> <span class="mi">50</span><span class="p">,</span> <span class="n">y</span> <span class="o">-</span> <span class="mi">50</span><span class="p">),</span> <span class="p">(</span><span class="n">x</span> <span class="o">+</span> <span class="n">w</span> <span class="o">+</span> <span class="mi">50</span><span class="p">,</span> <span class="n">y</span> <span class="o">+</span> <span class="n">h</span> <span class="o">+</span> <span class="mi">50</span><span class="p">),</span> <span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">255</span><span class="p">,</span> <span class="mi">0</span><span class="p">),</span> <span class="mi">2</span><span class="p">)</span>  <span class="c1"># Draw a rectangular box around the face</span>
</span><span id="line-42">            <span class="n">img_id</span><span class="p">,</span> <span class="n">confidence</span> <span class="o">=</span> <span class="n">recognizer</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">gray</span><span class="p">[</span><span class="n">y</span><span class="p">:</span><span class="n">y</span> <span class="o">+</span> <span class="n">h</span><span class="p">,</span> <span class="n">x</span><span class="p">:</span><span class="n">x</span> <span class="o">+</span> <span class="n">w</span><span class="p">])</span>  <span class="c1"># Predict on the grayscale image within the specified rectangular region (used for face presentation)</span>
</span><span id="line-43">            <span class="k">if</span> <span class="n">confidence</span> <span class="o">&lt;</span> <span class="mi">90</span><span class="p">:</span>  <span class="c1"># If confidence &lt; 80, it means a trained face is detected</span>
</span><span id="line-44">                <span class="k">if</span> <span class="n">img_id</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
</span><span id="line-45">                    <span class="n">img_id</span> <span class="o">=</span> <span class="s2">"Ralph"</span>
</span><span id="line-46">                <span class="n">cv2</span><span class="o">.</span><span class="n">putText</span><span class="p">(</span><span class="n">img</span><span class="p">,</span> <span class="s2">"Welcome Home"</span><span class="p">,</span> <span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">),</span> <span class="n">font</span><span class="p">,</span> <span class="mf">0.6</span><span class="p">,</span> <span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">255</span><span class="p">,</span> <span class="mi">0</span><span class="p">),</span> <span class="mi">2</span><span class="p">)</span>  <span class="c1"># Add the text "Welcome Home" to the specified position on the image</span>
</span><span id="line-47">                <span class="n">cv2</span><span class="o">.</span><span class="n">putText</span><span class="p">(</span><span class="n">img</span><span class="p">,</span> <span class="nb">str</span><span class="p">(</span><span class="n">img_id</span><span class="p">),</span> <span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span> <span class="o">+</span> <span class="n">h</span><span class="p">),</span> <span class="n">font</span><span class="p">,</span> <span class="mf">0.6</span><span class="p">,</span> <span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">255</span><span class="p">,</span> <span class="mi">0</span><span class="p">),</span> <span class="mi">2</span><span class="p">)</span>  <span class="c1"># Add the corresponding face ID label to the specified position on the image</span>
</span><span id="line-48">                <span class="k">if</span> <span class="n">count</span> <span class="o">==</span> <span class="mi">2</span><span class="p">:</span>  <span class="c1"># On the third frame</span>
</span><span id="line-49">                    <span class="c1">#s1.angle(170)  # Control the servo to rotate to the position of 170 degrees (open the door)</span>
</span><span id="line-50">                    <span class="nb">print</span><span class="p">(</span><span class="s2">"The door is open"</span><span class="p">)</span>
</span><span id="line-51">                    <span class="n">time</span><span class="o">.</span><span class="n">sleep</span><span class="p">(</span><span class="mi">5</span><span class="p">)</span>  <span class="c1"># Wait for five seconds</span>
</span><span id="line-52">                    <span class="c1">#s1.angle(10)  # Control the servo to rotate to the position of 10 degrees (close the door)</span>
</span><span id="line-53">                    <span class="nb">print</span><span class="p">(</span><span class="s2">"The door is closed"</span><span class="p">)</span>
</span><span id="line-54">                    <span class="n">count</span> <span class="o">=</span> <span class="mi">0</span>  <span class="c1"># Reset the count</span>
</span><span id="line-55">                <span class="k">else</span><span class="p">:</span>
</span><span id="line-56">                    <span class="c1">#s1.angle(10)</span>
</span><span id="line-57">                    <span class="n">count</span> <span class="o">=</span> <span class="n">count</span> <span class="o">+</span> <span class="mi">1</span>  <span class="c1"># Increment the frame count</span>
</span><span id="line-58">            <span class="c1">#else:  # If an unknown face is detected</span>
</span><span id="line-59">                <span class="c1">#img_id = "unknown"</span>
</span><span id="line-60">                <span class="c1">#cv2.putText(img, str(img_id), (x, y + h), font, 0.6, (0, 255, 0), 2)  # Add the text "unknown" to the specified position on the image</span>
</span><span id="line-61">        <span class="n">cv2</span><span class="o">.</span><span class="n">imshow</span><span class="p">(</span><span class="s1">'frame'</span><span class="p">,</span> <span class="n">img</span><span class="p">)</span>  <span class="c1"># Display the image</span>
</span><span id="line-62">        <span class="n">key</span> <span class="o">=</span> <span class="n">cv2</span><span class="o">.</span><span class="n">waitKey</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>  <span class="c1"># Delay each frame by 1ms, delay cannot be 0, otherwise the result will be a static frame</span>
</span><span id="line-63">        <span class="k">if</span> <span class="n">key</span> <span class="o">&amp;</span> <span class="mh">0xFF</span> <span class="o">==</span> <span class="nb">ord</span><span class="p">(</span><span class="s1">'b'</span><span class="p">):</span>  <span class="c1"># Press 'b' to exit</span>
</span><span id="line-64">            <span class="k">break</span>
</span><span id="line-65"> 
</span><span id="line-66"><span class="n">cap</span><span class="o">.</span><span class="n">release</span><span class="p">()</span>  <span class="c1"># Release the camera</span>
</span><span id="line-67"><span class="n">cv2</span><span class="o">.</span><span class="n">destroyAllWindows</span><span class="p">()</span>  <span class="c1"># Close all windows</span>
</span></pre>
       </div>
      </div>
     </div>
     <div class="preview-pane" id="code-widget-656920">
      <div class="header">
       <div class="text">
        <div class="title">
         <h3 class="hckui__typography__h3">
          faceRecognitionUnlock.py
         </h3>
         <span class="hckui__typography__bodyS hckui__typography__pebble">
          Python
         </span>
        </div>
        <div class="comment">
         <div class="hckui__typography__bodyS hckui__typography__pebble">
          Locks or unlocks depending on whether detected face is recognized
         </div>
        </div>
       </div>
      </div>
      <div class="preview-body pygments-syntax all">
       <div class="highlight">
        <pre><span></span><span id="line-1"><span class="sd">'''</span>
</span><span id="line-2"><span class="sd">Run this program to predict faces using the trained face model. When a trained face is detected, display the ID number and rotate the servo to 170° to open the door. When an unfamiliar face is detected, display "unknown". The more images collected, the higher the recognition accuracy.</span>
</span><span id="line-3"><span class="sd">'''</span>
</span><span id="line-4"><span class="kn">import</span> <span class="nn">cv2</span>  <span class="c1"># Import the OpenCV library</span>
</span><span id="line-5"><span class="kn">from</span> <span class="nn">pinpong.board</span> <span class="kn">import</span> <span class="n">Board</span><span class="p">,</span> <span class="n">Pin</span><span class="p">,</span> <span class="n">Servo</span>  <span class="c1"># Import the Pinpong library</span>
</span><span id="line-6"><span class="kn">import</span> <span class="nn">time</span>  <span class="c1"># Import the time library</span>
</span><span id="line-7"><span class="kn">import</span> <span class="nn">json</span>
</span><span id="line-8"><span class="kn">import</span> <span class="nn">hashlib</span>
</span><span id="line-9"><span class="kn">import</span> <span class="nn">hmac</span>
</span><span id="line-10"><span class="kn">import</span> <span class="nn">base64</span>
</span><span id="line-11"><span class="kn">import</span> <span class="nn">uuid</span>
</span><span id="line-12"><span class="kn">import</span> <span class="nn">requests</span>
</span><span id="line-13">
</span><span id="line-14"><span class="c1"># Replace with your actual device ID</span>
</span><span id="line-15"><span class="n">DEVICE_ID</span> <span class="o">=</span> <span class="s1">'FA25793937EC'</span>
</span><span id="line-16"><span class="c1"># Base URL for the SwitchBot API</span>
</span><span id="line-17"><span class="n">BASE_URL</span> <span class="o">=</span> <span class="s1">'https://api.switch-bot.com/v1.1/devices'</span>
</span><span id="line-18"><span class="c1"># Declare empty header dictionary</span>
</span><span id="line-19"><span class="n">apiHeader</span> <span class="o">=</span> <span class="p">{}</span>
</span><span id="line-20"><span class="c1"># open token</span>
</span><span id="line-21"><span class="n">token</span> <span class="o">=</span> <span class="s1">'84df5ca672695c6f7549769dece8861f26c3dc316e207db940137241fecdf8851d7520486cdbc53080e8c1ce7a41eafd'</span> <span class="c1"># copy and paste from the SwitchBot app V6.14 or later</span>
</span><span id="line-22"><span class="c1"># secret key</span>
</span><span id="line-23"><span class="n">secret</span> <span class="o">=</span> <span class="s1">'609f728a30cc777d698f9e43f1501b9f'</span> <span class="c1"># copy and paste from the SwitchBot app V6.14 or later</span>
</span><span id="line-24"><span class="n">nonce</span> <span class="o">=</span> <span class="n">uuid</span><span class="o">.</span><span class="n">uuid4</span><span class="p">()</span>
</span><span id="line-25"><span class="n">t</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="nb">round</span><span class="p">(</span><span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span> <span class="o">*</span> <span class="mi">1000</span><span class="p">))</span>
</span><span id="line-26"><span class="n">string_to_sign</span> <span class="o">=</span> <span class="s1">'</span><span class="si">{}{}{}</span><span class="s1">'</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">token</span><span class="p">,</span> <span class="n">t</span><span class="p">,</span> <span class="n">nonce</span><span class="p">)</span>
</span><span id="line-27">
</span><span id="line-28"><span class="n">string_to_sign</span> <span class="o">=</span> <span class="nb">bytes</span><span class="p">(</span><span class="n">string_to_sign</span><span class="p">,</span> <span class="s1">'utf-8'</span><span class="p">)</span>
</span><span id="line-29"><span class="n">secret</span> <span class="o">=</span> <span class="nb">bytes</span><span class="p">(</span><span class="n">secret</span><span class="p">,</span> <span class="s1">'utf-8'</span><span class="p">)</span>
</span><span id="line-30">
</span><span id="line-31"><span class="n">sign</span> <span class="o">=</span> <span class="n">base64</span><span class="o">.</span><span class="n">b64encode</span><span class="p">(</span><span class="n">hmac</span><span class="o">.</span><span class="n">new</span><span class="p">(</span><span class="n">secret</span><span class="p">,</span> <span class="n">msg</span><span class="o">=</span><span class="n">string_to_sign</span><span class="p">,</span> <span class="n">digestmod</span><span class="o">=</span><span class="n">hashlib</span><span class="o">.</span><span class="n">sha256</span><span class="p">)</span><span class="o">.</span><span class="n">digest</span><span class="p">())</span>
</span><span id="line-32"><span class="nb">print</span> <span class="p">(</span><span class="s1">'Authorization: </span><span class="si">{}</span><span class="s1">'</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">token</span><span class="p">))</span>
</span><span id="line-33"><span class="nb">print</span> <span class="p">(</span><span class="s1">'t: </span><span class="si">{}</span><span class="s1">'</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">t</span><span class="p">))</span>
</span><span id="line-34"><span class="nb">print</span> <span class="p">(</span><span class="s1">'sign: </span><span class="si">{}</span><span class="s1">'</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="nb">str</span><span class="p">(</span><span class="n">sign</span><span class="p">,</span> <span class="s1">'utf-8'</span><span class="p">)))</span>
</span><span id="line-35"><span class="nb">print</span> <span class="p">(</span><span class="s1">'nonce: </span><span class="si">{}</span><span class="s1">'</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">nonce</span><span class="p">))</span>
</span><span id="line-36">
</span><span id="line-37"><span class="c1">#Build api header JSON</span>
</span><span id="line-38"><span class="n">apiHeader</span><span class="p">[</span><span class="s1">'Authorization'</span><span class="p">]</span><span class="o">=</span><span class="n">token</span>
</span><span id="line-39"><span class="n">apiHeader</span><span class="p">[</span><span class="s1">'Content-Type'</span><span class="p">]</span><span class="o">=</span><span class="s1">'application/json'</span>
</span><span id="line-40"><span class="n">apiHeader</span><span class="p">[</span><span class="s1">'charset'</span><span class="p">]</span><span class="o">=</span><span class="s1">'utf8'</span>
</span><span id="line-41"><span class="n">apiHeader</span><span class="p">[</span><span class="s1">'t'</span><span class="p">]</span><span class="o">=</span><span class="nb">str</span><span class="p">(</span><span class="n">t</span><span class="p">)</span>
</span><span id="line-42"><span class="n">apiHeader</span><span class="p">[</span><span class="s1">'sign'</span><span class="p">]</span><span class="o">=</span><span class="nb">str</span><span class="p">(</span><span class="n">sign</span><span class="p">,</span> <span class="s1">'utf-8'</span><span class="p">)</span>
</span><span id="line-43"><span class="n">apiHeader</span><span class="p">[</span><span class="s1">'nonce'</span><span class="p">]</span><span class="o">=</span><span class="nb">str</span><span class="p">(</span><span class="n">nonce</span><span class="p">)</span>
</span><span id="line-44">
</span><span id="line-45"><span class="k">def</span> <span class="nf">lock_device</span><span class="p">():</span>
</span><span id="line-46">    <span class="n">url</span> <span class="o">=</span> <span class="sa">f</span><span class="s1">'</span><span class="si">{</span><span class="n">BASE_URL</span><span class="si">}</span><span class="s1">/</span><span class="si">{</span><span class="n">DEVICE_ID</span><span class="si">}</span><span class="s1">/commands'</span>
</span><span id="line-47">    <span class="n">payload</span> <span class="o">=</span> <span class="p">{</span>
</span><span id="line-48">        <span class="s1">'command'</span><span class="p">:</span> <span class="s1">'lock'</span><span class="p">,</span>
</span><span id="line-49">        <span class="s1">'parameter'</span><span class="p">:</span> <span class="s1">'default'</span><span class="p">,</span>
</span><span id="line-50">        <span class="s1">'commandType'</span><span class="p">:</span> <span class="s1">'command'</span>
</span><span id="line-51">    <span class="p">}</span>
</span><span id="line-52">    <span class="n">response</span> <span class="o">=</span> <span class="n">requests</span><span class="o">.</span><span class="n">post</span><span class="p">(</span><span class="n">url</span><span class="p">,</span> <span class="n">headers</span><span class="o">=</span><span class="n">apiHeader</span><span class="p">,</span> <span class="n">json</span><span class="o">=</span><span class="n">payload</span><span class="p">)</span>
</span><span id="line-53">    <span class="k">return</span> <span class="n">response</span><span class="o">.</span><span class="n">json</span><span class="p">()</span>
</span><span id="line-54">
</span><span id="line-55"><span class="k">def</span> <span class="nf">unlock_device</span><span class="p">():</span>
</span><span id="line-56">    <span class="n">url</span> <span class="o">=</span> <span class="sa">f</span><span class="s1">'</span><span class="si">{</span><span class="n">BASE_URL</span><span class="si">}</span><span class="s1">/</span><span class="si">{</span><span class="n">DEVICE_ID</span><span class="si">}</span><span class="s1">/commands'</span>
</span><span id="line-57">    <span class="n">payload</span> <span class="o">=</span> <span class="p">{</span>
</span><span id="line-58">        <span class="s1">'command'</span><span class="p">:</span> <span class="s1">'unlock'</span><span class="p">,</span>
</span><span id="line-59">        <span class="s1">'parameter'</span><span class="p">:</span> <span class="s1">'default'</span><span class="p">,</span>
</span><span id="line-60">        <span class="s1">'commandType'</span><span class="p">:</span> <span class="s1">'command'</span>
</span><span id="line-61">    <span class="p">}</span>
</span><span id="line-62">    <span class="n">response</span> <span class="o">=</span> <span class="n">requests</span><span class="o">.</span><span class="n">post</span><span class="p">(</span><span class="n">url</span><span class="p">,</span> <span class="n">headers</span><span class="o">=</span><span class="n">apiHeader</span><span class="p">,</span> <span class="n">json</span><span class="o">=</span><span class="n">payload</span><span class="p">)</span>
</span><span id="line-63">    <span class="k">return</span> <span class="n">response</span><span class="o">.</span><span class="n">json</span><span class="p">()</span>
</span><span id="line-64">
</span><span id="line-65"><span class="k">def</span> <span class="nf">list_devices</span><span class="p">():</span>
</span><span id="line-66">    <span class="n">response</span> <span class="o">=</span> <span class="n">requests</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="n">BASE_URL</span><span class="p">,</span> <span class="n">headers</span><span class="o">=</span><span class="n">apiHeader</span><span class="p">)</span>
</span><span id="line-67">    <span class="k">return</span> <span class="n">response</span><span class="o">.</span><span class="n">json</span><span class="p">()</span>
</span><span id="line-68"> 
</span><span id="line-69"><span class="n">Board</span><span class="p">(</span><span class="s2">"UNIHIKER"</span><span class="p">)</span><span class="o">.</span><span class="n">begin</span><span class="p">()</span>  <span class="c1"># Initialize and select the board type, if not specified, it will be automatically recognized</span>
</span><span id="line-70"> 
</span><span id="line-71"><span class="n">img_src</span> <span class="o">=</span> <span class="s1">'/root/image/project14'</span>  <span class="c1"># Define the save path (Specify to a fixed location in Mind+)</span>
</span><span id="line-72"> 
</span><span id="line-73"><span class="n">cap</span> <span class="o">=</span> <span class="n">cv2</span><span class="o">.</span><span class="n">VideoCapture</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>  <span class="c1"># Open the camera with index 0 and initialize</span>
</span><span id="line-74"><span class="n">cap</span><span class="o">.</span><span class="n">set</span><span class="p">(</span><span class="n">cv2</span><span class="o">.</span><span class="n">CAP_PROP_BUFFERSIZE</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>  <span class="c1"># Set the buffer to 1 frame to reduce latency</span>
</span><span id="line-75"><span class="n">cv2</span><span class="o">.</span><span class="n">namedWindow</span><span class="p">(</span><span class="s1">'frame'</span><span class="p">,</span> <span class="n">cv2</span><span class="o">.</span><span class="n">WND_PROP_FULLSCREEN</span><span class="p">)</span>  <span class="c1"># Create a window with the name 'frame', and set its property to fullscreen</span>
</span><span id="line-76"><span class="n">cv2</span><span class="o">.</span><span class="n">setWindowProperty</span><span class="p">(</span><span class="s1">'frame'</span><span class="p">,</span> <span class="n">cv2</span><span class="o">.</span><span class="n">WND_PROP_FULLSCREEN</span><span class="p">,</span> <span class="n">cv2</span><span class="o">.</span><span class="n">WINDOW_FULLSCREEN</span><span class="p">)</span>  <span class="c1"># Set the 'frame' window to fullscreen</span>
</span><span id="line-77"><span class="n">font</span> <span class="o">=</span> <span class="n">cv2</span><span class="o">.</span><span class="n">FONT_HERSHEY_SIMPLEX</span>  <span class="c1"># Set the font type to normal-sized sans-serif</span>
</span><span id="line-78"> 
</span><span id="line-79"><span class="sd">'''Initialize the face detector and recognizer, and use the previously trained .yml file to recognize faces'''</span>
</span><span id="line-80"><span class="n">detector</span> <span class="o">=</span> <span class="n">cv2</span><span class="o">.</span><span class="n">CascadeClassifier</span><span class="p">(</span><span class="n">cv2</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">haarcascades</span> <span class="o">+</span> <span class="s1">'haarcascade_frontalface_default.xml'</span><span class="p">)</span>  <span class="c1"># Load the face detection classifier</span>
</span><span id="line-81"><span class="n">recognizer</span> <span class="o">=</span> <span class="n">cv2</span><span class="o">.</span><span class="n">face</span><span class="o">.</span><span class="n">LBPHFaceRecognizer_create</span><span class="p">()</span>  <span class="c1"># Create an instance of the LBPH recognizer model</span>
</span><span id="line-82"><span class="n">recognizer</span><span class="o">.</span><span class="n">read</span><span class="p">(</span><span class="n">img_src</span> <span class="o">+</span> <span class="s1">'/model.yml'</span><span class="p">)</span>  <span class="c1"># Read the trained face model from the specified path</span>
</span><span id="line-83"> 
</span><span id="line-84"><span class="n">count</span> <span class="o">=</span> <span class="mi">0</span>  <span class="c1"># Define a count flag</span>
</span><span id="line-85"> 
</span><span id="line-86"><span class="k">while</span> <span class="kc">True</span><span class="p">:</span>
</span><span id="line-87">    <span class="n">ret</span><span class="p">,</span> <span class="n">img</span> <span class="o">=</span> <span class="n">cap</span><span class="o">.</span><span class="n">read</span><span class="p">()</span>  <span class="c1"># Read the image frame by frame</span>
</span><span id="line-88">    <span class="c1"># img = cv2.flip(img, 1)  # Mirror the image (horizontally flip the img image)</span>
</span><span id="line-89">    <span class="k">if</span> <span class="n">ret</span><span class="p">:</span>  <span class="c1"># If an image is read successfully</span>
</span><span id="line-90">        <span class="n">h</span><span class="p">,</span> <span class="n">w</span><span class="p">,</span> <span class="n">c</span> <span class="o">=</span> <span class="n">img</span><span class="o">.</span><span class="n">shape</span>  <span class="c1"># Record the shape of the image, including height, width, and channels</span>
</span><span id="line-91">        <span class="n">w1</span> <span class="o">=</span> <span class="n">h</span> <span class="o">*</span> <span class="mi">240</span> <span class="o">//</span> <span class="mi">320</span>
</span><span id="line-92">        <span class="n">x1</span> <span class="o">=</span> <span class="p">(</span><span class="n">w</span> <span class="o">-</span> <span class="n">w1</span><span class="p">)</span> <span class="o">//</span> <span class="mi">2</span>
</span><span id="line-93">        <span class="n">img</span> <span class="o">=</span> <span class="n">img</span><span class="p">[:,</span> <span class="n">x1</span><span class="p">:</span><span class="n">x1</span> <span class="o">+</span> <span class="n">w1</span><span class="p">]</span>  <span class="c1"># Crop the image</span>
</span><span id="line-94">        <span class="n">img</span> <span class="o">=</span> <span class="n">cv2</span><span class="o">.</span><span class="n">resize</span><span class="p">(</span><span class="n">img</span><span class="p">,</span> <span class="p">(</span><span class="mi">240</span><span class="p">,</span> <span class="mi">320</span><span class="p">))</span>  <span class="c1"># Resize the image to match the UNIHIKER display</span>
</span><span id="line-95">        <span class="n">gray</span> <span class="o">=</span> <span class="n">cv2</span><span class="o">.</span><span class="n">cvtColor</span><span class="p">(</span><span class="n">img</span><span class="p">,</span> <span class="n">cv2</span><span class="o">.</span><span class="n">COLOR_BGR2GRAY</span><span class="p">)</span>  <span class="c1"># Convert the image to grayscale</span>
</span><span id="line-96">        <span class="n">faces</span> <span class="o">=</span> <span class="n">detector</span><span class="o">.</span><span class="n">detectMultiScale</span><span class="p">(</span><span class="n">gray</span><span class="p">,</span> <span class="mf">1.2</span><span class="p">,</span> <span class="mi">5</span><span class="p">)</span>  <span class="c1"># Detect and obtain face recognition data</span>
</span><span id="line-97">        <span class="k">for</span> <span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">w</span><span class="p">,</span> <span class="n">h</span><span class="p">)</span> <span class="ow">in</span> <span class="n">faces</span><span class="p">:</span>
</span><span id="line-98">            <span class="n">cv2</span><span class="o">.</span><span class="n">rectangle</span><span class="p">(</span><span class="n">img</span><span class="p">,</span> <span class="p">(</span><span class="n">x</span> <span class="o">-</span> <span class="mi">50</span><span class="p">,</span> <span class="n">y</span> <span class="o">-</span> <span class="mi">50</span><span class="p">),</span> <span class="p">(</span><span class="n">x</span> <span class="o">+</span> <span class="n">w</span> <span class="o">+</span> <span class="mi">50</span><span class="p">,</span> <span class="n">y</span> <span class="o">+</span> <span class="n">h</span> <span class="o">+</span> <span class="mi">50</span><span class="p">),</span> <span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">255</span><span class="p">,</span> <span class="mi">0</span><span class="p">),</span> <span class="mi">2</span><span class="p">)</span>  <span class="c1"># Draw a rectangular box around the face</span>
</span><span id="line-99">            <span class="n">img_id</span><span class="p">,</span> <span class="n">confidence</span> <span class="o">=</span> <span class="n">recognizer</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">gray</span><span class="p">[</span><span class="n">y</span><span class="p">:</span><span class="n">y</span> <span class="o">+</span> <span class="n">h</span><span class="p">,</span> <span class="n">x</span><span class="p">:</span><span class="n">x</span> <span class="o">+</span> <span class="n">w</span><span class="p">])</span>  <span class="c1"># Predict on the grayscale image within the specified rectangular region (used for face presentation)</span>
</span><span id="line-100">            <span class="k">if</span> <span class="n">confidence</span> <span class="o">&lt;</span> <span class="mi">90</span><span class="p">:</span>  <span class="c1"># If confidence &lt; 80, it means a trained face is detected</span>
</span><span id="line-101">                <span class="k">if</span> <span class="n">img_id</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
</span><span id="line-102">                    <span class="n">img_id</span> <span class="o">=</span> <span class="s2">"Ralph"</span>
</span><span id="line-103">                <span class="n">cv2</span><span class="o">.</span><span class="n">putText</span><span class="p">(</span><span class="n">img</span><span class="p">,</span> <span class="s2">"Welcome Home"</span><span class="p">,</span> <span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">),</span> <span class="n">font</span><span class="p">,</span> <span class="mf">0.6</span><span class="p">,</span> <span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">255</span><span class="p">,</span> <span class="mi">0</span><span class="p">),</span> <span class="mi">2</span><span class="p">)</span>  <span class="c1"># Add the text "Welcome Home" to the specified position on the image</span>
</span><span id="line-104">                <span class="n">cv2</span><span class="o">.</span><span class="n">putText</span><span class="p">(</span><span class="n">img</span><span class="p">,</span> <span class="nb">str</span><span class="p">(</span><span class="n">img_id</span><span class="p">),</span> <span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span> <span class="o">+</span> <span class="n">h</span><span class="p">),</span> <span class="n">font</span><span class="p">,</span> <span class="mf">0.6</span><span class="p">,</span> <span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">255</span><span class="p">,</span> <span class="mi">0</span><span class="p">),</span> <span class="mi">2</span><span class="p">)</span>  <span class="c1"># Add the corresponding face ID label to the specified position on the image</span>
</span><span id="line-105">                <span class="k">if</span> <span class="n">count</span> <span class="o">==</span> <span class="mi">5</span><span class="p">:</span>  <span class="c1"># On the third frame</span>
</span><span id="line-106">                    <span class="n">cv2</span><span class="o">.</span><span class="n">imshow</span><span class="p">(</span><span class="s1">'frame'</span><span class="p">,</span> <span class="n">img</span><span class="p">)</span>  <span class="c1"># Display the image</span>
</span><span id="line-107">                    <span class="c1">#time.sleep(5)  # Wait for five seconds</span>
</span><span id="line-108">                    <span class="n">lock_response</span> <span class="o">=</span> <span class="n">unlock_device</span><span class="p">()</span>
</span><span id="line-109">                    <span class="nb">print</span><span class="p">(</span><span class="s1">'Unlock Response:'</span><span class="p">,</span> <span class="n">lock_response</span><span class="p">)</span>
</span><span id="line-110">                    <span class="nb">print</span><span class="p">(</span><span class="s2">"The door is unlocked"</span><span class="p">)</span>
</span><span id="line-111">                    <span class="n">time</span><span class="o">.</span><span class="n">sleep</span><span class="p">(</span><span class="mi">5</span><span class="p">)</span>  <span class="c1"># Wait for five seconds</span>
</span><span id="line-112">                    <span class="n">count</span> <span class="o">=</span> <span class="mi">0</span>  <span class="c1"># Reset the count</span>
</span><span id="line-113">                <span class="k">else</span><span class="p">:</span>
</span><span id="line-114">                    <span class="n">count</span> <span class="o">=</span> <span class="n">count</span> <span class="o">+</span> <span class="mi">1</span>  <span class="c1"># Increment the frame count</span>
</span><span id="line-115">            <span class="k">else</span><span class="p">:</span>  <span class="c1"># If an unknown face is detected</span>
</span><span id="line-116">                <span class="n">img_id</span> <span class="o">=</span> <span class="s2">"unknown"</span>
</span><span id="line-117">                <span class="n">cv2</span><span class="o">.</span><span class="n">putText</span><span class="p">(</span><span class="n">img</span><span class="p">,</span> <span class="nb">str</span><span class="p">(</span><span class="n">img_id</span><span class="p">),</span> <span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span> <span class="o">+</span> <span class="n">h</span><span class="p">),</span> <span class="n">font</span><span class="p">,</span> <span class="mf">0.6</span><span class="p">,</span> <span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">255</span><span class="p">,</span> <span class="mi">0</span><span class="p">),</span> <span class="mi">2</span><span class="p">)</span>  <span class="c1"># Add the text "unknown" to the specified position on the image</span>
</span><span id="line-118">                <span class="n">cv2</span><span class="o">.</span><span class="n">imshow</span><span class="p">(</span><span class="s1">'frame'</span><span class="p">,</span> <span class="n">img</span><span class="p">)</span>  <span class="c1"># Display the image</span>
</span><span id="line-119">                <span class="c1">#time.sleep(5)  # Wait for five seconds</span>
</span><span id="line-120">                <span class="n">lock_response</span> <span class="o">=</span> <span class="n">lock_device</span><span class="p">()</span>
</span><span id="line-121">                <span class="nb">print</span><span class="p">(</span><span class="s1">'Unlock Response:'</span><span class="p">,</span> <span class="n">lock_response</span><span class="p">)</span>
</span><span id="line-122">                <span class="nb">print</span><span class="p">(</span><span class="s2">"The door is locked"</span><span class="p">)</span>
</span><span id="line-123">                <span class="n">time</span><span class="o">.</span><span class="n">sleep</span><span class="p">(</span><span class="mi">5</span><span class="p">)</span>  <span class="c1"># Wait for five seconds</span>
</span><span id="line-124">                <span class="c1">#cv2.putText(img, str(img_id), (x, y + h), font, 0.6, (0, 255, 0), 2)  # Add the text "unknown" to the specified position on the image</span>
</span><span id="line-125">        <span class="n">cv2</span><span class="o">.</span><span class="n">imshow</span><span class="p">(</span><span class="s1">'frame'</span><span class="p">,</span> <span class="n">img</span><span class="p">)</span>  <span class="c1"># Display the image</span>
</span><span id="line-126">        <span class="n">key</span> <span class="o">=</span> <span class="n">cv2</span><span class="o">.</span><span class="n">waitKey</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span> <span class="o">&amp;</span> <span class="mh">0xFF</span>  <span class="c1"># Delay each frame by 1ms, delay cannot be 0, otherwise the result will be a static frame</span>
</span><span id="line-127">        <span class="k">if</span> <span class="n">key</span> <span class="o">==</span> <span class="nb">ord</span><span class="p">(</span><span class="s1">'q'</span><span class="p">):</span>  <span class="c1"># Press 'b' to exit</span>
</span><span id="line-128">            <span class="k">break</span>
</span><span id="line-129">        <span class="c1">#time.sleep(5)  # Wait for five seconds</span>
</span><span id="line-130"> 
</span><span id="line-131"><span class="n">cap</span><span class="o">.</span><span class="n">release</span><span class="p">()</span>  <span class="c1"># Release the camera</span>
</span><span id="line-132"><span class="n">cv2</span><span class="o">.</span><span class="n">destroyAllWindows</span><span class="p">()</span>  <span class="c1"># Close all windows</span>
</span></pre>
       </div>
      </div>
     </div>
     <div class="preview-pane" id="code-widget-656921">
      <div class="header">
       <div class="text">
        <div class="title">
         <h3 class="hckui__typography__h3">
          Xiao_ESP32S3_NotecardInterrupt.ino
         </h3>
         <span class="hckui__typography__bodyS hckui__typography__pebble">
          C/C++
         </span>
        </div>
        <div class="comment">
         <div class="hckui__typography__bodyS hckui__typography__pebble">
          Adds and syncs note to Notecard when interrupt is received from Unihiker
         </div>
        </div>
       </div>
      </div>
      <div class="preview-body pygments-syntax all">
       <div class="highlight">
        <pre><span></span><span id="line-1"><span class="c1">// Copyright 2022 Blues Inc.  All rights reserved.</span>
</span><span id="line-2"><span class="c1">//</span>
</span><span id="line-3"><span class="c1">// Use of this source code is governed by licenses granted by the</span>
</span><span id="line-4"><span class="c1">// copyright holder including that found in the LICENSE file.</span>
</span><span id="line-5"><span class="c1">//</span>
</span><span id="line-6"><span class="c1">// This example does the same function as the "basic" example, but demonstrates</span>
</span><span id="line-7"><span class="c1">// how easy it is to use the Notecard libraries to construct JSON commands and</span>
</span><span id="line-8"><span class="c1">// also to extract responses.</span>
</span><span id="line-9"><span class="c1">//</span>
</span><span id="line-10"><span class="c1">// Using the Notecard library, you can also easily set up your Arduino</span>
</span><span id="line-11"><span class="c1">// environment to "watch" JSON request and response traffic going to/from the</span>
</span><span id="line-12"><span class="c1">// Notecard on your Arduino debug port.</span>
</span><span id="line-13"><span class="c1">//</span>
</span><span id="line-14"><span class="c1">// Note that by using the Notecard library, it is also quite easy to connect the</span>
</span><span id="line-15"><span class="c1">// Notecard to a Microcontroller's I2C ports (SDA and SCL) rather than using</span>
</span><span id="line-16"><span class="c1">// Serial, in case there is no unused serial port available to use for the</span>
</span><span id="line-17"><span class="c1">// Notecard.</span>
</span><span id="line-18">
</span><span id="line-19"><span class="c1">// Include the Arduino library for the Notecard</span>
</span><span id="line-20"><span class="cp">#include</span><span class="w"> </span><span class="cpf">&lt;Notecard.h&gt;</span><span class="cp"></span>
</span><span id="line-21"><span class="k">const</span><span class="w"> </span><span class="kt">int</span><span class="w"> </span><span class="n">interruptPin</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">D0</span><span class="p">;</span><span class="w">  </span><span class="c1">// GPIO pin for the interrupt</span>
</span><span id="line-22"><span class="k">volatile</span><span class="w"> </span><span class="kt">bool</span><span class="w"> </span><span class="n">interruptFlag</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nb">false</span><span class="p">;</span><span class="w">  </span><span class="c1">// Flag to indicate the interrupt</span>
</span><span id="line-23">
</span><span id="line-24"><span class="c1">// If the Notecard is connected to a serial port, define it here.  For example,</span>
</span><span id="line-25"><span class="c1">// if you are using the Adafruit Feather NRF52840 Express, the RX/TX pins (and</span>
</span><span id="line-26"><span class="c1">// thus the Notecard) are on Serial1. However, if you are using an M5Stack Basic</span>
</span><span id="line-27"><span class="c1">// Core IoT Development Kit, you would connect the R2 pin to the Notecard's TX</span>
</span><span id="line-28"><span class="c1">// pin, and the M5Stack's T2 pin to the Notecard's RX pin, and then would use</span>
</span><span id="line-29"><span class="c1">// Serial2.</span>
</span><span id="line-30"><span class="c1">//</span>
</span><span id="line-31"><span class="c1">// Also, you may define a debug output port where you can watch transaction as</span>
</span><span id="line-32"><span class="c1">// they are sent to and from the Notecard.  When using the Arduino IDE this is</span>
</span><span id="line-33"><span class="c1">// typically "Serial", but you can use any available port.</span>
</span><span id="line-34"><span class="c1">//</span>
</span><span id="line-35"><span class="c1">// Note that both of these definitions are optional; just prefix either line</span>
</span><span id="line-36"><span class="c1">// with `//` to remove it.</span>
</span><span id="line-37"><span class="c1">//</span>
</span><span id="line-38"><span class="c1">// - Remove `txRxPinsSerial` if you wired your Notecard using I2C SDA/SCL pins,</span>
</span><span id="line-39"><span class="c1">//   instead of serial RX/TX.</span>
</span><span id="line-40"><span class="c1">// - Remove `usbSerial` if you don't want the Notecard library to output debug</span>
</span><span id="line-41"><span class="c1">//   information.</span>
</span><span id="line-42">
</span><span id="line-43"><span class="c1">// #define txRxPinsSerial Serial1</span>
</span><span id="line-44"><span class="cp">#define usbSerial Serial</span>
</span><span id="line-45">
</span><span id="line-46"><span class="c1">// This is the unique Product Identifier for your device.  This Product ID tells</span>
</span><span id="line-47"><span class="c1">// the Notecard what type of device has embedded the Notecard, and by extension</span>
</span><span id="line-48"><span class="c1">// which vendor or customer is in charge of "managing" it.  In order to set this</span>
</span><span id="line-49"><span class="c1">// value, you must first register with notehub.io and "claim" a unique product</span>
</span><span id="line-50"><span class="c1">// ID for your device.  It could be something as simple as as your email address</span>
</span><span id="line-51"><span class="c1">// in reverse, such as "com.gmail.smith.lisa:test-device" or</span>
</span><span id="line-52"><span class="c1">// "com.outlook.gates.bill.demo"</span>
</span><span id="line-53">
</span><span id="line-54"><span class="c1">// This is the unique Product Identifier for your device</span>
</span><span id="line-55"><span class="cp">#ifndef PRODUCT_UID</span>
</span><span id="line-56"><span class="cp">#define PRODUCT_UID "com.hotmail.ralphjy:build2gether_2.0" </span><span class="c1">// "com.my-company.my-name:my-project"</span>
</span><span id="line-57"><span class="cp">#pragma message "PRODUCT_UID is not defined in this example. Please ensure your Notecard has a product identifier set before running this example or define it in code here. More details at https:</span><span class="c1">//dev.blues.io/tools-and-sdks/samples/product-uid"</span>
</span><span id="line-58"><span class="cp">#endif</span>
</span><span id="line-59">
</span><span id="line-60"><span class="cp">#define myProductID PRODUCT_UID</span>
</span><span id="line-61"><span class="n">Notecard</span><span class="w"> </span><span class="n">notecard</span><span class="p">;</span><span class="w"></span>
</span><span id="line-62">
</span><span id="line-63"><span class="kt">void</span><span class="w"> </span><span class="n">IRAM_ATTR</span><span class="w"> </span><span class="n">handleInterrupt</span><span class="p">()</span><span class="w"> </span><span class="p">{</span><span class="w"></span>
</span><span id="line-64"><span class="w">  </span><span class="c1">// Enqueue the measurement to the Notecard for transmission to the Notehub,</span>
</span><span id="line-65"><span class="w">  </span><span class="c1">// adding the "sync" flag for demonstration purposes to upload the data</span>
</span><span id="line-66"><span class="w">  </span><span class="c1">// instantaneously. If you are looking at this on notehub.io you will see</span>
</span><span id="line-67"><span class="w">  </span><span class="c1">// the data appearing 'live'.</span>
</span><span id="line-68"><span class="w">  </span><span class="n">J</span><span class="w"> </span><span class="o">*</span><span class="n">req</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">notecard</span><span class="p">.</span><span class="n">newRequest</span><span class="p">(</span><span class="s">"note.add"</span><span class="p">);</span><span class="w"></span>
</span><span id="line-69"><span class="w">  </span><span class="k">if</span><span class="w"> </span><span class="p">(</span><span class="n">req</span><span class="w"> </span><span class="o">!=</span><span class="w"> </span><span class="nb">NULL</span><span class="p">)</span><span class="w"></span>
</span><span id="line-70"><span class="w">  </span><span class="p">{</span><span class="w"></span>
</span><span id="line-71"><span class="w">      </span><span class="n">JAddBoolToObject</span><span class="p">(</span><span class="n">req</span><span class="p">,</span><span class="w"> </span><span class="s">"sync"</span><span class="p">,</span><span class="w"> </span><span class="nb">true</span><span class="p">);</span><span class="w"></span>
</span><span id="line-72"><span class="w">      </span><span class="n">J</span><span class="w"> </span><span class="o">*</span><span class="n">body</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">JAddObjectToObject</span><span class="p">(</span><span class="n">req</span><span class="p">,</span><span class="w"> </span><span class="s">"body"</span><span class="p">);</span><span class="w"></span>
</span><span id="line-73"><span class="w">      </span><span class="k">if</span><span class="w"> </span><span class="p">(</span><span class="n">body</span><span class="w"> </span><span class="o">!=</span><span class="w"> </span><span class="nb">NULL</span><span class="p">)</span><span class="w"></span>
</span><span id="line-74"><span class="w">      </span><span class="p">{</span><span class="w"></span>
</span><span id="line-75"><span class="w">          </span><span class="n">JAddNumberToObject</span><span class="p">(</span><span class="n">body</span><span class="p">,</span><span class="w"> </span><span class="s">"lockStatus"</span><span class="p">,</span><span class="w"> </span><span class="s">"Unlocked"</span><span class="p">);</span><span class="w"></span>
</span><span id="line-76"><span class="w">          </span><span class="n">JAddNumberToObject</span><span class="p">(</span><span class="n">body</span><span class="p">,</span><span class="w"> </span><span class="s">"faceID"</span><span class="p">,</span><span class="w"> </span><span class="s">"Ralph"</span><span class="p">);</span><span class="w"></span>
</span><span id="line-77"><span class="w">      </span><span class="p">}</span><span class="w"></span>
</span><span id="line-78"><span class="w">      </span><span class="n">notecard</span><span class="p">.</span><span class="n">sendRequest</span><span class="p">(</span><span class="n">req</span><span class="p">);</span><span class="w"></span>
</span><span id="line-79"><span class="w">  </span><span class="p">}</span><span class="w"></span>
</span><span id="line-80"><span class="w">  </span><span class="n">Serial</span><span class="p">.</span><span class="n">println</span><span class="p">(</span><span class="s">"Interrupt detected!"</span><span class="p">);</span><span class="w"></span>
</span><span id="line-81"><span class="p">}</span><span class="w"></span>
</span><span id="line-82">
</span><span id="line-83"><span class="c1">// One-time Arduino initialization</span>
</span><span id="line-84"><span class="kt">void</span><span class="w"> </span><span class="n">setup</span><span class="p">()</span><span class="w"></span>
</span><span id="line-85"><span class="p">{</span><span class="w"></span>
</span><span id="line-86"><span class="w">  </span><span class="n">pinMode</span><span class="p">(</span><span class="n">interruptPin</span><span class="p">,</span><span class="w"> </span><span class="n">INPUT</span><span class="p">);</span><span class="w">  </span><span class="c1">// Set the pin as input with internal pull-up</span>
</span><span id="line-87"><span class="w">  </span><span class="n">attachInterrupt</span><span class="p">(</span><span class="n">digitalPinToInterrupt</span><span class="p">(</span><span class="n">interruptPin</span><span class="p">),</span><span class="w"> </span><span class="n">handleInterrupt</span><span class="p">,</span><span class="w"> </span><span class="n">RISING</span><span class="p">);</span><span class="w">  </span><span class="c1">// Attach interrupt on rising edge</span>
</span><span id="line-88">
</span><span id="line-89"><span class="w">    </span><span class="c1">// Set up for debug output (if available).</span>
</span><span id="line-90"><span class="cp">#ifdef usbSerial</span>
</span><span id="line-91"><span class="w">    </span><span class="c1">// If you open Arduino's serial terminal window, you'll be able to watch</span>
</span><span id="line-92"><span class="w">    </span><span class="c1">// JSON objects being transferred to and from the Notecard for each request.</span>
</span><span id="line-93"><span class="w">    </span><span class="n">usbSerial</span><span class="p">.</span><span class="n">begin</span><span class="p">(</span><span class="mi">115200</span><span class="p">);</span><span class="w"></span>
</span><span id="line-94"><span class="w">    </span><span class="k">const</span><span class="w"> </span><span class="kt">size_t</span><span class="w"> </span><span class="n">usb_timeout_ms</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">3000</span><span class="p">;</span><span class="w"></span>
</span><span id="line-95"><span class="w">    </span><span class="k">for</span><span class="w"> </span><span class="p">(</span><span class="k">const</span><span class="w"> </span><span class="kt">size_t</span><span class="w"> </span><span class="n">start_ms</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">millis</span><span class="p">();</span><span class="w"> </span><span class="o">!</span><span class="n">usbSerial</span><span class="w"> </span><span class="o">&amp;&amp;</span><span class="w"> </span><span class="p">(</span><span class="n">millis</span><span class="p">()</span><span class="w"> </span><span class="o">-</span><span class="w"> </span><span class="n">start_ms</span><span class="p">)</span><span class="w"> </span><span class="o">&lt;</span><span class="w"> </span><span class="n">usb_timeout_ms</span><span class="p">;)</span><span class="w"></span>
</span><span id="line-96"><span class="w">        </span><span class="p">;</span><span class="w"></span>
</span><span id="line-97">
</span><span id="line-98"><span class="w">    </span><span class="c1">// For low-memory platforms, don't turn on internal Notecard logs.</span>
</span><span id="line-99"><span class="cp">#ifndef NOTE_C_LOW_MEM</span>
</span><span id="line-100"><span class="w">    </span><span class="n">notecard</span><span class="p">.</span><span class="n">setDebugOutputStream</span><span class="p">(</span><span class="n">usbSerial</span><span class="p">);</span><span class="w"></span>
</span><span id="line-101"><span class="cp">#else</span>
</span><span id="line-102"><span class="cp">#pragma message("INFO: Notecard debug logs disabled. (non-fatal)")</span>
</span><span id="line-103"><span class="cp">#endif </span><span class="c1">// !NOTE_C_LOW_MEM</span>
</span><span id="line-104"><span class="cp">#endif </span><span class="c1">// usbSerial</span>
</span><span id="line-105">
</span><span id="line-106"><span class="w">    </span><span class="c1">// Initialize the physical I/O channel to the Notecard</span>
</span><span id="line-107"><span class="cp">#ifdef txRxPinsSerial</span>
</span><span id="line-108"><span class="w">    </span><span class="n">notecard</span><span class="p">.</span><span class="n">begin</span><span class="p">(</span><span class="n">txRxPinsSerial</span><span class="p">,</span><span class="w"> </span><span class="mi">9600</span><span class="p">);</span><span class="w"></span>
</span><span id="line-109"><span class="cp">#else</span>
</span><span id="line-110"><span class="w">    </span><span class="n">notecard</span><span class="p">.</span><span class="n">begin</span><span class="p">();</span><span class="w"></span>
</span><span id="line-111"><span class="cp">#endif</span>
</span><span id="line-112">
</span><span id="line-113"><span class="w">    </span><span class="c1">// "newRequest()" uses the bundled "J" json package to allocate a "req",</span>
</span><span id="line-114"><span class="w">    </span><span class="c1">// which is a JSON object for the request to which we will then add Request</span>
</span><span id="line-115"><span class="w">    </span><span class="c1">// arguments.  The function allocates a "req" request structure using</span>
</span><span id="line-116"><span class="w">    </span><span class="c1">// malloc() and initializes its "req" field with the type of request.</span>
</span><span id="line-117"><span class="w">    </span><span class="n">J</span><span class="w"> </span><span class="o">*</span><span class="n">req</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">notecard</span><span class="p">.</span><span class="n">newRequest</span><span class="p">(</span><span class="s">"hub.set"</span><span class="p">);</span><span class="w"></span>
</span><span id="line-118">
</span><span id="line-119"><span class="w">    </span><span class="c1">// This command (required) causes the data to be delivered to the Project</span>
</span><span id="line-120"><span class="w">    </span><span class="c1">// on notehub.io that has claimed this Product ID (see above).</span>
</span><span id="line-121"><span class="w">    </span><span class="k">if</span><span class="w"> </span><span class="p">(</span><span class="n">myProductID</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span><span class="w"></span>
</span><span id="line-122"><span class="w">    </span><span class="p">{</span><span class="w"></span>
</span><span id="line-123"><span class="w">        </span><span class="n">JAddStringToObject</span><span class="p">(</span><span class="n">req</span><span class="p">,</span><span class="w"> </span><span class="s">"product"</span><span class="p">,</span><span class="w"> </span><span class="n">myProductID</span><span class="p">);</span><span class="w"></span>
</span><span id="line-124"><span class="w">    </span><span class="p">}</span><span class="w"></span>
</span><span id="line-125">
</span><span id="line-126"><span class="w">    </span><span class="c1">// This command determines how often the Notecard connects to the service.</span>
</span><span id="line-127"><span class="w">    </span><span class="c1">// If "continuous", the Notecard immediately establishes a session with the</span>
</span><span id="line-128"><span class="w">    </span><span class="c1">// service at notehub.io, and keeps it active continuously. Due to the power</span>
</span><span id="line-129"><span class="w">    </span><span class="c1">// requirements of a continuous connection, a battery powered device would</span>
</span><span id="line-130"><span class="w">    </span><span class="c1">// instead only sample its sensors occasionally, and would only upload to</span>
</span><span id="line-131"><span class="w">    </span><span class="c1">// the service on a "periodic" basis.</span>
</span><span id="line-132"><span class="w">    </span><span class="n">JAddStringToObject</span><span class="p">(</span><span class="n">req</span><span class="p">,</span><span class="w"> </span><span class="s">"mode"</span><span class="p">,</span><span class="w"> </span><span class="s">"continuous"</span><span class="p">);</span><span class="w"></span>
</span><span id="line-133">
</span><span id="line-134"><span class="w">    </span><span class="c1">// Issue the request, telling the Notecard how and how often to access the</span>
</span><span id="line-135"><span class="w">    </span><span class="c1">// service.</span>
</span><span id="line-136"><span class="w">    </span><span class="c1">// This results in a JSON message to Notecard formatted like:</span>
</span><span id="line-137"><span class="w">    </span><span class="c1">//     {</span>
</span><span id="line-138"><span class="w">    </span><span class="c1">//       "req"     : "service.set",</span>
</span><span id="line-139"><span class="w">    </span><span class="c1">//       "product" : myProductID,</span>
</span><span id="line-140"><span class="w">    </span><span class="c1">//       "mode"    : "continuous"</span>
</span><span id="line-141"><span class="w">    </span><span class="c1">//     }</span>
</span><span id="line-142"><span class="w">    </span><span class="c1">// Note that `notecard.sendRequestWithRetry()` always frees the request data</span>
</span><span id="line-143"><span class="w">    </span><span class="c1">// structure, and it returns "true" if success or "false" if there is any</span>
</span><span id="line-144"><span class="w">    </span><span class="c1">// failure. It is important to use `sendRequestWithRetry()` on the first</span>
</span><span id="line-145"><span class="w">    </span><span class="c1">// message from the MCU to the Notecard, because there will always be a</span>
</span><span id="line-146"><span class="w">    </span><span class="c1">// hardware race condition on cold boot and the Notecard must be ready to</span>
</span><span id="line-147"><span class="w">    </span><span class="c1">// receive and process the message.</span>
</span><span id="line-148"><span class="w">    </span><span class="n">notecard</span><span class="p">.</span><span class="n">sendRequestWithRetry</span><span class="p">(</span><span class="n">req</span><span class="p">,</span><span class="w"> </span><span class="mi">5</span><span class="p">);</span><span class="w"> </span><span class="c1">// 5 seconds</span>
</span><span id="line-149"><span class="p">}</span><span class="w"></span>
</span><span id="line-150">
</span><span id="line-151"><span class="kt">void</span><span class="w"> </span><span class="n">loop</span><span class="p">()</span><span class="w"></span>
</span><span id="line-152"><span class="p">{</span><span class="w"></span>
</span><span id="line-153"><span class="w">    </span><span class="c1">// Delay between loops</span>
</span><span id="line-154"><span class="w">    </span><span class="n">delay</span><span class="p">(</span><span class="mi">15</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="mi">1000</span><span class="p">);</span><span class="w"> </span><span class="c1">// 15 seconds</span>
</span><span id="line-155"><span class="p">}</span><span class="w"></span>
</span></pre>
       </div>
      </div>
     </div>
    </div>
   </div>
  </section>
  <div class="project-section-break">
  </div>
  <div class="project-section-break">
  </div>
 </div>
</div>
