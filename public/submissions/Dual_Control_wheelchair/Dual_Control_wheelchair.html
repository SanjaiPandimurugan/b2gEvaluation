<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/water.css@2/out/water.css"><link rel="stylesheet" href="../custom.css"><div class="middle-column">
 <section id="overview">
  <h1 class="hckui__typography__h1" itemprop="name">
   Dual Control wheelchair
  </h1>
  <p class="hckui__typography__bodyL hckui__layout__marginBottom15" itemprop="description">
   Control your wheelchair with a smile! FaceMesh tech + voice command = effortless mobility. Independence redefined. #assistivetech #innovatio
  </p>
  <div class="hckui__layout__marginTop30">
   <div class="hckui__layout__hiddenMedUp">
   </div>
   <div class="project-cover-image" itemprop="image" itemscope="" itemtype="https://schema.org/ImageObject">
    <meta content="https://hackster.imgix.net/uploads/attachments/1749800/_IasxdB1SVu.blob?auto=compress&amp;w=900&amp;h=675&amp;fit=min&amp;fm=jpg" itemprop="url"/>
    <meta content="900" itemprop="width"/>
    <meta content="675" itemprop="height"/>
    <img alt="Dual Control wheelchair" src="10.jpg"/>
   </div>
  </div>
 </section>
 <div class="project-section-break">
 </div>
 <div id="project_page_simple_ad_portal">
 </div>
 <div id="description" itemprop="articleBody">
  <section id="things">
   <div class="project-section-title">
    <h2 class="hckui__typography__h2 title-with-anchor">
     <span>
      Things used in this project
     </span>
    </h2>
   </div>
   <div class="project-parts">
    <div class="view-expanded" style="display:block">
     <table class="project-parts-table">
      <colgroup>
       <col style="width: 100px; height: 50px;"/>
       <col style="width: auto;"/>
      </colgroup>
      <tbody>
       <tr class="head">
        <td colspan="2">
         <h3 class="hckui__typography__h3">
          Hardware components
         </h3>
        </td>
        <tr>
         <td class="part-img">
          <img alt="UNIHIKER - IoT Python Programming Single Board Computer with Touchscreen" src="11.jpg" srcset="https://hackster.imgix.net/uploads/attachments/1623050/9924dc25f8a8d36cae2ea2becac95b77_Bn8OXLjRQw.png?auto=compress%2Cformat&amp;w=96&amp;h=96&amp;fit=fill&amp;bg=ffffff 2x, https://hackster.imgix.net/uploads/attachments/1623050/9924dc25f8a8d36cae2ea2becac95b77_Bn8OXLjRQw.png?auto=compress%2Cformat&amp;w=48&amp;h=48&amp;fit=fill&amp;bg=ffffff"/>
         </td>
         <td class="hckui__typography__bodyL">
          <a class="hckui__typography__linkBlue" data-ha='{"eventName":"Clicked link","customProps":{"value":"DFRobot UNIHIKER - IoT Python Programming Single Board Computer with Touchscreen","href":"/dfrobot/products/unihiker-iot-python-programming-single-board-computer-with-touchscreen1?ref=project-12248f","type":"part","location":"things"},"clickOpts":{"delayRedirect":true}}' href="https://www.hackster.io/dfrobot/products/unihiker-iot-python-programming-single-board-computer-with-touchscreen1?ref=project-12248f">
           DFRobot UNIHIKER - IoT Python Programming Single Board Computer with Touchscreen
          </a>
         </td>
        </tr>
        <tr>
         <td class="part-img">
          <img alt="Seeed Studio XIAO ESP32S3 Sense" src="12.jpg" srcset="https://hackster.imgix.net/uploads/attachments/1650360/screenshot_2023-11-20_at_17_16_09_QdLoLAbseq.png?auto=compress%2Cformat&amp;w=96&amp;h=96&amp;fit=fill&amp;bg=ffffff 2x, https://hackster.imgix.net/uploads/attachments/1650360/screenshot_2023-11-20_at_17_16_09_QdLoLAbseq.png?auto=compress%2Cformat&amp;w=48&amp;h=48&amp;fit=fill&amp;bg=ffffff"/>
         </td>
         <td class="hckui__typography__bodyL">
          <a class="hckui__typography__linkBlue" data-ha='{"eventName":"Clicked link","customProps":{"value":"Seeed Studio XIAO ESP32S3 Sense","href":"/seeed/products/seeed-studio-xiao-esp32s3-sense?ref=project-12248f","type":"part","location":"things"},"clickOpts":{"delayRedirect":true}}' href="https://www.hackster.io/seeed/products/seeed-studio-xiao-esp32s3-sense?ref=project-12248f">
           Seeed Studio XIAO ESP32S3 Sense
          </a>
         </td>
        </tr>
        <tr>
         <td class="part-img">
          <img alt="Blues Notecarrier A" src="13.jpg" srcset="https://hackster.imgix.net/uploads/attachments/1431807/CARR_AL_2.0_front_1800x1800.jpg?auto=compress%2Cformat&amp;w=96&amp;h=96&amp;fit=fill&amp;bg=ffffff 2x, https://hackster.imgix.net/uploads/attachments/1431807/CARR_AL_2.0_front_1800x1800.jpg?auto=compress%2Cformat&amp;w=48&amp;h=48&amp;fit=fill&amp;bg=ffffff"/>
         </td>
         <td class="hckui__typography__bodyL">
          <a class="hckui__typography__linkBlue" data-ha='{"eventName":"Clicked link","customProps":{"value":"Blues Notecarrier A","href":"/blues-wireless/products/blues-notecarrier-a?ref=project-12248f","type":"part","location":"things"},"clickOpts":{"delayRedirect":true}}' href="https://www.hackster.io/blues-wireless/products/blues-notecarrier-a?ref=project-12248f">
           Blues Notecarrier A
          </a>
         </td>
        </tr>
        <tr>
         <td class="part-img">
          <img alt="Blues Notecard (Cellular)" src="14.jpg" srcset="https://hackster.imgix.net/uploads/attachments/1708752/wbnan-front_tdId2xJ1V4.png?auto=compress%2Cformat&amp;w=96&amp;h=96&amp;fit=fill&amp;bg=ffffff 2x, https://hackster.imgix.net/uploads/attachments/1708752/wbnan-front_tdId2xJ1V4.png?auto=compress%2Cformat&amp;w=48&amp;h=48&amp;fit=fill&amp;bg=ffffff"/>
         </td>
         <td class="hckui__typography__bodyL">
          <a class="hckui__typography__linkBlue" data-ha='{"eventName":"Clicked link","customProps":{"value":"Blues Notecard (Cellular)","href":"/blues-wireless/products/blues-notecard-cellular?ref=project-12248f","type":"part","location":"things"},"clickOpts":{"delayRedirect":true}}' href="https://www.hackster.io/blues-wireless/products/blues-notecard-cellular?ref=project-12248f">
           Blues Notecard (Cellular)
          </a>
         </td>
        </tr>
        <tr>
         <td class="part-img">
          <img alt="ESP32" src="15.jpg" srcset="https://hackster.imgix.net/uploads/attachments/1684399/esp32_pVG2tEKppK.png?auto=compress%2Cformat&amp;w=96&amp;h=96&amp;fit=fill&amp;bg=ffffff 2x, https://hackster.imgix.net/uploads/attachments/1684399/esp32_pVG2tEKppK.png?auto=compress%2Cformat&amp;w=48&amp;h=48&amp;fit=fill&amp;bg=ffffff"/>
         </td>
         <td class="hckui__typography__bodyL">
          <a class="hckui__typography__linkBlue" data-ha='{"eventName":"Clicked link","customProps":{"value":"Espressif ESP32","href":"/Espressif/products/esp32?ref=project-12248f","type":"part","location":"things"},"clickOpts":{"delayRedirect":true}}' href="https://www.hackster.io/Espressif/products/esp32?ref=project-12248f">
           Espressif ESP32
          </a>
         </td>
        </tr>
        <tr>
         <td class="part-img">
          <img alt="Webcam, Logitech® HD Pro" src="16.jpg" srcset="https://hackster.imgix.net/uploads/attachments/841664/5167418.jpg?auto=compress%2Cformat&amp;w=96&amp;h=96&amp;fit=fill&amp;bg=ffffff 2x, https://hackster.imgix.net/uploads/attachments/841664/5167418.jpg?auto=compress%2Cformat&amp;w=48&amp;h=48&amp;fit=fill&amp;bg=ffffff"/>
         </td>
         <td class="hckui__typography__bodyL">
          Webcam, Logitech® HD Pro
         </td>
        </tr>
        <tr>
         <td class="part-img">
         </td>
         <td class="hckui__typography__bodyL">
          hoverboard motor
         </td>
        </tr>
       </tr>
       <tr class="head">
        <td colspan="2">
         <h3 class="hckui__typography__h3">
          Software apps and online services
         </h3>
        </td>
       </tr>
       <tr>
        <td class="part-img">
         <img alt="Arduino IDE" src="17.jpg" srcset="https://hackster.imgix.net/uploads/image/file/144203/IDE_web.jpg?auto=compress%2Cformat&amp;w=96&amp;h=96&amp;fit=fill&amp;bg=ffffff 2x, https://hackster.imgix.net/uploads/image/file/144203/IDE_web.jpg?auto=compress%2Cformat&amp;w=48&amp;h=48&amp;fit=fill&amp;bg=ffffff"/>
        </td>
        <td class="hckui__typography__bodyL">
         <a class="hckui__typography__linkBlue" data-ha='{"eventName":"Clicked link","customProps":{"value":"Arduino IDE","href":"/arduino/products/arduino-ide?ref=project-12248f","type":"part","location":"things"},"clickOpts":{"delayRedirect":true}}' href="https://www.hackster.io/arduino/products/arduino-ide?ref=project-12248f">
          Arduino IDE
         </a>
        </td>
       </tr>
       <tr>
        <td class="part-img">
         <img alt="VS Code" src="18.jpg" srcset="https://hackster.imgix.net/uploads/attachments/673386/512px-visual_studio_code_1_18_icon_svg_k5OBc8o3Yk.png?auto=compress%2Cformat&amp;w=96&amp;h=96&amp;fit=fill&amp;bg=ffffff 2x, https://hackster.imgix.net/uploads/attachments/673386/512px-visual_studio_code_1_18_icon_svg_k5OBc8o3Yk.png?auto=compress%2Cformat&amp;w=48&amp;h=48&amp;fit=fill&amp;bg=ffffff"/>
        </td>
        <td class="hckui__typography__bodyL">
         <a class="hckui__typography__linkBlue" data-ha='{"eventName":"Clicked link","customProps":{"value":"Microsoft VS Code","href":"/microsoft/products/vs-code?ref=project-12248f","type":"part","location":"things"},"clickOpts":{"delayRedirect":true}}' href="https://www.hackster.io/microsoft/products/vs-code?ref=project-12248f">
          Microsoft VS Code
         </a>
        </td>
       </tr>
       <tr>
        <td class="part-img">
        </td>
        <td class="hckui__typography__bodyL">
         mind+
        </td>
       </tr>
       <tr>
        <td class="part-img">
         <img alt="Blues Notehub.io" src="19.jpg" srcset="https://hackster.imgix.net/uploads/attachments/1592772/blues-brandmark-black-large_roS7acnDbx.png?auto=compress%2Cformat&amp;w=96&amp;h=96&amp;fit=fill&amp;bg=ffffff 2x, https://hackster.imgix.net/uploads/attachments/1592772/blues-brandmark-black-large_roS7acnDbx.png?auto=compress%2Cformat&amp;w=48&amp;h=48&amp;fit=fill&amp;bg=ffffff"/>
        </td>
        <td class="hckui__typography__bodyL">
         <a class="hckui__typography__linkBlue" data-ha='{"eventName":"Clicked link","customProps":{"value":"Blues Notehub.io","href":"/blues-wireless/products/blues-notehub-io?ref=project-12248f","type":"part","location":"things"},"clickOpts":{"delayRedirect":true}}' href="https://www.hackster.io/blues-wireless/products/blues-notehub-io?ref=project-12248f">
          Blues Notehub.io
         </a>
        </td>
       </tr>
       <tr>
        <td class="part-img">
         <img alt="OpenCV" src="20.jpg" srcset="https://hackster.imgix.net/uploads/attachments/177955/73318_301258139977848_644841747_n.png?auto=compress%2Cformat&amp;w=96&amp;h=96&amp;fit=fill&amp;bg=ffffff 2x, https://hackster.imgix.net/uploads/attachments/177955/73318_301258139977848_644841747_n.png?auto=compress%2Cformat&amp;w=48&amp;h=48&amp;fit=fill&amp;bg=ffffff"/>
        </td>
        <td class="hckui__typography__bodyL">
         <a class="hckui__typography__linkBlue" data-ha='{"eventName":"Clicked link","customProps":{"value":"OpenCV","href":"/opencv/products/opencv?ref=project-12248f","type":"part","location":"things"},"clickOpts":{"delayRedirect":true}}' href="https://www.hackster.io/opencv/products/opencv?ref=project-12248f">
          OpenCV
         </a>
        </td>
       </tr>
       <tr>
        <td class="part-img">
        </td>
        <td class="hckui__typography__bodyL">
         Mediapipe
        </td>
       </tr>
       <tr>
        <td class="part-img">
         <img alt="Edge Impulse Studio" src="21.jpg" srcset="https://hackster.imgix.net/uploads/attachments/1125747/picture1_aQHULTyVRc.png?auto=compress%2Cformat&amp;w=96&amp;h=96&amp;fit=fill&amp;bg=ffffff 2x, https://hackster.imgix.net/uploads/attachments/1125747/picture1_aQHULTyVRc.png?auto=compress%2Cformat&amp;w=48&amp;h=48&amp;fit=fill&amp;bg=ffffff"/>
        </td>
        <td class="hckui__typography__bodyL">
         <a class="hckui__typography__linkBlue" data-ha='{"eventName":"Clicked link","customProps":{"value":"Edge Impulse Studio","href":"/EdgeImpulse/products/edge-impulse-studio?ref=project-12248f","type":"part","location":"things"},"clickOpts":{"delayRedirect":true}}' href="https://www.hackster.io/EdgeImpulse/products/edge-impulse-studio?ref=project-12248f">
          Edge Impulse Studio
         </a>
        </td>
       </tr>
       <tr>
        <td class="part-img">
         <img alt="MQTT" src="22.jpg" srcset="https://hackster.imgix.net/uploads/attachments/183131/mqtt.png?auto=compress%2Cformat&amp;w=96&amp;h=96&amp;fit=fill&amp;bg=ffffff 2x, https://hackster.imgix.net/uploads/attachments/183131/mqtt.png?auto=compress%2Cformat&amp;w=48&amp;h=48&amp;fit=fill&amp;bg=ffffff"/>
        </td>
        <td class="hckui__typography__bodyL">
         <a class="hckui__typography__linkBlue" data-ha='{"eventName":"Clicked link","customProps":{"value":"MQTT","href":"/mqtt/products/mqtt?ref=project-12248f","type":"part","location":"things"},"clickOpts":{"delayRedirect":true}}' href="https://www.hackster.io/mqtt/products/mqtt?ref=project-12248f">
          MQTT
         </a>
        </td>
       </tr>
       <tr>
        <td class="part-img">
        </td>
        <td class="hckui__typography__bodyL">
         cvzone
        </td>
       </tr>
       <tr>
        <td class="part-img">
        </td>
        <td class="hckui__typography__bodyL">
         speech recognition
        </td>
       </tr>
       <tr class="head">
        <td colspan="2">
         <h3 class="hckui__typography__h3">
          Hand tools and fabrication machines
         </h3>
        </td>
       </tr>
       <tr>
        <td class="part-img">
         <img alt="Soldering iron (generic)" src="23.jpg" srcset="https://hackster.imgix.net/uploads/image/file/79853/09507-01.jpg?auto=compress%2Cformat&amp;w=96&amp;h=96&amp;fit=fill&amp;bg=ffffff 2x, https://hackster.imgix.net/uploads/image/file/79853/09507-01.jpg?auto=compress%2Cformat&amp;w=48&amp;h=48&amp;fit=fill&amp;bg=ffffff"/>
        </td>
        <td class="hckui__typography__bodyL">
         Soldering iron (generic)
        </td>
       </tr>
       <tr>
        <td class="part-img">
         <img alt="Solder Wire, Lead Free" src="24.jpg" srcset="https://hackster.imgix.net/uploads/attachments/842592/4966285.jpg?auto=compress%2Cformat&amp;w=96&amp;h=96&amp;fit=fill&amp;bg=ffffff 2x, https://hackster.imgix.net/uploads/attachments/842592/4966285.jpg?auto=compress%2Cformat&amp;w=48&amp;h=48&amp;fit=fill&amp;bg=ffffff"/>
        </td>
        <td class="hckui__typography__bodyL">
         Solder Wire, Lead Free
        </td>
       </tr>
       <tr>
        <td class="part-img">
         <img alt="Mastech MS8217 Autorange Digital Multimeter" src="25.jpg" srcset="https://hackster.imgix.net/uploads/attachments/223412/Pro_DMM_box_600__26129.1449785766.500.659.png?auto=compress%2Cformat&amp;w=96&amp;h=96&amp;fit=fill&amp;bg=ffffff 2x, https://hackster.imgix.net/uploads/attachments/223412/Pro_DMM_box_600__26129.1449785766.500.659.png?auto=compress%2Cformat&amp;w=48&amp;h=48&amp;fit=fill&amp;bg=ffffff"/>
        </td>
        <td class="hckui__typography__bodyL">
         <a class="hckui__typography__linkBlue" data-ha='{"eventName":"Clicked link","customProps":{"value":"Digilent Mastech MS8217 Autorange Digital Multimeter","href":"/digilent/products/mastech-ms8217-autorange-digital-multimeter?ref=project-12248f","type":"part","location":"things"},"clickOpts":{"delayRedirect":true}}' href="https://www.hackster.io/digilent/products/mastech-ms8217-autorange-digital-multimeter?ref=project-12248f">
          Digilent Mastech MS8217 Autorange Digital Multimeter
         </a>
        </td>
       </tr>
      </tbody>
     </table>
    </div>
   </div>
  </section>
  <div class="project-section-break">
  </div>
  <section id="story">
   <div class="project-section-title">
    <h2 class="hckui__typography__h2 title-with-anchor">
     <span>
      Story
     </span>
    </h2>
   </div>
   <div class="project-story collapsible-section collapsed hljs-active hljs-monokai" itemprop="text">
    <h3 class="hckui__typography__h3 title-with-anchor" id="toc-story-0">
     <p>
      <p class="hckui__typography__bodyL">
      </p>
     </p>
     <span>
      STORY
     </span>
    </h3>
    <h3 class="hckui__typography__h3 title-with-anchor" id="toc-1-introduction-1">
     <p>
      <p class="hckui__typography__bodyL">
      </p>
     </p>
     <span>
      1.Introduction
     </span>
    </h3>
    <p class="hckui__typography__bodyL">
     The primary purpose of this project is to develop an innovative assistive technology solution that enhances the quality of life for individuals with limited mobility. By leveraging facial expression recognition and voice command capabilities, we aim to create a more intuitive and accessible control interface for assistive devices such as wheelchairs and robotic arms.
    </p>
    <p class="hckui__typography__bodyL">
     Our motivation stems from the desire to empower individuals with disabilities by providing them with greater independence and control over their environment. We believe that by combining these advanced technologies, we can create a system that effectively addresses the challenges faced by people with limited mobility and offers a more human-centric approach to assistive technology.Individuals with limited mobility often encounter significant challenges in performing everyday tasks due to physical impairments.Our project addresses these challenges by providing an alternative control method.
    </p>
    <h3 class="hckui__typography__h3 title-with-anchor" id="toc-2-system-overview-2">
     <p>
      <p class="hckui__typography__bodyL">
      </p>
     </p>
     <span>
      2.System Overview
     </span>
    </h3>
    <p class="hckui__typography__bodyL">
     A Unihiker acts as the input for both face recognition and voice control. For face recognition, Face Mesh is used to detect the face and draw landmarks on it. The mouth landmarks are used to determine if the mouth is open or closed. If the mouth is open, commands are sent to the ESP32 Wroom, which controls the motor controller to move or not move. If the head moves left or right, commands are sent to another ESP32 to control the motor.
    </p>
    <p class="hckui__typography__bodyL">
     The system also has a provision for voice commands. This is useful in case the user is wearing a mask, making it difficult for the system to detect the face. The user can say words like "move forward, " "stop, " "left, " or "right" to send commands to the ESP32 Wroom and control the motors.
    </p>
    <p class="hckui__typography__bodyL">
     Additionally, an ESP32 Sense Xiao is used for object detection. This ensures safety by detecting obstacles in front of the system and sending commands to the ESP32 for control.
    </p>
    <p class="hckui__typography__bodyL">
     Finally, Notecarrier and Notecard are added to the system to utilize GPS and track the location of the system for safety purposes.
    </p>
    <h3 class="hckui__typography__h3 title-with-anchor" id="toc-3-facial-expression-recognition-and-voice-commands-3">
     <p>
      <p class="hckui__typography__bodyL">
      </p>
     </p>
     <span>
      3.Facial Expression Recognition and Voice Commands
     </span>
    </h3>
    <p class="hckui__typography__bodyL">
     <span>
      For face recognition and voice control, we are using a
     </span>
     <a class="hckui__typography__linkBlue" data-ha='{"eventName":"Clicked link","customProps":{"value":"UNIHIKER","href":"https://www.unihiker.com/","type":"story","location":"story"},"clickOpts":{"delayRedirect":true}}' href="https://www.unihiker.com/" rel="nofollow">
      UNIHIKER
     </a>
     <span>
      . This is a cutting-edge single-board computer designed to revolutionize your computing experience. Packed with a 2.8-inch touchscreen, Wi-Fi, Bluetooth, and an array of sensors including light, accelerometer, gyroscope, and microphone, UNIHIKER is your gateway to a world of possibilities. With its integrated co-processor, this versatile device seamlessly communicates with a wide range of analog, digital, I2C, UART, and SPI sensors and actuators.
     </span>
    </p>
    <div class="carousel-images">
     <img class="carousel-image" src="0.jpg"/>
    </div>
    <p class="hckui__typography__bodyL">
     The script below creates an interactive system where facial expressions and voice commands are detected in real-time. The detected states are published to an MQTT broker, making it possible to control external devices like an ESP32 based on user input. The combination of OpenCV, MediaPipe, and speech recognition allows for a robust and interactive system that can be integrated into various IoT application.
    </p>
    <p class="hckui__typography__bodyL">
     <strong>
      Note:
     </strong>
     <span>
      Ensure that you install the following libraries on your Unihiker:
     </span>
    </p>
    <ul class="hckui__typography__bodyL">
     <li>
      <a class="hckui__typography__linkBlue" data-ha='{"eventName":"Clicked link","customProps":{"value":"OpenCV","href":"https://opencv.org/releases/","type":"story","location":"story"},"clickOpts":{"delayRedirect":true}}' href="https://opencv.org/releases/" rel="nofollow">
       OpenCV
      </a>
     </li>
     <li>
      <a class="hckui__typography__linkBlue" data-ha='{"eventName":"Clicked link","customProps":{"value":"MediaPipe","href":"https://ai.google.dev/edge/mediapipe/solutions/guide","type":"story","location":"story"},"clickOpts":{"delayRedirect":true}}' href="https://ai.google.dev/edge/mediapipe/solutions/guide" rel="nofollow">
       MediaPipe
      </a>
     </li>
     <li>
      <a class="hckui__typography__linkBlue" data-ha='{"eventName":"Clicked link","customProps":{"value":"Speech Recognition","href":"https://pypi.org/project/SpeechRecognition/","type":"story","location":"story"},"clickOpts":{"delayRedirect":true}}' href="https://pypi.org/project/SpeechRecognition/" rel="nofollow">
       Speech Recognition
      </a>
     </li>
     <li>
      <a class="hckui__typography__linkBlue" data-ha='{"eventName":"Clicked link","customProps":{"value":"Cvzone","href":"https://github.com/cvzone/cvzone","type":"story","location":"story"},"clickOpts":{"delayRedirect":true}}' href="https://github.com/cvzone/cvzone" rel="nofollow">
       Cvzone
      </a>
     </li>
     <li>
      <a class="hckui__typography__linkBlue" data-ha='{"eventName":"Clicked link","customProps":{"value":"Mqtt","href":"https://mqtt.org/software/","type":"story","location":"story"},"clickOpts":{"delayRedirect":true}}' href="https://mqtt.org/software/" rel="nofollow">
       Mqtt
      </a>
     </li>
    </ul>
    <pre><code><span>"""</span><br/><span>This Python script combines facial recognition and voice command recognition with an MQTT client.</span><br/><span>It allows real-time face tracking and voice command processing, where the results are published </span><br/><span>to an MQTT broker. The script uses threading to run both face recognition and voice command </span><br/><span>recognition simultaneously. The GUI interface enables starting or stopping these processes.</span><br/><br/><span>Main components:</span><br/><span>1. **MQTT Client**: Connects to an MQTT broker and publishes face and voice recognition results.</span><br/><span>2. **Face Recognition**: Uses MediaPipe's face mesh model to track facial landmarks. Detects mouth </span><br/><span>   status (open/closed) and gaze direction (left/right/center).</span><br/><span>3. **Voice Command Recognition**: Captures voice commands via a microphone and recognizes commands </span><br/><span>   such as "move forward", "move left", "move right", and "stop".</span><br/><span>4. **GUI Interface**: Provides buttons to start and stop voice and face recognition processes.</span><br/><br/><span>Prerequisites:</span><br/><span>- Install the required libraries: paho-mqtt, cvzone, opencv-python, mediapipe, speechrecognition, unihiker.</span><br/><br/><span>Usage:</span><br/><span>- Press "START VOICE COM" to start voice command recognition.</span><br/><span>- Press "START FACE RECOG" to start face recognition.</span><br/><span>- The system will display detected statuses on the screen and publish corresponding messages to the MQTT broker.</span><br/><span>"""</span><br/><br/><span>import paho.mqtt.client as mqtt</span><br/><span>from unihiker import GUI</span><br/><span>import time</span><br/><span>import cvzone</span><br/><span>import cv2 as cv </span><br/><span>import threading</span><br/><span>import mediapipe as mp</span><br/><span>import speech_recognition as sr</span><br/><br/><span># Initialize the GUI interface for Unihiker</span><br/><span>gui = GUI()</span><br/><br/><span># MQTT settings</span><br/><span>mqtt_broker = "broker.hivemq.com"  # Replace with your MQTT broker address</span><br/><span>mqtt_port = 1883</span><br/><span>mqtt_topic = "esp32/face_control"</span><br/><br/><span># Initialize MQTT Client</span><br/><span>client = mqtt.Client()</span><br/><br/><span># Define callback for when the client connects to the MQTT broker</span><br/><span>def on_connect(client, userdata, flags, rc):</span><br/><span>    print(f"Connected with result code {rc}")</span><br/><span>    client.subscribe(mqtt_topic)  # Subscribe to the topic to listen for incoming messages</span><br/><br/><span>client.on_connect = on_connect</span><br/><span>client.connect(mqtt_broker, mqtt_port, 60)</span><br/><br/><span># Start the MQTT client loop in a separate thread</span><br/><span>client.loop_start()</span><br/><br/><span># Global flags to control the running state of face recognition and voice command recognition</span><br/><span>face_recognition_running = False</span><br/><span>voice_command_running = False</span><br/><br/><span>def faceRecognition():</span><br/><span>    """ </span><br/><span>    This function uses MediaPipe to perform real-time face recognition. It detects mouth </span><br/><span>    status (open/closed) and head orientation (looking left, right, or center), and publishes </span><br/><span>    these statuses to the MQTT broker.</span><br/><span>    """</span><br/><span>    global face_recognition_running</span><br/><br/><span>    # Initialize MediaPipe face mesh and drawing tools</span><br/><span>    mp_drawing = mp.solutions.drawing_utils  </span><br/><span>    mp_drawing_styles = mp.solutions.drawing_styles  </span><br/><span>    mp_face_mesh = mp.solutions.face_mesh  </span><br/><br/><span>    # Set drawing specifications for face landmarks</span><br/><span>    drawing_spec = mp_drawing.DrawingSpec(thickness=1, circle_radius=1)</span><br/><br/><span>    # Open the camera for video capture</span><br/><span>    cap = cv.VideoCapture(0)</span><br/><span>    cap.set(cv.CAP_PROP_FRAME_WIDTH, 320)</span><br/><span>    cap.set(cv.CAP_PROP_FRAME_HEIGHT, 240)</span><br/><span>    cap.set(cv.CAP_PROP_BUFFERSIZE, 1)</span><br/><br/><span>    # Create a full-screen window to display the face mesh</span><br/><span>    cv.namedWindow('MediaPipe Face Mesh', cv.WND_PROP_FULLSCREEN)</span><br/><span>    cv.setWindowProperty('MediaPipe Face Mesh', cv.WND_PROP_FULLSCREEN, cv.WINDOW_FULLSCREEN)</span><br/><br/><span>    # Start face mesh detection</span><br/><span>    with mp_face_mesh.FaceMesh(max_num_faces=1, refine_landmarks=True, </span><br/><span>                               min_detection_confidence=0.5, min_tracking_confidence=0.5) as face_mesh:</span><br/><span>        while face_recognition_running and cap.isOpened():</span><br/><span>            success, image = cap.read()</span><br/><span>            if not success:</span><br/><span>                print("Ignoring empty camera frame.")</span><br/><span>                continue</span><br/><br/><span>            # Convert the image to RGB and process it with the face mesh</span><br/><span>            image.flags.writeable = False</span><br/><span>            image = cv.cvtColor(image, cv.COLOR_BGR2RGB)</span><br/><span>            results = face_mesh.process(image)</span><br/><br/><span>            # Convert the image back to BGR for OpenCV processing</span><br/><span>            image.flags.writeable = True</span><br/><span>            image = cv.cvtColor(image, cv.COLOR_RGB2BGR)</span><br/><br/><span>            if results.multi_face_landmarks:</span><br/><span>                for face_landmarks in results.multi_face_landmarks:</span><br/><span>                    # Draw face mesh landmarks on the image</span><br/><span>                    mp_drawing.draw_landmarks(</span><br/><span>                        image=image, </span><br/><span>                        landmark_list=face_landmarks, </span><br/><span>                        connections=mp_face_mesh.FACEMESH_TESSELATION, </span><br/><span>                        landmark_drawing_spec=None, </span><br/><span>                        connection_drawing_spec=mp_drawing_styles.get_default_face_mesh_tesselation_style()</span><br/><span>                    )</span><br/><span>                    mp_drawing.draw_landmarks(</span><br/><span>                        image=image, </span><br/><span>                        landmark_list=face_landmarks, </span><br/><span>                        connections=mp_face_mesh.FACEMESH_CONTOURS, </span><br/><span>                        landmark_drawing_spec=None, </span><br/><span>                        connection_drawing_spec=mp_drawing_styles.get_default_face_mesh_contours_style()</span><br/><span>                    )</span><br/><span>                    mp_drawing.draw_landmarks(</span><br/><span>                        image=image, </span><br/><span>                        landmark_list=face_landmarks, </span><br/><span>                        connections=mp_face_mesh.FACEMESH_IRISES, </span><br/><span>                        landmark_drawing_spec=None, </span><br/><span>                        connection_drawing_spec=mp_drawing_styles.get_default_face_mesh_iris_connections_style()</span><br/><span>                    )</span><br/><br/><span>                    # Calculate the distance between the upper and lower lips</span><br/><span>                    upper_lip = face_landmarks.landmark[13]</span><br/><span>                    lower_lip = face_landmarks.landmark[14]</span><br/><span>                    lip_distance = ((upper_lip.x - lower_lip.x) ** 2 + (upper_lip.y - lower_lip.y) ** 2) ** 0.5</span><br/><span>                    if lip_distance &gt; 0.02:</span><br/><span>                        cvzone.putTextRect(image, "Mouth Open", (10, 40), scale=1.5, thickness=2)</span><br/><span>                        client.publish(mqtt_topic, "Mouth Open")  # Publish to MQTT</span><br/><span>                    else:</span><br/><span>                        cvzone.putTextRect(image, "Mouth Closed", (10, 40), scale=1.5, thickness=2)</span><br/><span>                        client.publish(mqtt_topic, "Mouth Closed")  # Publish to MQTT</span><br/><br/><span>                    # Detect gaze direction based on cheek positions</span><br/><span>                    left_cheek = face_landmarks.landmark[234]</span><br/><span>                    right_cheek = face_landmarks.landmark[454]</span><br/><span>                    if left_cheek.x &lt; 0.3:</span><br/><span>                        cvzone.putTextRect(image, "Looking Left", (10, 80), scale=1.5, thickness=2)</span><br/><span>                        client.publish(mqtt_topic, "Looking Left")  # Publish to MQTT</span><br/><span>                    elif right_cheek.x &gt; 0.7:</span><br/><span>                        cvzone.putTextRect(image, "Looking Right", (10, 80), scale=1.5, thickness=2)</span><br/><span>                        client.publish(mqtt_topic, "Looking Right")  # Publish to MQTT</span><br/><span>                    else:</span><br/><span>                        cvzone.putTextRect(image, "Looking Center", (10, 80), scale=1.5, thickness=2)</span><br/><span>                        client.publish(mqtt_topic, "Looking Center")  # Publish to MQTT</span><br/><br/><span>            # Rotate the image to display it correctly in portrait mode</span><br/><span>            image = cv.rotate(image, cv.ROTATE_90_CLOCKWISE)</span><br/><span>            cv.imshow('MediaPipe Face Mesh', image)</span><br/><br/><span>            # Break the loop if the 'ESC' key is pressed</span><br/><span>            if cv.waitKey(5) &amp; 0xFF == 27:</span><br/><span>                break</span><br/><br/><span>    # Release the camera and close all OpenCV windows</span><br/><span>    cap.release()</span><br/><span>    cv.destroyAllWindows()</span><br/><br/><span>def voiceCommands():</span><br/><span>    """</span><br/><span>    This function listens for voice commands using the microphone and recognizes specific</span><br/><span>    commands such as "move forward", "move left", "move right", and "stop". Recognized </span><br/><span>    commands are published to the MQTT broker.</span><br/><span>    """</span><br/><span>    global voice_command_running</span><br/><br/><span>    recognizer = sr.Recognizer()</span><br/><span>    mic = sr.Microphone()</span><br/><br/><span>    # Adjust the recognizer for ambient noise</span><br/><span>    with mic as source:</span><br/><span>        recognizer.adjust_for_ambient_noise(source)</span><br/><br/><span>    while voice_command_running:</span><br/><span>        with mic as source:</span><br/><span>            print("Listening...")</span><br/><span>            audio = recognizer.listen(source)</span><br/><span>        try:</span><br/><span>            command = recognizer.recognize_google(audio).lower()</span><br/><span>            print(f"You said: {command}")</span><br/><br/><span>            # Publish recognized commands to MQTT</span><br/><span>            if "move forward" in command:</span><br/><span>                print("Moving Forward")</span><br/><span>                client.publish(mqtt_topic, "Move Forward")</span><br/><span>            elif "move left" in command:</span><br/><span>                print("Moving Left")</span><br/><span>                client.publish(mqtt_topic, "Move Left")</span><br/><span>            elif "move right" in command:</span><br/><span>                print("Moving Right")</span><br/><span>                client.publish(mqtt_topic, "Move Right")</span><br/><span>            elif "stop" in command:</span><br/><span>                print("Stopping")</span><br/><span>                client.publish(mqtt_topic, "Stop")</span><br/><span>            else:</span><br/><span>                print("Command not recognized")</span><br/><br/><span>        except sr.UnknownValueError:</span><br/><span>            print("Sorry, I did not understand that.")</span><br/><span>        except sr.RequestError as e:</span><br/><span>            print(f"Sorry, there was an error with the speech recognition service: {e}")</span><br/><br/><span>def startFaceRecognition():</span><br/><span>    """Starts the face recognition process in a separate thread."""</span><br/><span>    global face_recognition_running</span><br/><span>    face_recognition_running = True</span><br/><span>    threading.Thread(target=faceRecognition).start()</span><br/><br/><span>def stopFaceRecognition():</span><br/><span>    """Stops the face recognition process."""</span><br/><span>    global face_recognition_running</span><br/><span>    face_recognition_running = False</span><br/><br/><span>def startVoiceCommands():</span><br/><span>    """Starts the voice command recognition process in a separate thread."""</span><br/><span>    global voice_command_running</span><br/><span>    voice_command_running = True</span><br/><span>    threading.Thread(target=voiceCommands).start()</span><br/><br/><span>def stopVoiceCommands():</span><br/><span>    """Stops the voice command recognition process."""</span><br/><span>    global voice_command_running</span><br/><span>    voice_command_running = False</span><br/><br/><span># Add buttons to the GUI for starting voice and face recognition processes</span><br/><span>gui.add_button(x=120, y=100, w=180, h=30, text="START VOICE COM", origin='center', onclick=startVoiceCommands)</span><br/><span>gui.add_button(x=120, y=180, w=180, h=30, text="START FACE RECOG", origin='center', onclick=startFaceRecognition)</span><br/><br/><span># Display a static text label on the GUI</span><br/><span>info_text = gui.draw_text(x=120, y=50, text='MOMO', color="red", origin='bottom')</span><br/><br/><span># Main loop to keep the script running and allow the GUI and threads to function</span><br/><span>while True:</span><br/><span>    time.sleep(1)</span></code></pre>
    <p class="hckui__typography__bodyL">
     <strong>
      Wiring Diagram Of The Unihiker and Webcam
     </strong>
    </p>
    <div class="carousel-images">
     <img class="carousel-image" src="1.jpg"/>
    </div>
    <h3 class="hckui__typography__h3 title-with-anchor" id="toc-results-4">
     <p>
      <p class="hckui__typography__bodyL">
      </p>
     </p>
     <span>
      Results
     </span>
    </h3>
    <div class="embed-frame">
     <figure class="youtube">
      <iframe allowfullscreen="" frameborder="0" height="500" src="//www.youtube.com/embed/8ZuaToTzkDg?rel=0" style="margin: 10px auto; display: block;" width="75%">
      </iframe>
      <figcaption class="hckui__typography__textCenter hckui__typography__pebble hckui__typography__bodyS hckui__layout__marginTop10">
       Face recognition using a UNIHIKER
      </figcaption>
     </figure>
    </div>
    <h3 class="hckui__typography__h3 title-with-anchor" id="toc-4-location-trucking-and-motor-5">
     <p>
      <p class="hckui__typography__bodyL">
      </p>
     </p>
     <span>
      4.Location Trucking and Motor
     </span>
    </h3>
    <p class="hckui__typography__bodyL">
     <span>
      Espressif Systems
     </span>
     <a class="hckui__typography__linkBlue" data-ha='{"eventName":"Clicked link","customProps":{"value":"ESP32-WROOM-32 MCU","href":"https://www.espressif.com/sites/default/files/documentation/esp32-wroom-32_datasheet_en.pdf","type":"story","location":"story"},"clickOpts":{"delayRedirect":true}}' href="https://www.espressif.com/sites/default/files/documentation/esp32-wroom-32_datasheet_en.pdf" rel="nofollow">
      ESP32-WROOM-32 MCU
     </a>
     <span>
      Modules are versatile and powerful Wi-Fi/Bluetooth/Bluetooth Low Energy (BLE) microcontroller units (MCUs) designed for a wide range of applications. These modules can be used for tasks as diverse as low-power sensor networks and demanding applications like voice encoding, music streaming, and MP3 decoding.
     </span>
    </p>
    <p class="hckui__typography__bodyL">
     <span>
      The
     </span>
     <strong>
      ESP32-WROOM-32U
     </strong>
     <span>
      module differs from the
     </span>
     <strong>
      ESP32-WROOM-32D
     </strong>
     <span>
      by incorporating a U.FL connector, which requires an external IPEX antenna to be connected.
     </span>
    </p>
    <div class="carousel-images">
     <img class="carousel-image" src="2.jpg"/>
    </div>
    <p class="hckui__typography__bodyL">
     <strong>
      <a class="hckui__typography__linkBlue" data-ha='{"eventName":"Clicked link","customProps":{"value":"Notecarriers","href":"https://dev.blues.io/datasheets/notecarrier-datasheet/notecarrier-a/?__hstc=171785791.e9ff222bb4df13eaeaa630a17180541e.1714917780389.1722122282980.1724265338433.6\u0026__hssc=171785791.1.1724265338433\u0026__hsfp=507127670\u0026_gl=1*1ogyy7j*_gcl_au*MjAxNDQwMjgyMC4xNzI0MjY1MzM5*_ga*NTcwMDczODg5LjE3MTQ5MTc3ODU.*_ga_PJ7RGMWWBX*MTcyNDI2NTMzOS44LjAuMTcyNDI2NTMzOS42MC4wLjA.\u0026_ga=2.132128782.1204438760.1724265344-570073889.1714917785","type":"story","location":"story"},"clickOpts":{"delayRedirect":true}}' href="https://dev.blues.io/datasheets/notecarrier-datasheet/notecarrier-a/?__hstc=171785791.e9ff222bb4df13eaeaa630a17180541e.1714917780389.1722122282980.1724265338433.6&amp;__hssc=171785791.1.1724265338433&amp;__hsfp=507127670&amp;_gl=1*1ogyy7j*_gcl_au*MjAxNDQwMjgyMC4xNzI0MjY1MzM5*_ga*NTcwMDczODg5LjE3MTQ5MTc3ODU.*_ga_PJ7RGMWWBX*MTcyNDI2NTMzOS44LjAuMTcyNDI2NTMzOS42MC4wLjA.&amp;_ga=2.132128782.1204438760.1724265344-570073889.1714917785" rel="nofollow">
       Notecarriers
      </a>
     </strong>
     <span>
      are designed to facilitate the transition from prototyping to production for the
     </span>
     <strong>
      Notecard
     </strong>
     <span>
      . The Notecard is intended to be directly soldered onto a circuit board using an edge connector socket, alongside a customer's microcontroller unit (MCU), sensors, and controls. While this approach offers a highly modular configuration for the final product, it can make prototyping unnecessarily challenging.
     </span>
    </p>
    <p class="hckui__typography__bodyL">
     Notecarriers provide breakout connections for the Notecard, as well as circuitry to ensure power management, protection, and signal amplification.
    </p>
    <div class="carousel-images">
     <img class="carousel-image" src="3.jpg"/>
     <img class="carousel-image" src="4.jpg"/>
    </div>
    <p class="hckui__typography__bodyL">
     This code segment serves as an intermediary between the external control system (communicating through MQTT) from the Unihiker and the ESP32 Sense Xiao, and the hoverboard (communicating through a serial connection). It interprets object detection, facial expressions, and voice commands received as MQTT messages and translates them into control commands for the hoverboard.
    </p>
    <p class="hckui__typography__bodyL">
     Note: If you are unfamiliar with hoverboard modification, please refer to this resource to get started:
    </p>
    <ul class="hckui__typography__bodyL">
     <li>
      <a class="hckui__typography__linkBlue" data-ha='{"eventName":"Clicked link","customProps":{"value":"GPN18 - How To: Moving Objects","href":"https://www.youtube.com/watch?v=qnQSL9DBPaE\u0026list=PLuKI-hkh8TW-fqB3zIvJ6aMABnWheFOYM\u0026index=1","type":"story","location":"story"},"clickOpts":{"delayRedirect":true}}' href="https://www.youtube.com/watch?v=qnQSL9DBPaE&amp;list=PLuKI-hkh8TW-fqB3zIvJ6aMABnWheFOYM&amp;index=1" rel="nofollow">
       GPN18 - How To: Moving Objects
      </a>
     </li>
     <li>
      <a class="hckui__typography__linkBlue" data-ha='{"eventName":"Clicked link","customProps":{"value":"Hoverboard Robotics Tutorial","href":"https://www.youtube.com/watch?v=bIHjRTG7ilU\u0026list=PLXJDPdNEjPS4lyRpuGIr0aqRVPMaLvePO","type":"story","location":"story"},"clickOpts":{"delayRedirect":true}}' href="https://www.youtube.com/watch?v=bIHjRTG7ilU&amp;list=PLXJDPdNEjPS4lyRpuGIr0aqRVPMaLvePO" rel="nofollow">
       Hoverboard Robotics Tutorial
      </a>
     </li>
    </ul>
    <div class="carousel-images">
     <img class="carousel-image" src="5.jpg"/>
    </div>
    <blockquote>
     <strong>
      Disclaimer:
     </strong>
     <span>
      Hoverboard modification  can be risky and may void the warranty. It's crucial to prioritize  safety throughout the entire process.Consult a qualified technician for  complex modifications, especially those involving high voltages.Always  exercise caution when working with a modified hoverboard.
     </span>
    </blockquote>
    <p class="hckui__typography__bodyL">
     <strong>
      The configuration
     </strong>
    </p>
    <div class="carousel-images">
     <img class="carousel-image" src="6.jpg"/>
    </div>
    <pre><code><span>/*</span><br/><span> * This Arduino code integrates various functionalities, including Wi-Fi, MQTT, serial communication,</span><br/><span> * and motor control for a hoverboard. The program connects to a Wi-Fi network, subscribes to </span><br/><span> * MQTT topics to receive face control and object detection commands, and controls a hoverboard </span><br/><span> * based on those commands. The hoverboard's control data is received and sent via serial communication.</span><br/><span> *</span><br/><span> * Main Components:</span><br/><span> * 1. **Wi-Fi and MQTT**: Connects to a Wi-Fi network and an MQTT broker to receive and send messages.</span><br/><span> * 2. **Hoverboard Control**: Uses serial communication to send steering and speed commands to a hoverboard.</span><br/><span> * 3. **Object Detection**: Stops the hoverboard if an object is detected and resumes control when the object is cleared.</span><br/><span> * 4. **Face Control**: Controls the hoverboard's movement based on face recognition commands such as "Mouth Open", "Looking Left", etc.</span><br/><span> * 5. **Notecard Communication**: Handles communication with a Notecard for cloud connectivity.</span><br/><span> *</span><br/><span> * Prerequisites:</span><br/><span> * - Libraries: Notecard, Wire, WiFi, PubSubClient, SoftwareSerial</span><br/><span> * - Replace placeholders for Wi-Fi credentials and MQTT topics with actual values.</span><br/><span> *</span><br/><span> * Usage:</span><br/><span> * - Upon startup, the system connects to Wi-Fi and the MQTT broker.</span><br/><span> * - Listens for face control commands to control the hoverboard.</span><br/><span> * - Stops the hoverboard if an object is detected and resumes control when the object is cleared.</span><br/><span> */</span><br/><br/><span>// ########################## DEFINES ##########################</span><br/><span>#define usbSerial Serial</span><br/><span>#define txRxPinsSerial Serial1</span><br/><span>#define NOTE_PRODUCT_UID "com.gmail.bobbanda441145:hello"</span><br/><span>#define HOVER_SERIAL_BAUD   115200      // Baud rate for HoverSerial (used to communicate with the hoverboard)</span><br/><span>#define SERIAL_BAUD         115200      // Baud rate for built-in Serial (used for the Serial Monitor)</span><br/><span>#define START_FRAME         0xABCD      // Start frame definition for reliable serial communication</span><br/><span>#define TIME_SEND           100         // Sending time interval [ms]</span><br/><span>#define SPEED_MAX_TEST      300         // Maximum speed for testing</span><br/><span>#define SPEED_STEP          20          // Speed step for gradual acceleration</span><br/><span>#define LED_BUILTIN       13            // Built-in LED pin</span><br/><br/><span>// WiFi settings</span><br/><span>const char* ssid = "OPPO A37m";        // Replace with your WiFi SSID</span><br/><span>const char* password = "sainebanda";   // Replace with your WiFi password</span><br/><br/><span>// MQTT settings</span><br/><span>const char* mqtt_server = "broker.hivemq.com";</span><br/><span>const char* mqtt_topic_face_control = "esp32/face_control";</span><br/><span>const char* mqtt_topic_object_detected = "object_detected";</span><br/><br/><span>const int SDA_PIN = 5;                 // I2C SDA pin</span><br/><span>const int SCL_PIN = 4;                 // I2C SCL pin</span><br/><br/><span>long previousMillis = 0;               // Variable to store the last time an action was performed</span><br/><span>long interval = 60000 * 10;            // Interval between actions (in milliseconds)</span><br/><br/><span>// Initialize the WiFi and MQTT clients</span><br/><span>WiFiClient espClient;</span><br/><span>PubSubClient client(espClient);</span><br/><br/><span>Notecard notecard;</span><br/><span>SoftwareSerial HoverSerial(2, 19);  // RX, TX pins for SoftwareSerial communication</span><br/><br/><span>// Global variables</span><br/><span>uint8_t idx = 0;              // Index for new data pointer</span><br/><span>uint16_t bufStartFrame;       // Buffer Start Frame for incoming serial data</span><br/><span>byte *p;                      // Pointer declaration for the new received data</span><br/><span>byte incomingByte;            // Incoming byte from serial</span><br/><span>byte incomingBytePrev;        // Previous incoming byte</span><br/><br/><span>bool objectDetected = false;  // Flag to track if an object is detected</span><br/><br/><span>// Struct to define the serial command structure sent to the hoverboard</span><br/><span>typedef struct {</span><br/><span>  uint16_t start;</span><br/><span>  int16_t steer;</span><br/><span>  int16_t speed;</span><br/><span>  uint16_t checksum;</span><br/><span>} SerialCommand;</span><br/><span>SerialCommand Command;</span><br/><br/><span>// Struct to define the feedback structure received from the hoverboard</span><br/><span>typedef struct {</span><br/><span>  uint16_t start;</span><br/><span>  int16_t cmd1;</span><br/><span>  int16_t cmd2;</span><br/><span>  int16_t speedR_meas;</span><br/><span>  int16_t speedL_meas;</span><br/><span>  int16_t batVoltage;</span><br/><span>  int16_t boardTemp;</span><br/><span>  uint16_t cmdLed;</span><br/><span>  uint16_t checksum;</span><br/><span>} SerialFeedback;</span><br/><span>SerialFeedback Feedback;</span><br/><span>SerialFeedback NewFeedback;</span><br/><br/><span>// Function to connect to Wi-Fi</span><br/><span>void setup_wifi() {</span><br/><span>  delay(10);</span><br/><span>  Serial.println();</span><br/><span>  Serial.print("Connecting to ");</span><br/><span>  Serial.println(ssid);</span><br/><br/><span>  WiFi.begin(ssid, password);</span><br/><br/><span>  // Wait until Wi-Fi is connected</span><br/><span>  while (WiFi.status() != WL_CONNECTED) {</span><br/><span>    delay(500);</span><br/><span>    Serial.print(".");</span><br/><span>  }</span><br/><br/><span>  Serial.println("");</span><br/><span>  Serial.println("WiFi connected");</span><br/><span>  Serial.println("IP address: ");</span><br/><span>  Serial.println(WiFi.localIP());</span><br/><span>}</span><br/><br/><span>// MQTT callback function to handle incoming messages</span><br/><span>void callback(char* topic, byte* payload, unsigned int length) {</span><br/><span>  Serial.print("Message arrived on topic: ");</span><br/><span>  Serial.print(topic);</span><br/><span>  Serial.print(". Message: ");</span><br/><span>  </span><br/><span>  String message;</span><br/><span>  for (int i = 0; i &lt; length; i++) {</span><br/><span>    message += (char)payload[i];</span><br/><span>  }</span><br/><span>  Serial.println(message);</span><br/><br/><span>  // Handle object detection messages</span><br/><span>  if (String(topic) == mqtt_topic_object_detected) {</span><br/><span>    if (message == "object_detected") {</span><br/><span>      // Stop the hoverboard if an object is detected</span><br/><span>      Serial.println("Object detected, stopping wheels.");</span><br/><span>      Send(0, 0);  // Send command to stop</span><br/><span>      objectDetected = true;</span><br/><span>    } else if (message == "object_cleared") {</span><br/><span>      // Resume control by face detection if the object is cleared</span><br/><span>      Serial.println("Object cleared, resuming control.");</span><br/><span>      objectDetected = false;</span><br/><span>    }</span><br/><span>  } </span><br/><span>  // Handle face control messages only if no object is detected</span><br/><span>  else if (String(topic) == mqtt_topic_face_control &amp;&amp; !objectDetected) {</span><br/><span>    if (message == "Mouth Open") {</span><br/><span>      // Move the hoverboard forward</span><br/><span>      Serial.println("Moving Forward");</span><br/><span>      Send(0, SPEED_MAX_TEST);  // Send command to move forward</span><br/><span>    } else if (message == "Mouth Closed") {</span><br/><span>      // Stop the hoverboard</span><br/><span>      Serial.println("Stopping");</span><br/><span>      Send(0, 0);  // Send command to stop</span><br/><span>    } else if (message == "Looking Left") {</span><br/><span>      // Turn the hoverboard left</span><br/><span>      Serial.println("Turning Left");</span><br/><span>      Send(-SPEED_MAX_TEST, SPEED_STEP);  // Send command to turn left</span><br/><span>    } else if (message == "Looking Right") {</span><br/><span>      // Turn the hoverboard right</span><br/><span>      Serial.println("Turning Right");</span><br/><span>      Send(SPEED_MAX_TEST, SPEED_STEP);  // Send command to turn right</span><br/><span>    }</span><br/><span>  }</span><br/><span>}</span><br/><br/><span>// Function to reconnect to MQTT broker if the connection is lost</span><br/><span>void reconnect() {</span><br/><span>  while (!client.connected()) {</span><br/><span>    Serial.print("Attempting MQTT connection...");</span><br/><span>    if (client.connect("ESP32Client")) {</span><br/><span>      Serial.println("connected");</span><br/><span>      client.subscribe(mqtt_topic_face_control);  // Subscribe to face control topic</span><br/><span>      client.subscribe(mqtt_topic_object_detected);  // Subscribe to object detection topic</span><br/><span>    } else {</span><br/><span>      Serial.print("failed, rc=");</span><br/><span>      Serial.print(client.state());</span><br/><span>      Serial.println(" try again in 5 seconds");</span><br/><span>      delay(5000);  // Wait 5 seconds before retrying</span><br/><span>    }</span><br/><span>  }</span><br/><span>}</span><br/><br/><span>// Function to send steering and speed commands to the hoverboard</span><br/><span>void Send(int16_t uSteer, int16_t uSpeed) {</span><br/><span>  Command.start = (uint16_t)START_FRAME;  // Start frame</span><br/><span>  Command.steer = (int16_t)uSteer;        // Steering command</span><br/><span>  Command.speed = (int16_t)uSpeed;        // Speed command</span><br/><span>  Command.checksum = (uint16_t)(Command.start ^ Command.steer ^ Command.speed);  // Calculate checksum</span><br/><br/><span>  // Write the command to the hoverboard serial</span><br/><span>  HoverSerial.write((uint8_t *)&amp;Command, sizeof(Command)); </span><br/><span>}</span><br/><br/><span>// Function to receive and process data from the hoverboard</span><br/><span>void Receive() {</span><br/><span>  // Check for new data in the serial buffer</span><br/><span>  if (HoverSerial.available()) {</span><br/><span>    incomingByte = HoverSerial.read();  // Read incoming byte</span><br/><span>    bufStartFrame = ((uint16_t)(incomingByte) &lt;&lt; 8) | incomingBytePrev;  // Construct the start frame</span><br/><span>  } else {</span><br/><span>    return;</span><br/><span>  }</span><br/><br/><span>#ifdef DEBUG_RX</span><br/><span>  Serial.print(incomingByte);</span><br/><span>  return;</span><br/><span>#endif</span><br/><br/><span>  // Process the received data if the start frame is detected</span><br/><span>  if (bufStartFrame == START_FRAME) {</span><br/><span>    p = (byte *)&amp;NewFeedback;</span><br/><span>    *p++ = incomingBytePrev;</span><br/><span>    *p++ = incomingByte;</span><br/><span>    idx = 2;</span><br/><span>  } else if (idx &gt;= 2 &amp;&amp; idx &lt; sizeof(SerialFeedback)) {</span><br/><span>    *p++ = incomingByte;</span><br/><span>    idx++;</span><br/><span>  }</span><br/><br/><span>  // Verify the checksum and update the feedback if valid</span><br/><span>  if (idx == sizeof(SerialFeedback)) {</span><br/><span>    uint16_t checksum;</span><br/><span>    checksum = (uint16_t)(NewFeedback.start ^ NewFeedback.cmd1 ^ NewFeedback.cmd2 ^ NewFeedback.speedR_meas ^ NewFeedback.speedL_meas</span><br/><span>                          ^ NewFeedback.batVoltage ^ NewFeedback.boardTemp ^ NewFeedback.cmdLed);</span><br/><br/><span>    if (NewFeedback.start == START_FRAME &amp;&amp; checksum == NewFeedback.checksum) {</span><br/><span>      memcpy(&amp;Feedback, &amp;NewFeedback, sizeof(SerialFeedback));  // Copy the valid feedback data</span><br/><span>    } else {</span><br/><span>      Serial.println("Non-valid data skipped");</span><br/><span>    }</span><br/><span>    idx = 0;  // Reset index</span><br/><span>  }</span><br/><br/><span>  // Update the previous byte for the next cycle</span><br/><span>  incomingBytePrev = incomingByte;</span><br/><span>}</span><br/><br/><span>// Setup function that runs once at the beginning</span><br/><span>void setup() {</span><br/><span>  Serial.begin(SERIAL_BAUD);  // Initialize built-in serial communication</span><br/><span>  HoverSerial.begin(HOVER_SERIAL_BAUD);  // Initialize hoverboard serial communication</span><br/><span>  pinMode(LED_BUILTIN, OUTPUT);  // Set the built-in LED pin as output</span><br/><span>  digitalWrite(LED_BUILTIN, LOW);  // Turn off the built-in LED</span><br/><br/><span>  // Initialize the Notecard</span><br/><span>  Wire.begin(SDA_PIN, SCL_PIN);</span><br/><span>  notecard.begin(txRxPinsSerial);</span><br/><span>  notecard.setDebugOutputStream(usbSerial);</span><br/><br/><span>  // Connect to Wi-Fi</span><br/><span>  setup_wifi();</span><br/><br/><span>  // Setup MQTT server connection</span><br/><span>  client.setServer(mqtt_server, 1883);</span><br/><span>  client.setCallback(callback);</span><br/><span>}</span><br/><br/><span>// Loop function that runs continuously after setup</span><br/><span>void loop() {</span><br/><span>  if (!client.connected()) {</span><br/><span>    reconnect();  // Reconnect to MQTT broker if disconnected</span><br/><span>  }</span><br/><span>  client.loop();  // Process MQTT messages</span><br/><br/><span>  // Handle hoverboard communication</span><br/><span>  Receive();</span><br/><span>  delay(10);  // Short delay to allow loop processing</span><br/><span>}</span></code></pre>
    <p class="hckui__typography__bodyL">
     <strong>
      Wiring Diagram for esp32 Wroom and Notecarrier
     </strong>
    </p>
    <div class="carousel-images">
     <img class="carousel-image" src="7.jpg"/>
    </div>
    <blockquote>
     I intended to include a video demonstrating how these configurations function, but due to a 48-hour power outage, I couldn't record it.
    </blockquote>
    <h3 class="hckui__typography__h3 title-with-anchor" id="toc-5-the-object-detection-6">
     <p>
      <p class="hckui__typography__bodyL">
      </p>
     </p>
     <span>
      5.The Object Detection
     </span>
    </h3>
    <p class="hckui__typography__bodyL">
     <span>
      For object detection, we are using the
     </span>
     <a class="hckui__typography__linkBlue" data-ha='{"eventName":"Clicked link","customProps":{"value":"ESP32-S3 Xiao Sense","href":"https://wiki.seeedstudio.com/xiao_esp32s3_getting_started/","type":"story","location":"story"},"clickOpts":{"delayRedirect":true}}' href="https://wiki.seeedstudio.com/xiao_esp32s3_getting_started/" rel="nofollow">
      ESP32-S3 Xiao Sense
     </a>
     <span>
      . The Seeed Studio XIAO ESP32-S3 utilizes a dual-core ESP32-S3 chip, supporting both Wi-Fi and Bluetooth Low Energy (BLE) wireless connectivity, enabling battery charging. It features a built-in camera sensor and digital microphone. Additionally, it offers 8MB of PSRAM, 8MB of FLASH, and an external SD card slot. All these features make it well-suited for embedded machine learning applications, such as intelligent voice and vision AI.
     </span>
    </p>
    <div class="carousel-images">
     <img class="carousel-image" src="8.jpg"/>
    </div>
    <p class="hckui__typography__bodyL">
     The provided code demonstrates how to utilize Edge Impulse for object detection on the ESP32-S3 Xiao Sense. It begins by initializing WiFi, MQTT, the camera, and waiting before starting the inference process. In the main loop, the code manages the MQTT connection, captures an image, prepares the data for inference, runs the classifier, and processes the object detection results. If an object is detected with a confidence level above a defined threshold, an MQTT message is published. This code showcases the integration of Edge Impulse models for real-time object detection on a microcontroller board.
    </p>
    <pre><code><span>/* Edge Impulse Arduino examples</span><br/><span> * Copyright (c) 2022 EdgeImpulse Inc.</span><br/><span> *</span><br/><span> * Permission is hereby granted, free of charge, to any person obtaining a copy</span><br/><span> * of this software and associated documentation files (the "Software"), to deal</span><br/><span> * in the Software without restriction, including without limitation the rights</span><br/><span> * to use, copy, modify, merge, publish, distribute, sublicense, and/or sell</span><br/><span> * copies of the Software, and to permit persons to whom the Software is</span><br/><span> * furnished to do so, subject to the following conditions:</span><br/><span> *</span><br/><span> * The above copyright notice and this permission notice shall be included in</span><br/><span> * all copies or substantial portions of the Software.</span><br/><span> *</span><br/><span> * THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR</span><br/><span> * IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,</span><br/><span> * FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE</span><br/><span> * AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER</span><br/><span> * LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,</span><br/><span> * OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE</span><br/><span> * SOFTWARE.</span><br/><span> */</span><br/><br/><span>// These sketches are tested with 2.0.4 ESP32 Arduino Core</span><br/><span>// https://github.com/espressif/arduino-esp32/releases/tag/2.0.4</span><br/><br/><span>/* Includes ---------------------------------------------------------------- */</span><br/><span>#include &lt;XIAO-ESP32S3-Sense-Object_Detection_inferencing.h&gt;</span><br/><span>#include "edge-impulse-sdk/dsp/image/image.hpp"</span><br/><span>#include "esp_camera.h"</span><br/><span>#include &lt;WiFi.h&gt;</span><br/><span>#include &lt;PubSubClient.h&gt;</span><br/><br/><span>// WiFi credentials</span><br/><span>const char* ssid = "OPPO A37m";</span><br/><span>const char* password = "sainebanda";</span><br/><br/><span>// MQTT broker credentials</span><br/><span>const char* mqtt_server = "broker.hivemq.com";  // Example broker</span><br/><span>const char* mqtt_topic = "wheel/control";</span><br/><br/><span>// Initialize WiFi and MQTT clients</span><br/><span>WiFiClient espClient;</span><br/><span>PubSubClient client(espClient);</span><br/><br/><span>#define CAMERA_MODEL_ESP_EYE // Has PSRAM</span><br/><span>//#define CAMERA_MODEL_AI_THINKER // Has PSRAM</span><br/><br/><span>#if defined(CAMERA_MODEL_ESP_EYE)</span><br/><span>#define PWDN_GPIO_NUM     -1 </span><br/><span>#define RESET_GPIO_NUM    -1 </span><br/><span>#define XCLK_GPIO_NUM     10 </span><br/><span>#define SIOD_GPIO_NUM     40 </span><br/><span>#define SIOC_GPIO_NUM     39</span><br/><span>#define Y9_GPIO_NUM       48 </span><br/><span>#define Y8_GPIO_NUM       11 </span><br/><span>#define Y7_GPIO_NUM       12 </span><br/><span>#define Y6_GPIO_NUM       14 </span><br/><span>#define Y5_GPIO_NUM       16 </span><br/><span>#define Y4_GPIO_NUM       18 </span><br/><span>#define Y3_GPIO_NUM       17 </span><br/><span>#define Y2_GPIO_NUM       15 </span><br/><span>#define VSYNC_GPIO_NUM    38 </span><br/><span>#define HREF_GPIO_NUM     47 </span><br/><span>#define PCLK_GPIO_NUM     13</span><br/><span>#else</span><br/><span>#error "Camera model not selected"</span><br/><span>#endif</span><br/><br/><span>/* Constant defines -------------------------------------------------------- */</span><br/><span>#define EI_CAMERA_RAW_FRAME_BUFFER_COLS           320</span><br/><span>#define EI_CAMERA_RAW_FRAME_BUFFER_ROWS           240</span><br/><span>#define EI_CAMERA_FRAME_BYTE_SIZE                 3</span><br/><br/><span>/* Private variables ------------------------------------------------------- */</span><br/><span>static bool debug_nn = false; // Set this to true to see e.g. features generated from the raw signal</span><br/><span>static bool is_initialised = false;</span><br/><span>uint8_t *snapshot_buf; // Points to the output of the capture</span><br/><br/><span>static camera_config_t camera_config = {</span><br/><span>    .pin_pwdn = PWDN_GPIO_NUM,</span><br/><span>    .pin_reset = RESET_GPIO_NUM,</span><br/><span>    .pin_xclk = XCLK_GPIO_NUM,</span><br/><span>    .pin_sscb_sda = SIOD_GPIO_NUM,</span><br/><span>    .pin_sscb_scl = SIOC_GPIO_NUM,</span><br/><br/><span>    .pin_d7 = Y9_GPIO_NUM,</span><br/><span>    .pin_d6 = Y8_GPIO_NUM,</span><br/><span>    .pin_d5 = Y7_GPIO_NUM,</span><br/><span>    .pin_d4 = Y6_GPIO_NUM,</span><br/><span>    .pin_d3 = Y5_GPIO_NUM,</span><br/><span>    .pin_d2 = Y4_GPIO_NUM,</span><br/><span>    .pin_d1 = Y3_GPIO_NUM,</span><br/><span>    .pin_d0 = Y2_GPIO_NUM,</span><br/><span>    .pin_vsync = VSYNC_GPIO_NUM,</span><br/><span>    .pin_href = HREF_GPIO_NUM,</span><br/><span>    .pin_pclk = PCLK_GPIO_NUM,</span><br/><br/><span>    // XCLK 20MHz or 10MHz for OV2640 double FPS (Experimental)</span><br/><span>    .xclk_freq_hz = 20000000,</span><br/><span>    .ledc_timer = LEDC_TIMER_0,</span><br/><span>    .ledc_channel = LEDC_CHANNEL_0,</span><br/><br/><span>    .pixel_format = PIXFORMAT_JPEG, // YUV422,GRAYSCALE,RGB565,JPEG</span><br/><span>    .frame_size = FRAMESIZE_QVGA,    // QQVGA-UXGA Do not use sizes above QVGA when not JPEG</span><br/><br/><span>    .jpeg_quality = 12, // 0-63 lower number means higher quality</span><br/><span>    .fb_count = 1,       // If more than one, i2s runs in continuous mode. Use only with JPEG</span><br/><span>    .fb_location = CAMERA_FB_IN_PSRAM,</span><br/><span>    .grab_mode = CAMERA_GRAB_WHEN_EMPTY,</span><br/><span>};</span><br/><br/><span>/* Function definitions ------------------------------------------------------- */</span><br/><span>bool ei_camera_init(void);</span><br/><span>void ei_camera_deinit(void);</span><br/><span>bool ei_camera_capture(uint32_t img_width, uint32_t img_height, uint8_t *out_buf);</span><br/><span>void setup_wifi();</span><br/><span>void reconnect();</span><br/><span>int ei_camera_get_data(size_t offset, size_t length, float *out_ptr);  // Added this function</span><br/><br/><span>/**</span><br/><span> * @brief   Setup image sensor &amp; start streaming</span><br/><span> *</span><br/><span> * @retval  false if initialisation failed</span><br/><span> */</span><br/><span>bool ei_camera_init(void) {</span><br/><span>    if (is_initialised) return true;</span><br/><br/><span>    // Initialize the camera</span><br/><span>    if (esp_camera_init(&amp;camera_config) != ESP_OK) {</span><br/><span>        ei_printf("Camera init failed\r\n");</span><br/><span>        return false;</span><br/><span>    }</span><br/><span>    is_initialised = true;</span><br/><span>    return true;</span><br/><span>}</span><br/><br/><span>/**</span><br/><span> * @brief   Deinitialize the image sensor</span><br/><span> */</span><br/><span>void ei_camera_deinit(void) {</span><br/><span>    if (!is_initialised) return;</span><br/><span>    esp_camera_deinit();</span><br/><span>    is_initialised = false;</span><br/><span>}</span><br/><br/><span>/**</span><br/><span> * @brief   Capture an image using the camera</span><br/><span> *</span><br/><span> * @param[in]  img_width   Width of the image</span><br/><span> * @param[in]  img_height  Height of the image</span><br/><span> * @param[out] out_buf     Pointer to buffer where image data will be stored</span><br/><span> * @retval     True on success, false on failure</span><br/><span> */</span><br/><span>bool ei_camera_capture(uint32_t img_width, uint32_t img_height, uint8_t *out_buf) {</span><br/><span>    camera_fb_t *fb = esp_camera_fb_get();</span><br/><span>    if (!fb) {</span><br/><span>        ei_printf("Camera capture failed\r\n");</span><br/><span>        return false;</span><br/><span>    }</span><br/><br/><span>    memcpy(out_buf, fb-&gt;buf, fb-&gt;len);</span><br/><span>    esp_camera_fb_return(fb);</span><br/><span>    return true;</span><br/><span>}</span><br/><br/><span>/**</span><br/><span> * @brief   Setup WiFi connection</span><br/><span> */</span><br/><span>void setup_wifi() {</span><br/><span>    delay(10);</span><br/><span>    // Connect to WiFi</span><br/><span>    Serial.println();</span><br/><span>    Serial.print("Connecting to ");</span><br/><span>    Serial.println(ssid);</span><br/><br/><span>    WiFi.begin(ssid, password);</span><br/><br/><span>    while (WiFi.status() != WL_CONNECTED) {</span><br/><span>        delay(500);</span><br/><span>        Serial.print(".");</span><br/><span>    }</span><br/><br/><span>    Serial.println("");</span><br/><span>    Serial.println("WiFi connected");</span><br/><span>    Serial.println("IP address: ");</span><br/><span>    Serial.println(WiFi.localIP());</span><br/><span>}</span><br/><br/><span>/**</span><br/><span> * @brief   Reconnect to MQTT broker</span><br/><span> */</span><br/><span>void reconnect() {</span><br/><span>    // Loop until we're reconnected</span><br/><span>    while (!client.connected()) {</span><br/><span>        Serial.print("Attempting MQTT connection...");</span><br/><span>        // Attempt to connect</span><br/><span>        if (client.connect("ESP32Client")) {</span><br/><span>            Serial.println("connected");</span><br/><span>            // Once connected, publish an announcement...</span><br/><span>            client.publish("outTopic", "hello world");</span><br/><span>            // ... and resubscribe</span><br/><span>            client.subscribe("inTopic");</span><br/><span>        } else {</span><br/><span>            Serial.print("failed, rc=");</span><br/><span>            Serial.print(client.state());</span><br/><span>            Serial.println(" try again in 5 seconds");</span><br/><span>            // Wait 5 seconds before retrying</span><br/><span>            delay(5000);</span><br/><span>        }</span><br/><span>    }</span><br/><span>}</span><br/><br/><span>/**</span><br/><span> * @brief   Retrieve camera data and populate the output buffer</span><br/><span> *</span><br/><span> * @param[in]  offset   Offset in the buffer to start reading</span><br/><span> * @param[in]  length   Number of bytes to read</span><br/><span> * @param[out] out_ptr  Pointer to output buffer</span><br/><span> * @retval     0 on success</span><br/><span> */</span><br/><span>int ei_camera_get_data(size_t offset, size_t length, float *out_ptr) {</span><br/><span>    for (size_t i = 0; i &lt; length; i++) {</span><br/><span>        out_ptr[i] = static_cast&lt;float&gt;(snapshot_buf[offset + i]) / 255.0f;</span><br/><span>    }</span><br/><span>    return 0;</span><br/><span>}</span><br/><br/><span>/**</span><br/><span> * @brief      Arduino setup function</span><br/><span> */</span><br/><span>void setup() {</span><br/><span>    Serial.begin(115200);</span><br/><span>    while (!Serial);</span><br/><br/><span>    setup_wifi();  // Initialize WiFi</span><br/><span>    client.setServer(mqtt_server, 1883);  // Initialize MQTT server</span><br/><br/><span>    Serial.println("Edge Impulse Inferencing Demo");</span><br/><span>    if (ei_camera_init() == false) {</span><br/><span>        ei_printf("Failed to initialize Camera!\r\n");</span><br/><span>    } else {</span><br/><span>        ei_printf("Camera initialized\r\n");</span><br/><span>    }</span><br/><br/><span>    ei_printf("\nStarting continuous inference in 2 seconds...\n");</span><br/><span>    ei_sleep(2000);</span><br/><span>}</span><br/><br/><span>/**</span><br/><span> * @brief      Get data and run inferencing</span><br/><span> *</span><br/><span> * @param[in]  debug  Get debug info if true</span><br/><span> */</span><br/><span>void loop() {</span><br/><span>    if (!client.connected()) {</span><br/><span>        reconnect();  // Reconnect to MQTT broker if connection is lost</span><br/><span>    }</span><br/><span>    client.loop();</span><br/><br/><span>    if (ei_sleep(5) != EI_IMPULSE_OK) {</span><br/><span>        return;</span><br/><span>    }</span><br/><br/><span>    snapshot_buf = (uint8_t*)malloc(EI_CAMERA_RAW_FRAME_BUFFER_COLS * EI_CAMERA_RAW_FRAME_BUFFER_ROWS * EI_CAMERA_FRAME_BYTE_SIZE);</span><br/><br/><span>    if (snapshot_buf == nullptr) {</span><br/><span>        ei_printf("ERR: Failed to allocate snapshot buffer!\n");</span><br/><span>        return;</span><br/><span>    }</span><br/><br/><span>    ei::signal_t signal;</span><br/><span>    signal.total_length = EI_CLASSIFIER_INPUT_WIDTH * EI_CLASSIFIER_INPUT_HEIGHT;</span><br/><span>    signal.get_data = &amp;ei_camera_get_data;</span><br/><br/><span>    if (ei_camera_capture((size_t)EI_CLASSIFIER_INPUT_WIDTH, (size_t)EI_CLASSIFIER_INPUT_HEIGHT, snapshot_buf) == false) {</span><br/><span>        ei_printf("Failed to capture image\r\n");</span><br/><span>        free(snapshot_buf);</span><br/><span>        return;</span><br/><span>    }</span><br/><br/><span>    ei_impulse_result_t result = { 0 };</span><br/><br/><span>    EI_IMPULSE_ERROR err = run_classifier(&amp;signal, &amp;result, debug_nn);</span><br/><span>    if (err != EI_IMPULSE_OK) {</span><br/><span>        ei_printf("ERR: Failed to run classifier (%d)\n", err);</span><br/><span>        return;</span><br/><span>    }</span><br/><br/><span>    ei_printf("Predictions (DSP: %d ms., Classification: %d ms., Anomaly: %d ms.): \n",</span><br/><span>                result.timing.dsp, result.timing.classification, result.timing.anomaly);</span><br/><br/><span>#if EI_CLASSIFIER_OBJECT_DETECTION == 1</span><br/><span>    ei_printf("Object detection bounding boxes:\r\n");</span><br/><span>    for (uint32_t i = 0; i &lt; result.bounding_boxes_count; i++) {</span><br/><span>        ei_impulse_result_bounding_box_t bb = result.bounding_boxes[i];</span><br/><span>        if (bb.value == 0) {</span><br/><span>            continue;</span><br/><span>        }</span><br/><span>        ei_printf("  %s (%f) [ x: %u, y: %u, width: %u, height: %u ]\r\n",</span><br/><span>                bb.label,</span><br/><span>                bb.value,</span><br/><span>                bb.x,</span><br/><span>                bb.y,</span><br/><span>                bb.width,</span><br/><span>                bb.height);</span><br/><br/><span>        // Send MQTT message if object is detected</span><br/><span>        if (bb.value &gt; 0.5) {  // Adjust this threshold as needed</span><br/><span>            client.publish(mqtt_topic, "object_detected");</span><br/><span>        }</span><br/><span>    }</span><br/><span>#else</span><br/><span>    ei_printf("Predictions:\r\n");</span><br/><span>    for (uint16_t i = 0; i &lt; EI_CLASSIFIER_LABEL_COUNT; i++) {</span><br/><span>        ei_printf("  %s: ", ei_classifier_inferencing_categories[i]);</span><br/><span>        ei_printf("%.5f\r\n", result.classification[i].value);</span><br/><span>    }</span><br/><span>#endif</span><br/><br/><span>    free(snapshot_buf);</span><br/><span>}</span></code></pre>
    <blockquote>
     I intended to include a video demonstrating how these configurations function, but due to a 48-hour power outage, I couldn't record it.
    </blockquote>
    <h3 class="hckui__typography__h3 title-with-anchor" id="toc-6-wiring-diagram-of-the-whole-system-7">
     <p>
      <p class="hckui__typography__bodyL">
      </p>
     </p>
     <span>
      6.Wiring Diagram Of the whole system
     </span>
    </h3>
    <div class="carousel-images">
     <img class="carousel-image" src="9.jpg"/>
    </div>
    <h3 class="hckui__typography__h3 title-with-anchor" id="toc-workflow-8">
     <p>
      <p class="hckui__typography__bodyL">
      </p>
     </p>
     <span>
      WorkFlow
     </span>
    </h3>
    <p class="hckui__typography__bodyL">
     A Unihiker serves as the input for both face recognition and voice control.For face recognition, Face Mesh is used to detect the face and draw landmarks on it. The mouth landmarks are used to determine if the mouth is open or closed. If the mouth is open, the Unihiker sends commands to the ESP32 Wroom using MQTT. The ESP32 Wroom subscribes to this topic on the same network (WiFi) and executes corresponding commands to control the hoverboard motors (e.g., forward, stop, left, right).
    </p>
    <p class="hckui__typography__bodyL">
     The ESP32 Wroom also acts as the host controller for the Notecarrier and Notecard, which are used to track the system's location for safety purposes.
    </p>
    <p class="hckui__typography__bodyL">
     The system also incorporates voice commands. This is useful when the user is wearing a mask, making it difficult for the system to detect the face. The user can say words like "move forward," "stop," "left," or "right" to send commands to the ESP32 Wroom and control the motors.
    </p>
    <p class="hckui__typography__bodyL">
     Additionally, an ESP32 Sense Xiao is used for object detection. If an object is detected in front of the system, a topic is sent to an ESP32 Wroom over the WiFi network. The ESP32 Wroom then ensures that it ignores commands from the Unihiker and issues a command to stop the motors.
    </p>
    <p class="hckui__typography__bodyL">
     <strong>
      6.BOM
     </strong>
    </p>
    <p class="hckui__typography__bodyL">
     <strong>
      Devices
     </strong>
    </p>
    <p class="hckui__typography__bodyL">
     • UNIHIKER
    </p>
    <p class="hckui__typography__bodyL">
     • ESP32-Wroom
    </p>
    <p class="hckui__typography__bodyL">
     • Logitech C920 HD Pro Webcam,
    </p>
    <p class="hckui__typography__bodyL">
     • Esp32-sence Xiao
    </p>
    <p class="hckui__typography__bodyL">
     • Hoverboard
    </p>
    <p class="hckui__typography__bodyL">
     • Notecarrier -AE
    </p>
    <p class="hckui__typography__bodyL">
     • Notecard
    </p>
    <p class="hckui__typography__bodyL">
     <strong>
      Power
     </strong>
    </p>
    <p class="hckui__typography__bodyL">
     • 5 Volts power supply
    </p>
    <p class="hckui__typography__bodyL">
     • 42 Volt 13 Amp Lithium batteries
    </p>
    <p class="hckui__typography__bodyL">
     <strong>
      Wires
     </strong>
    </p>
    <p class="hckui__typography__bodyL">
     • Male to male jumpers
    </p>
    <p class="hckui__typography__bodyL">
     • Female to male jumpers
    </p>
    <p class="hckui__typography__bodyL">
     <strong>
      Tools
     </strong>
    </p>
    <p class="hckui__typography__bodyL">
     • Solder and iron
    </p>
    <p class="hckui__typography__bodyL">
     • Multimeter
    </p>
    <p class="hckui__typography__bodyL">
     • Wire strippers and cutters
    </p>
    <p class="hckui__typography__bodyL">
     • Crimp tools
    </p>
    <p class="hckui__typography__bodyL">
     <span>
      •  Glue gun
     </span>
     <br/>
     <br/>
     <strong>
      7.Future Works
     </strong>
    </p>
    <p class="hckui__typography__bodyL">
     The Dual Control Wheelchair project has significant potential for further development. By enhancing face recognition and voice control, expanding functionality, improving safety and security, and integrating with other technologies, the project can offer even more innovative solutions for individuals with mobility impairments. Future improvements might include advanced face mesh models, noise reduction techniques, multi-modal input, obstacle avoidance algorithms, autonomous navigation, remote control, emergency stop mechanisms, data privacy measures, system monitoring tools and IoT integration. These advancements could lead to a more intuitive, reliable, and versatile wheelchair that empowers users to navigate their environments with greater independence and confidence.
    </p>
   </div>
  </section>
  <div class="project-section-break">
  </div>
  <section id="schematics">
   <div class="project-section-title">
    <h2 class="hckui__typography__h2 title-with-anchor">
     <span>
      Schematics
     </span>
    </h2>
   </div>
   <div class="project-attachment">
    <div class="header">
     <div class="text">
      <h3 class="hckui__typography__h3">
       System Diagram
      </h3>
      <div class="hckui__typography__bodyS hckui__typography__pebble">
       This is the systems Diagram
      </div>
     </div>
    </div>
    <div class="embed original boxed hckui__typography__textCenter">
     <img src="26.jpg"/>
    </div>
   </div>
  </section>
  <div class="project-section-break">
  </div>
  <section id="code">
   <div class="project-section-title">
    <h2 class="hckui__typography__h2 title-with-anchor">
     <span>
      Code
     </span>
    </h2>
   </div>
   <div class="project-attachment project-code-widget single-file">
    <div class="tabs hckui__typography__bodyS">
     <ul>
      <li class="active">
       <a data-target="#code-widget-657347" href="javascript:void(0)">
        Unihicker
       </a>
      </li>
     </ul>
    </div>
    <div class="preview-container">
     <div class="preview-pane active" id="code-widget-657347">
      <div class="header">
       <div class="text">
        <div class="title">
         <h3 class="hckui__typography__h3">
          Unihicker
         </h3>
         <span class="hckui__typography__bodyS hckui__typography__pebble">
          Python
         </span>
        </div>
        <div class="comment">
         <div class="hckui__typography__bodyS hckui__typography__pebble">
          These codes are for the Unihicker
         </div>
        </div>
       </div>
      </div>
      <div class="preview-body pygments-syntax all">
       <div class="highlight">
        <pre><span></span><span id="line-1"><span class="sd">"""</span>
</span><span id="line-2"><span class="sd">This Python script combines facial recognition and voice command recognition with an MQTT client.</span>
</span><span id="line-3"><span class="sd">It allows real-time face tracking and voice command processing, where the results are published </span>
</span><span id="line-4"><span class="sd">to an MQTT broker. The script uses threading to run both face recognition and voice command </span>
</span><span id="line-5"><span class="sd">recognition simultaneously. The GUI interface enables starting or stopping these processes.</span>
</span><span id="line-6">
</span><span id="line-7"><span class="sd">Main components:</span>
</span><span id="line-8"><span class="sd">1. **MQTT Client**: Connects to an MQTT broker and publishes face and voice recognition results.</span>
</span><span id="line-9"><span class="sd">2. **Face Recognition**: Uses MediaPipe's face mesh model to track facial landmarks. Detects mouth </span>
</span><span id="line-10"><span class="sd">   status (open/closed) and gaze direction (left/right/center).</span>
</span><span id="line-11"><span class="sd">3. **Voice Command Recognition**: Captures voice commands via a microphone and recognizes commands </span>
</span><span id="line-12"><span class="sd">   such as "move forward", "move left", "move right", and "stop".</span>
</span><span id="line-13"><span class="sd">4. **GUI Interface**: Provides buttons to start and stop voice and face recognition processes.</span>
</span><span id="line-14">
</span><span id="line-15"><span class="sd">Prerequisites:</span>
</span><span id="line-16"><span class="sd">- Install the required libraries: paho-mqtt, cvzone, opencv-python, mediapipe, speechrecognition, unihiker.</span>
</span><span id="line-17">
</span><span id="line-18"><span class="sd">Usage:</span>
</span><span id="line-19"><span class="sd">- Press "START VOICE COM" to start voice command recognition.</span>
</span><span id="line-20"><span class="sd">- Press "START FACE RECOG" to start face recognition.</span>
</span><span id="line-21"><span class="sd">- The system will display detected statuses on the screen and publish corresponding messages to the MQTT broker.</span>
</span><span id="line-22"><span class="sd">"""</span>
</span><span id="line-23">
</span><span id="line-24"><span class="kn">import</span> <span class="nn">paho.mqtt.client</span> <span class="k">as</span> <span class="nn">mqtt</span>
</span><span id="line-25"><span class="kn">from</span> <span class="nn">unihiker</span> <span class="kn">import</span> <span class="n">GUI</span>
</span><span id="line-26"><span class="kn">import</span> <span class="nn">time</span>
</span><span id="line-27"><span class="kn">import</span> <span class="nn">cvzone</span>
</span><span id="line-28"><span class="kn">import</span> <span class="nn">cv2</span> <span class="k">as</span> <span class="nn">cv</span> 
</span><span id="line-29"><span class="kn">import</span> <span class="nn">threading</span>
</span><span id="line-30"><span class="kn">import</span> <span class="nn">mediapipe</span> <span class="k">as</span> <span class="nn">mp</span>
</span><span id="line-31"><span class="kn">import</span> <span class="nn">speech_recognition</span> <span class="k">as</span> <span class="nn">sr</span>
</span><span id="line-32">
</span><span id="line-33"><span class="c1"># Initialize the GUI interface for Unihiker</span>
</span><span id="line-34"><span class="n">gui</span> <span class="o">=</span> <span class="n">GUI</span><span class="p">()</span>
</span><span id="line-35">
</span><span id="line-36"><span class="c1"># MQTT settings</span>
</span><span id="line-37"><span class="n">mqtt_broker</span> <span class="o">=</span> <span class="s2">"broker.hivemq.com"</span>  <span class="c1"># Replace with your MQTT broker address</span>
</span><span id="line-38"><span class="n">mqtt_port</span> <span class="o">=</span> <span class="mi">1883</span>
</span><span id="line-39"><span class="n">mqtt_topic</span> <span class="o">=</span> <span class="s2">"esp32/face_control"</span>
</span><span id="line-40">
</span><span id="line-41"><span class="c1"># Initialize MQTT Client</span>
</span><span id="line-42"><span class="n">client</span> <span class="o">=</span> <span class="n">mqtt</span><span class="o">.</span><span class="n">Client</span><span class="p">()</span>
</span><span id="line-43">
</span><span id="line-44"><span class="c1"># Define callback for when the client connects to the MQTT broker</span>
</span><span id="line-45"><span class="k">def</span> <span class="nf">on_connect</span><span class="p">(</span><span class="n">client</span><span class="p">,</span> <span class="n">userdata</span><span class="p">,</span> <span class="n">flags</span><span class="p">,</span> <span class="n">rc</span><span class="p">):</span>
</span><span id="line-46">    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"Connected with result code </span><span class="si">{</span><span class="n">rc</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>
</span><span id="line-47">    <span class="n">client</span><span class="o">.</span><span class="n">subscribe</span><span class="p">(</span><span class="n">mqtt_topic</span><span class="p">)</span>  <span class="c1"># Subscribe to the topic to listen for incoming messages</span>
</span><span id="line-48">
</span><span id="line-49"><span class="n">client</span><span class="o">.</span><span class="n">on_connect</span> <span class="o">=</span> <span class="n">on_connect</span>
</span><span id="line-50"><span class="n">client</span><span class="o">.</span><span class="n">connect</span><span class="p">(</span><span class="n">mqtt_broker</span><span class="p">,</span> <span class="n">mqtt_port</span><span class="p">,</span> <span class="mi">60</span><span class="p">)</span>
</span><span id="line-51">
</span><span id="line-52"><span class="c1"># Start the MQTT client loop in a separate thread</span>
</span><span id="line-53"><span class="n">client</span><span class="o">.</span><span class="n">loop_start</span><span class="p">()</span>
</span><span id="line-54">
</span><span id="line-55"><span class="c1"># Global flags to control the running state of face recognition and voice command recognition</span>
</span><span id="line-56"><span class="n">face_recognition_running</span> <span class="o">=</span> <span class="kc">False</span>
</span><span id="line-57"><span class="n">voice_command_running</span> <span class="o">=</span> <span class="kc">False</span>
</span><span id="line-58">
</span><span id="line-59"><span class="k">def</span> <span class="nf">faceRecognition</span><span class="p">():</span>
</span><span id="line-60">    <span class="sd">""" </span>
</span><span id="line-61"><span class="sd">    This function uses MediaPipe to perform real-time face recognition. It detects mouth </span>
</span><span id="line-62"><span class="sd">    status (open/closed) and head orientation (looking left, right, or center), and publishes </span>
</span><span id="line-63"><span class="sd">    these statuses to the MQTT broker.</span>
</span><span id="line-64"><span class="sd">    """</span>
</span><span id="line-65">    <span class="k">global</span> <span class="n">face_recognition_running</span>
</span><span id="line-66">
</span><span id="line-67">    <span class="c1"># Initialize MediaPipe face mesh and drawing tools</span>
</span><span id="line-68">    <span class="n">mp_drawing</span> <span class="o">=</span> <span class="n">mp</span><span class="o">.</span><span class="n">solutions</span><span class="o">.</span><span class="n">drawing_utils</span>  
</span><span id="line-69">    <span class="n">mp_drawing_styles</span> <span class="o">=</span> <span class="n">mp</span><span class="o">.</span><span class="n">solutions</span><span class="o">.</span><span class="n">drawing_styles</span>  
</span><span id="line-70">    <span class="n">mp_face_mesh</span> <span class="o">=</span> <span class="n">mp</span><span class="o">.</span><span class="n">solutions</span><span class="o">.</span><span class="n">face_mesh</span>  
</span><span id="line-71">
</span><span id="line-72">    <span class="c1"># Set drawing specifications for face landmarks</span>
</span><span id="line-73">    <span class="n">drawing_spec</span> <span class="o">=</span> <span class="n">mp_drawing</span><span class="o">.</span><span class="n">DrawingSpec</span><span class="p">(</span><span class="n">thickness</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">circle_radius</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
</span><span id="line-74">
</span><span id="line-75">    <span class="c1"># Open the camera for video capture</span>
</span><span id="line-76">    <span class="n">cap</span> <span class="o">=</span> <span class="n">cv</span><span class="o">.</span><span class="n">VideoCapture</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
</span><span id="line-77">    <span class="n">cap</span><span class="o">.</span><span class="n">set</span><span class="p">(</span><span class="n">cv</span><span class="o">.</span><span class="n">CAP_PROP_FRAME_WIDTH</span><span class="p">,</span> <span class="mi">320</span><span class="p">)</span>
</span><span id="line-78">    <span class="n">cap</span><span class="o">.</span><span class="n">set</span><span class="p">(</span><span class="n">cv</span><span class="o">.</span><span class="n">CAP_PROP_FRAME_HEIGHT</span><span class="p">,</span> <span class="mi">240</span><span class="p">)</span>
</span><span id="line-79">    <span class="n">cap</span><span class="o">.</span><span class="n">set</span><span class="p">(</span><span class="n">cv</span><span class="o">.</span><span class="n">CAP_PROP_BUFFERSIZE</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
</span><span id="line-80">
</span><span id="line-81">    <span class="c1"># Create a full-screen window to display the face mesh</span>
</span><span id="line-82">    <span class="n">cv</span><span class="o">.</span><span class="n">namedWindow</span><span class="p">(</span><span class="s1">'MediaPipe Face Mesh'</span><span class="p">,</span> <span class="n">cv</span><span class="o">.</span><span class="n">WND_PROP_FULLSCREEN</span><span class="p">)</span>
</span><span id="line-83">    <span class="n">cv</span><span class="o">.</span><span class="n">setWindowProperty</span><span class="p">(</span><span class="s1">'MediaPipe Face Mesh'</span><span class="p">,</span> <span class="n">cv</span><span class="o">.</span><span class="n">WND_PROP_FULLSCREEN</span><span class="p">,</span> <span class="n">cv</span><span class="o">.</span><span class="n">WINDOW_FULLSCREEN</span><span class="p">)</span>
</span><span id="line-84">
</span><span id="line-85">    <span class="c1"># Start face mesh detection</span>
</span><span id="line-86">    <span class="k">with</span> <span class="n">mp_face_mesh</span><span class="o">.</span><span class="n">FaceMesh</span><span class="p">(</span><span class="n">max_num_faces</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">refine_landmarks</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> 
</span><span id="line-87">                               <span class="n">min_detection_confidence</span><span class="o">=</span><span class="mf">0.5</span><span class="p">,</span> <span class="n">min_tracking_confidence</span><span class="o">=</span><span class="mf">0.5</span><span class="p">)</span> <span class="k">as</span> <span class="n">face_mesh</span><span class="p">:</span>
</span><span id="line-88">        <span class="k">while</span> <span class="n">face_recognition_running</span> <span class="ow">and</span> <span class="n">cap</span><span class="o">.</span><span class="n">isOpened</span><span class="p">():</span>
</span><span id="line-89">            <span class="n">success</span><span class="p">,</span> <span class="n">image</span> <span class="o">=</span> <span class="n">cap</span><span class="o">.</span><span class="n">read</span><span class="p">()</span>
</span><span id="line-90">            <span class="k">if</span> <span class="ow">not</span> <span class="n">success</span><span class="p">:</span>
</span><span id="line-91">                <span class="nb">print</span><span class="p">(</span><span class="s2">"Ignoring empty camera frame."</span><span class="p">)</span>
</span><span id="line-92">                <span class="k">continue</span>
</span><span id="line-93">
</span><span id="line-94">            <span class="c1"># Convert the image to RGB and process it with the face mesh</span>
</span><span id="line-95">            <span class="n">image</span><span class="o">.</span><span class="n">flags</span><span class="o">.</span><span class="n">writeable</span> <span class="o">=</span> <span class="kc">False</span>
</span><span id="line-96">            <span class="n">image</span> <span class="o">=</span> <span class="n">cv</span><span class="o">.</span><span class="n">cvtColor</span><span class="p">(</span><span class="n">image</span><span class="p">,</span> <span class="n">cv</span><span class="o">.</span><span class="n">COLOR_BGR2RGB</span><span class="p">)</span>
</span><span id="line-97">            <span class="n">results</span> <span class="o">=</span> <span class="n">face_mesh</span><span class="o">.</span><span class="n">process</span><span class="p">(</span><span class="n">image</span><span class="p">)</span>
</span><span id="line-98">
</span><span id="line-99">            <span class="c1"># Convert the image back to BGR for OpenCV processing</span>
</span><span id="line-100">            <span class="n">image</span><span class="o">.</span><span class="n">flags</span><span class="o">.</span><span class="n">writeable</span> <span class="o">=</span> <span class="kc">True</span>
</span><span id="line-101">            <span class="n">image</span> <span class="o">=</span> <span class="n">cv</span><span class="o">.</span><span class="n">cvtColor</span><span class="p">(</span><span class="n">image</span><span class="p">,</span> <span class="n">cv</span><span class="o">.</span><span class="n">COLOR_RGB2BGR</span><span class="p">)</span>
</span><span id="line-102">
</span><span id="line-103">            <span class="k">if</span> <span class="n">results</span><span class="o">.</span><span class="n">multi_face_landmarks</span><span class="p">:</span>
</span><span id="line-104">                <span class="k">for</span> <span class="n">face_landmarks</span> <span class="ow">in</span> <span class="n">results</span><span class="o">.</span><span class="n">multi_face_landmarks</span><span class="p">:</span>
</span><span id="line-105">                    <span class="c1"># Draw face mesh landmarks on the image</span>
</span><span id="line-106">                    <span class="n">mp_drawing</span><span class="o">.</span><span class="n">draw_landmarks</span><span class="p">(</span>
</span><span id="line-107">                        <span class="n">image</span><span class="o">=</span><span class="n">image</span><span class="p">,</span> 
</span><span id="line-108">                        <span class="n">landmark_list</span><span class="o">=</span><span class="n">face_landmarks</span><span class="p">,</span> 
</span><span id="line-109">                        <span class="n">connections</span><span class="o">=</span><span class="n">mp_face_mesh</span><span class="o">.</span><span class="n">FACEMESH_TESSELATION</span><span class="p">,</span> 
</span><span id="line-110">                        <span class="n">landmark_drawing_spec</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> 
</span><span id="line-111">                        <span class="n">connection_drawing_spec</span><span class="o">=</span><span class="n">mp_drawing_styles</span><span class="o">.</span><span class="n">get_default_face_mesh_tesselation_style</span><span class="p">()</span>
</span><span id="line-112">                    <span class="p">)</span>
</span><span id="line-113">                    <span class="n">mp_drawing</span><span class="o">.</span><span class="n">draw_landmarks</span><span class="p">(</span>
</span><span id="line-114">                        <span class="n">image</span><span class="o">=</span><span class="n">image</span><span class="p">,</span> 
</span><span id="line-115">                        <span class="n">landmark_list</span><span class="o">=</span><span class="n">face_landmarks</span><span class="p">,</span> 
</span><span id="line-116">                        <span class="n">connections</span><span class="o">=</span><span class="n">mp_face_mesh</span><span class="o">.</span><span class="n">FACEMESH_CONTOURS</span><span class="p">,</span> 
</span><span id="line-117">                        <span class="n">landmark_drawing_spec</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> 
</span><span id="line-118">                        <span class="n">connection_drawing_spec</span><span class="o">=</span><span class="n">mp_drawing_styles</span><span class="o">.</span><span class="n">get_default_face_mesh_contours_style</span><span class="p">()</span>
</span><span id="line-119">                    <span class="p">)</span>
</span><span id="line-120">                    <span class="n">mp_drawing</span><span class="o">.</span><span class="n">draw_landmarks</span><span class="p">(</span>
</span><span id="line-121">                        <span class="n">image</span><span class="o">=</span><span class="n">image</span><span class="p">,</span> 
</span><span id="line-122">                        <span class="n">landmark_list</span><span class="o">=</span><span class="n">face_landmarks</span><span class="p">,</span> 
</span><span id="line-123">                        <span class="n">connections</span><span class="o">=</span><span class="n">mp_face_mesh</span><span class="o">.</span><span class="n">FACEMESH_IRISES</span><span class="p">,</span> 
</span><span id="line-124">                        <span class="n">landmark_drawing_spec</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> 
</span><span id="line-125">                        <span class="n">connection_drawing_spec</span><span class="o">=</span><span class="n">mp_drawing_styles</span><span class="o">.</span><span class="n">get_default_face_mesh_iris_connections_style</span><span class="p">()</span>
</span><span id="line-126">                    <span class="p">)</span>
</span><span id="line-127">
</span><span id="line-128">                    <span class="c1"># Calculate the distance between the upper and lower lips</span>
</span><span id="line-129">                    <span class="n">upper_lip</span> <span class="o">=</span> <span class="n">face_landmarks</span><span class="o">.</span><span class="n">landmark</span><span class="p">[</span><span class="mi">13</span><span class="p">]</span>
</span><span id="line-130">                    <span class="n">lower_lip</span> <span class="o">=</span> <span class="n">face_landmarks</span><span class="o">.</span><span class="n">landmark</span><span class="p">[</span><span class="mi">14</span><span class="p">]</span>
</span><span id="line-131">                    <span class="n">lip_distance</span> <span class="o">=</span> <span class="p">((</span><span class="n">upper_lip</span><span class="o">.</span><span class="n">x</span> <span class="o">-</span> <span class="n">lower_lip</span><span class="o">.</span><span class="n">x</span><span class="p">)</span> <span class="o">**</span> <span class="mi">2</span> <span class="o">+</span> <span class="p">(</span><span class="n">upper_lip</span><span class="o">.</span><span class="n">y</span> <span class="o">-</span> <span class="n">lower_lip</span><span class="o">.</span><span class="n">y</span><span class="p">)</span> <span class="o">**</span> <span class="mi">2</span><span class="p">)</span> <span class="o">**</span> <span class="mf">0.5</span>
</span><span id="line-132">                    <span class="k">if</span> <span class="n">lip_distance</span> <span class="o">&gt;</span> <span class="mf">0.02</span><span class="p">:</span>
</span><span id="line-133">                        <span class="n">cvzone</span><span class="o">.</span><span class="n">putTextRect</span><span class="p">(</span><span class="n">image</span><span class="p">,</span> <span class="s2">"Mouth Open"</span><span class="p">,</span> <span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="mi">40</span><span class="p">),</span> <span class="n">scale</span><span class="o">=</span><span class="mf">1.5</span><span class="p">,</span> <span class="n">thickness</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
</span><span id="line-134">                        <span class="n">client</span><span class="o">.</span><span class="n">publish</span><span class="p">(</span><span class="n">mqtt_topic</span><span class="p">,</span> <span class="s2">"Mouth Open"</span><span class="p">)</span>  <span class="c1"># Publish to MQTT</span>
</span><span id="line-135">                    <span class="k">else</span><span class="p">:</span>
</span><span id="line-136">                        <span class="n">cvzone</span><span class="o">.</span><span class="n">putTextRect</span><span class="p">(</span><span class="n">image</span><span class="p">,</span> <span class="s2">"Mouth Closed"</span><span class="p">,</span> <span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="mi">40</span><span class="p">),</span> <span class="n">scale</span><span class="o">=</span><span class="mf">1.5</span><span class="p">,</span> <span class="n">thickness</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
</span><span id="line-137">                        <span class="n">client</span><span class="o">.</span><span class="n">publish</span><span class="p">(</span><span class="n">mqtt_topic</span><span class="p">,</span> <span class="s2">"Mouth Closed"</span><span class="p">)</span>  <span class="c1"># Publish to MQTT</span>
</span><span id="line-138">
</span><span id="line-139">                    <span class="c1"># Detect gaze direction based on cheek positions</span>
</span><span id="line-140">                    <span class="n">left_cheek</span> <span class="o">=</span> <span class="n">face_landmarks</span><span class="o">.</span><span class="n">landmark</span><span class="p">[</span><span class="mi">234</span><span class="p">]</span>
</span><span id="line-141">                    <span class="n">right_cheek</span> <span class="o">=</span> <span class="n">face_landmarks</span><span class="o">.</span><span class="n">landmark</span><span class="p">[</span><span class="mi">454</span><span class="p">]</span>
</span><span id="line-142">                    <span class="k">if</span> <span class="n">left_cheek</span><span class="o">.</span><span class="n">x</span> <span class="o">&lt;</span> <span class="mf">0.3</span><span class="p">:</span>
</span><span id="line-143">                        <span class="n">cvzone</span><span class="o">.</span><span class="n">putTextRect</span><span class="p">(</span><span class="n">image</span><span class="p">,</span> <span class="s2">"Looking Left"</span><span class="p">,</span> <span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="mi">80</span><span class="p">),</span> <span class="n">scale</span><span class="o">=</span><span class="mf">1.5</span><span class="p">,</span> <span class="n">thickness</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
</span><span id="line-144">                        <span class="n">client</span><span class="o">.</span><span class="n">publish</span><span class="p">(</span><span class="n">mqtt_topic</span><span class="p">,</span> <span class="s2">"Looking Left"</span><span class="p">)</span>  <span class="c1"># Publish to MQTT</span>
</span><span id="line-145">                    <span class="k">elif</span> <span class="n">right_cheek</span><span class="o">.</span><span class="n">x</span> <span class="o">&gt;</span> <span class="mf">0.7</span><span class="p">:</span>
</span><span id="line-146">                        <span class="n">cvzone</span><span class="o">.</span><span class="n">putTextRect</span><span class="p">(</span><span class="n">image</span><span class="p">,</span> <span class="s2">"Looking Right"</span><span class="p">,</span> <span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="mi">80</span><span class="p">),</span> <span class="n">scale</span><span class="o">=</span><span class="mf">1.5</span><span class="p">,</span> <span class="n">thickness</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
</span><span id="line-147">                        <span class="n">client</span><span class="o">.</span><span class="n">publish</span><span class="p">(</span><span class="n">mqtt_topic</span><span class="p">,</span> <span class="s2">"Looking Right"</span><span class="p">)</span>  <span class="c1"># Publish to MQTT</span>
</span><span id="line-148">                    <span class="k">else</span><span class="p">:</span>
</span><span id="line-149">                        <span class="n">cvzone</span><span class="o">.</span><span class="n">putTextRect</span><span class="p">(</span><span class="n">image</span><span class="p">,</span> <span class="s2">"Looking Center"</span><span class="p">,</span> <span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="mi">80</span><span class="p">),</span> <span class="n">scale</span><span class="o">=</span><span class="mf">1.5</span><span class="p">,</span> <span class="n">thickness</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
</span><span id="line-150">                        <span class="n">client</span><span class="o">.</span><span class="n">publish</span><span class="p">(</span><span class="n">mqtt_topic</span><span class="p">,</span> <span class="s2">"Looking Center"</span><span class="p">)</span>  <span class="c1"># Publish to MQTT</span>
</span><span id="line-151">
</span><span id="line-152">            <span class="c1"># Rotate the image to display it correctly in portrait mode</span>
</span><span id="line-153">            <span class="n">image</span> <span class="o">=</span> <span class="n">cv</span><span class="o">.</span><span class="n">rotate</span><span class="p">(</span><span class="n">image</span><span class="p">,</span> <span class="n">cv</span><span class="o">.</span><span class="n">ROTATE_90_CLOCKWISE</span><span class="p">)</span>
</span><span id="line-154">            <span class="n">cv</span><span class="o">.</span><span class="n">imshow</span><span class="p">(</span><span class="s1">'MediaPipe Face Mesh'</span><span class="p">,</span> <span class="n">image</span><span class="p">)</span>
</span><span id="line-155">
</span><span id="line-156">            <span class="c1"># Break the loop if the 'ESC' key is pressed</span>
</span><span id="line-157">            <span class="k">if</span> <span class="n">cv</span><span class="o">.</span><span class="n">waitKey</span><span class="p">(</span><span class="mi">5</span><span class="p">)</span> <span class="o">&amp;</span> <span class="mh">0xFF</span> <span class="o">==</span> <span class="mi">27</span><span class="p">:</span>
</span><span id="line-158">                <span class="k">break</span>
</span><span id="line-159">
</span><span id="line-160">    <span class="c1"># Release the camera and close all OpenCV windows</span>
</span><span id="line-161">    <span class="n">cap</span><span class="o">.</span><span class="n">release</span><span class="p">()</span>
</span><span id="line-162">    <span class="n">cv</span><span class="o">.</span><span class="n">destroyAllWindows</span><span class="p">()</span>
</span><span id="line-163">
</span><span id="line-164"><span class="k">def</span> <span class="nf">voiceCommands</span><span class="p">():</span>
</span><span id="line-165">    <span class="sd">"""</span>
</span><span id="line-166"><span class="sd">    This function listens for voice commands using the microphone and recognizes specific</span>
</span><span id="line-167"><span class="sd">    commands such as "move forward", "move left", "move right", and "stop". Recognized </span>
</span><span id="line-168"><span class="sd">    commands are published to the MQTT broker.</span>
</span><span id="line-169"><span class="sd">    """</span>
</span><span id="line-170">    <span class="k">global</span> <span class="n">voice_command_running</span>
</span><span id="line-171">
</span><span id="line-172">    <span class="n">recognizer</span> <span class="o">=</span> <span class="n">sr</span><span class="o">.</span><span class="n">Recognizer</span><span class="p">()</span>
</span><span id="line-173">    <span class="n">mic</span> <span class="o">=</span> <span class="n">sr</span><span class="o">.</span><span class="n">Microphone</span><span class="p">()</span>
</span><span id="line-174">
</span><span id="line-175">    <span class="c1"># Adjust the recognizer for ambient noise</span>
</span><span id="line-176">    <span class="k">with</span> <span class="n">mic</span> <span class="k">as</span> <span class="n">source</span><span class="p">:</span>
</span><span id="line-177">        <span class="n">recognizer</span><span class="o">.</span><span class="n">adjust_for_ambient_noise</span><span class="p">(</span><span class="n">source</span><span class="p">)</span>
</span><span id="line-178">
</span><span id="line-179">    <span class="k">while</span> <span class="n">voice_command_running</span><span class="p">:</span>
</span><span id="line-180">        <span class="k">with</span> <span class="n">mic</span> <span class="k">as</span> <span class="n">source</span><span class="p">:</span>
</span><span id="line-181">            <span class="nb">print</span><span class="p">(</span><span class="s2">"Listening..."</span><span class="p">)</span>
</span><span id="line-182">            <span class="n">audio</span> <span class="o">=</span> <span class="n">recognizer</span><span class="o">.</span><span class="n">listen</span><span class="p">(</span><span class="n">source</span><span class="p">)</span>
</span><span id="line-183">        <span class="k">try</span><span class="p">:</span>
</span><span id="line-184">            <span class="n">command</span> <span class="o">=</span> <span class="n">recognizer</span><span class="o">.</span><span class="n">recognize_google</span><span class="p">(</span><span class="n">audio</span><span class="p">)</span><span class="o">.</span><span class="n">lower</span><span class="p">()</span>
</span><span id="line-185">            <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"You said: </span><span class="si">{</span><span class="n">command</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>
</span><span id="line-186">
</span><span id="line-187">            <span class="c1"># Publish recognized commands to MQTT</span>
</span><span id="line-188">            <span class="k">if</span> <span class="s2">"move forward"</span> <span class="ow">in</span> <span class="n">command</span><span class="p">:</span>
</span><span id="line-189">                <span class="nb">print</span><span class="p">(</span><span class="s2">"Moving Forward"</span><span class="p">)</span>
</span><span id="line-190">                <span class="n">client</span><span class="o">.</span><span class="n">publish</span><span class="p">(</span><span class="n">mqtt_topic</span><span class="p">,</span> <span class="s2">"Move Forward"</span><span class="p">)</span>
</span><span id="line-191">            <span class="k">elif</span> <span class="s2">"move left"</span> <span class="ow">in</span> <span class="n">command</span><span class="p">:</span>
</span><span id="line-192">                <span class="nb">print</span><span class="p">(</span><span class="s2">"Moving Left"</span><span class="p">)</span>
</span><span id="line-193">                <span class="n">client</span><span class="o">.</span><span class="n">publish</span><span class="p">(</span><span class="n">mqtt_topic</span><span class="p">,</span> <span class="s2">"Move Left"</span><span class="p">)</span>
</span><span id="line-194">            <span class="k">elif</span> <span class="s2">"move right"</span> <span class="ow">in</span> <span class="n">command</span><span class="p">:</span>
</span><span id="line-195">                <span class="nb">print</span><span class="p">(</span><span class="s2">"Moving Right"</span><span class="p">)</span>
</span><span id="line-196">                <span class="n">client</span><span class="o">.</span><span class="n">publish</span><span class="p">(</span><span class="n">mqtt_topic</span><span class="p">,</span> <span class="s2">"Move Right"</span><span class="p">)</span>
</span><span id="line-197">            <span class="k">elif</span> <span class="s2">"stop"</span> <span class="ow">in</span> <span class="n">command</span><span class="p">:</span>
</span><span id="line-198">                <span class="nb">print</span><span class="p">(</span><span class="s2">"Stopping"</span><span class="p">)</span>
</span><span id="line-199">                <span class="n">client</span><span class="o">.</span><span class="n">publish</span><span class="p">(</span><span class="n">mqtt_topic</span><span class="p">,</span> <span class="s2">"Stop"</span><span class="p">)</span>
</span><span id="line-200">            <span class="k">else</span><span class="p">:</span>
</span><span id="line-201">                <span class="nb">print</span><span class="p">(</span><span class="s2">"Command not recognized"</span><span class="p">)</span>
</span><span id="line-202">
</span><span id="line-203">        <span class="k">except</span> <span class="n">sr</span><span class="o">.</span><span class="n">UnknownValueError</span><span class="p">:</span>
</span><span id="line-204">            <span class="nb">print</span><span class="p">(</span><span class="s2">"Sorry, I did not understand that."</span><span class="p">)</span>
</span><span id="line-205">        <span class="k">except</span> <span class="n">sr</span><span class="o">.</span><span class="n">RequestError</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
</span><span id="line-206">            <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"Sorry, there was an error with the speech recognition service: </span><span class="si">{</span><span class="n">e</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>
</span><span id="line-207">
</span><span id="line-208"><span class="k">def</span> <span class="nf">startFaceRecognition</span><span class="p">():</span>
</span><span id="line-209">    <span class="sd">"""Starts the face recognition process in a separate thread."""</span>
</span><span id="line-210">    <span class="k">global</span> <span class="n">face_recognition_running</span>
</span><span id="line-211">    <span class="n">face_recognition_running</span> <span class="o">=</span> <span class="kc">True</span>
</span><span id="line-212">    <span class="n">threading</span><span class="o">.</span><span class="n">Thread</span><span class="p">(</span><span class="n">target</span><span class="o">=</span><span class="n">faceRecognition</span><span class="p">)</span><span class="o">.</span><span class="n">start</span><span class="p">()</span>
</span><span id="line-213">
</span><span id="line-214"><span class="k">def</span> <span class="nf">stopFaceRecognition</span><span class="p">():</span>
</span><span id="line-215">    <span class="sd">"""Stops the face recognition process."""</span>
</span><span id="line-216">    <span class="k">global</span> <span class="n">face_recognition_running</span>
</span><span id="line-217">    <span class="n">face_recognition_running</span> <span class="o">=</span> <span class="kc">False</span>
</span><span id="line-218">
</span><span id="line-219"><span class="k">def</span> <span class="nf">startVoiceCommands</span><span class="p">():</span>
</span><span id="line-220">    <span class="sd">"""Starts the voice command recognition process in a separate thread."""</span>
</span><span id="line-221">    <span class="k">global</span> <span class="n">voice_command_running</span>
</span><span id="line-222">    <span class="n">voice_command_running</span> <span class="o">=</span> <span class="kc">True</span>
</span><span id="line-223">    <span class="n">threading</span><span class="o">.</span><span class="n">Thread</span><span class="p">(</span><span class="n">target</span><span class="o">=</span><span class="n">voiceCommands</span><span class="p">)</span><span class="o">.</span><span class="n">start</span><span class="p">()</span>
</span><span id="line-224">
</span><span id="line-225"><span class="k">def</span> <span class="nf">stopVoiceCommands</span><span class="p">():</span>
</span><span id="line-226">    <span class="sd">"""Stops the voice command recognition process."""</span>
</span><span id="line-227">    <span class="k">global</span> <span class="n">voice_command_running</span>
</span><span id="line-228">    <span class="n">voice_command_running</span> <span class="o">=</span> <span class="kc">False</span>
</span><span id="line-229">
</span><span id="line-230"><span class="c1"># Add buttons to the GUI for starting voice and face recognition processes</span>
</span><span id="line-231"><span class="n">gui</span><span class="o">.</span><span class="n">add_button</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="mi">120</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span> <span class="n">w</span><span class="o">=</span><span class="mi">180</span><span class="p">,</span> <span class="n">h</span><span class="o">=</span><span class="mi">30</span><span class="p">,</span> <span class="n">text</span><span class="o">=</span><span class="s2">"START VOICE COM"</span><span class="p">,</span> <span class="n">origin</span><span class="o">=</span><span class="s1">'center'</span><span class="p">,</span> <span class="n">onclick</span><span class="o">=</span><span class="n">startVoiceCommands</span><span class="p">)</span>
</span><span id="line-232"><span class="n">gui</span><span class="o">.</span><span class="n">add_button</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="mi">120</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="mi">180</span><span class="p">,</span> <span class="n">w</span><span class="o">=</span><span class="mi">180</span><span class="p">,</span> <span class="n">h</span><span class="o">=</span><span class="mi">30</span><span class="p">,</span> <span class="n">text</span><span class="o">=</span><span class="s2">"START FACE RECOG"</span><span class="p">,</span> <span class="n">origin</span><span class="o">=</span><span class="s1">'center'</span><span class="p">,</span> <span class="n">onclick</span><span class="o">=</span><span class="n">startFaceRecognition</span><span class="p">)</span>
</span><span id="line-233">
</span><span id="line-234"><span class="c1"># Display a static text label on the GUI</span>
</span><span id="line-235"><span class="n">info_text</span> <span class="o">=</span> <span class="n">gui</span><span class="o">.</span><span class="n">draw_text</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="mi">120</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="mi">50</span><span class="p">,</span> <span class="n">text</span><span class="o">=</span><span class="s1">'MOMO'</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s2">"red"</span><span class="p">,</span> <span class="n">origin</span><span class="o">=</span><span class="s1">'bottom'</span><span class="p">)</span>
</span><span id="line-236">
</span><span id="line-237"><span class="c1"># Main loop to keep the script running and allow the GUI and threads to function</span>
</span><span id="line-238"><span class="k">while</span> <span class="kc">True</span><span class="p">:</span>
</span><span id="line-239">    <span class="n">time</span><span class="o">.</span><span class="n">sleep</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>
</span></pre>
       </div>
      </div>
     </div>
    </div>
   </div>
  </section>
  <div class="project-section-break">
  </div>
  <div class="project-section-break">
  </div>
 </div>
</div>
